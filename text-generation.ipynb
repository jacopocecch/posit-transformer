{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T17:13:28.252803250Z",
     "start_time": "2023-05-16T17:13:28.159990046Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import backend as K\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T15:56:07.380239694Z",
     "start_time": "2023-05-16T15:55:46.142160033Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget -O aclImdbGen.tar.gz https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "#!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T17:06:18.840186875Z",
     "start_time": "2023-05-16T17:06:18.152120793Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20003 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = keras.utils.text_dataset_from_directory(\n",
    "    directory=\"aclImdb/train\", label_mode=None, batch_size=256\n",
    ")\n",
    "dataset_train = dataset_train.map(lambda x: tf.strings.regex_replace(x, \"<br />\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T17:06:27.233323354Z",
     "start_time": "2023-05-16T17:06:24.858155970Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "vocab_size = 15000\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "text_vectorization.adapt(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_lm_dataset(text_batch):\n",
    "    vectorized_sequences = text_vectorization(text_batch)\n",
    "    x = vectorized_sequences[:, :-1]\n",
    "    y = vectorized_sequences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "lm_dataset_train = dataset_train.map(prepare_lm_dataset, num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T17:06:31.620876910Z",
     "start_time": "2023-05-16T17:06:31.549347881Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T17:06:32.670551072Z",
     "start_time": "2023-05-16T17:06:32.576777933Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "             [tf.expand_dims(batch_size, -1),\n",
    "              tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 2\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)\n",
    "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "79/79 [==============================] - 245s 3s/step - loss: 3.1298\n"
     ]
    }
   ],
   "source": [
    "model.fit(lm_dataset_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(\"text-generation/transformer_best.keras\")\n",
    "model.save_weights(\"ext-generation/transformer_best_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"text-generation/transformer_best.keras\",\n",
    "    custom_objects={\"TransformerDecoder\": TransformerDecoder,\n",
    "                    \"PositionalEmbedding\": PositionalEmbedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGsCAYAAADzMYzrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAha0lEQVR4nO3deXDU9f3H8deSkOVKggECSYncgXJfQlFQEOQsAzjjgSiRph4ttNCIR+pMKT+lEZWorQhMlURaLUgL6NgCcgWqHEIAObQIiJzLUdFsEsuK2c/vD8cdQyAky2a/n2Sfj5nvH/vNZzfvfGcHnvPd7+66jDFGAAAAFqrl9AAAAABXQqgAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAa9WYUNm0aZNGjx6t5ORkuVwurVixolL3//3vfy+Xy1Vmq1+/ftUMDAAArqrGhEpxcbG6deumuXPnBnX/6dOny+PxlNo6duyoO+64I8STAgCAiqoxoTJixAg9/fTTGjdu3GV/7vP5NH36dP3oRz9S/fr11bdvX+Xl5QV+3qBBAzVr1iywnTlzRh9//LHS09PD9BcAAIBL1ZhQuZopU6Zoy5YtWrx4sfbs2aM77rhDw4cP18GDBy+7/tVXX1VqaqoGDBgQ5kkBAMD3IiJUjh07ppycHC1dulQDBgxQmzZtNH36dPXv3185OTll1l+4cEFvvPEGZ1MAAHBYtNMDhMPevXtVUlKi1NTUUvt9Pp8aNWpUZv3y5ctVWFiotLS0cI0IAAAuIyJCpaioSFFRUcrPz1dUVFSpnzVo0KDM+ldffVU//elP1bRp03CNCAAALiMiQqVHjx4qKSnR2bNnr3rNyZEjR7Rhwwa98847YZoOAABcSY0JlaKiIh06dChw+8iRI9q9e7cSEhKUmpqqCRMmaOLEiZozZ4569Oihc+fOad26deratatGjRoVuN/ChQuVlJSkESNGOPFnAACAH3AZY4zTQ4RCXl6eBg0aVGZ/WlqacnNzdfHiRT399NNatGiRTp48qcaNG+snP/mJZs6cqS5dukiS/H6/WrRooYkTJ2rWrFnh/hMAAMAlakyoAACAmici3p4MAACqJ0IFAABYq1pfTOv3+3Xq1CnFxsbK5XI5PQ4AAKgAY4wKCwuVnJysWrXKP2dSrUPl1KlTSklJcXoMAAAQhOPHj6t58+blrqnWoRIbGyvpuz80Li7O4WkAAEBFeL1epaSkBP4fL0+1DpXvX+6Ji4sjVAAAqGYqctkGF9MCAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBa0U4PAIRTp67d5fF4yl2TlJSk/Xt2h2cgAEC5CBVEFI/Ho6GzVpS75r0nx4ZlFgDA1fHSDwAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqOhsrvf/97uVyuUluHDh2cHAkAAFjE8W9P7tSpk9auXRu4HR3t+EgAAMASjldBdHS0mjVr5vQYAADAQo5fo3Lw4EElJyerdevWmjBhgo4dO3bFtT6fT16vt9QGAABqLkdDpW/fvsrNzdWqVas0b948HTlyRAMGDFBhYeFl12dlZSk+Pj6wpaSkhHliAAAQTi5jjHF6iO999dVXatGihbKzs5Wenl7m5z6fTz6fL3Db6/UqJSVFBQUFiouLC+eoqKYSmjTV0Fkryl3z3pNjdf7cmfAMBAARyOv1Kj4+vkL/fzt+jcoPNWzYUKmpqTp06NBlf+52u+V2u8M8FQAAcIrj16j8UFFRkQ4fPqykpCSnRwEAABZwNFSmT5+ujRs36vPPP9fmzZs1btw4RUVFafz48U6OBQAALOHoSz8nTpzQ+PHj9cUXX6hJkybq37+/tm7dqiZNmjg5FgAAsISjobJ48WInfz0AALCcVdeoAAAA/BChAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwVrTTAwC28RYWKaFJ03LXJCUlaf+e3eEZCAAiGKECXML4/Ro6a0W5a957cmxYZgGASMdLPwAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGtZEyrPPPOMXC6Xpk2b5vQoAADAElaEyvbt27VgwQJ17drV6VEAAIBFHA+VoqIiTZgwQX/+85913XXXOT0OAACwiOOhMnnyZI0aNUpDhgy56lqfzyev11tqAwAANVe0k7988eLF2rlzp7Zv316h9VlZWZo5c2YVTwUAAGzh2BmV48ePa+rUqXrjjTdUp06dCt0nMzNTBQUFge348eNVPCUAAHCSY2dU8vPzdfbsWfXs2TOwr6SkRJs2bdLLL78sn8+nqKioUvdxu91yu93hHhUAADjEsVAZPHiw9u7dW2rfpEmT1KFDBz3++ONlIgUAAEQex0IlNjZWnTt3LrWvfv36atSoUZn9AAAgMjn+rh8AAIArcfRdP5fKy8tzegQAAGARzqgAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArBVUqHz22WehngMAAKCMoEKlbdu2GjRokP7617/qwoULoZ4JAABAUpChsnPnTnXt2lUZGRlq1qyZHnroIX344Yehng0AAES4oEKle/fueumll3Tq1CktXLhQHo9H/fv3V+fOnZWdna1z586Fek7gqjp17a6EJk3L3byFhU6PCQCohOhrunN0tG6//XaNGjVKr7zyijIzMzV9+nT99re/1Z133qnZs2crKSkpVLMC5fJ4PBo6a0W5a5ZOuTU8wwAAQuKa3vWzY8cO/fKXv1RSUpKys7M1ffp0HT58WGvWrNGpU6c0ZsyYUM0JAAAiUFBnVLKzs5WTk6MDBw5o5MiRWrRokUaOHKlatb7rnlatWik3N1ctW7YM5awAACDCBBUq8+bN089+9jPdf//9V3xpJzExUa+99to1DQcAACJbUKFy8ODBq66JiYlRWlpaMA8PAAAgKchrVHJycrR06dIy+5cuXarXX3/9mocCAACQggyVrKwsNW7cuMz+xMRE/eEPf7jmoQAAAKQgQ+XYsWNq1apVmf0tWrTQsWPHrnkoAAAAKchQSUxM1J49e8rs/+ijj9SoUaMKP868efPUtWtXxcXFKS4uTv369dPKlSuDGQkAANRAQYXK+PHj9etf/1obNmxQSUmJSkpKtH79ek2dOlV33313hR+nefPmeuaZZ5Sfn68dO3bo1ltv1ZgxY7R///5gxgIAADVMUO/6eeqpp/T5559r8ODBio7+7iH8fr8mTpxYqWtURo8eXer2rFmzNG/ePG3dulWdOnUKZjQAAFCDBBUqMTExWrJkiZ566il99NFHqlu3rrp06aIWLVoEPUhJSYmWLl2q4uJi9evX77JrfD6ffD5f4LbX6w369wEAAPtd03f9pKamKjU19ZoG2Lt3r/r166cLFy6oQYMGWr58uTp27HjZtVlZWZo5c+Y1/T4AAFB9BBUqJSUlys3N1bp163T27Fn5/f5SP1+/fn2FH6t9+/bavXu3CgoK9Pe//11paWnauHHjZWMlMzNTGRkZgdter1cpKSnB/AkAAKAaCCpUpk6dqtzcXI0aNUqdO3eWy+UKeoCYmBi1bdtWktSrVy9t375dL730khYsWFBmrdvtltvtDvp3AQCA6iWoUFm8eLHeeustjRw5MtTzyO/3l7oOBQAARK6gL6b9/izItcjMzNSIESN0/fXXq7CwUG+++aby8vK0evXqa35sAABQ/QX1OSqPPPKIXnrpJRljrumXnz17VhMnTlT79u01ePBgbd++XatXr9Ztt912TY8LAABqhqDOqLz//vvasGGDVq5cqU6dOql27dqlfr5s2bIKPc5rr70WzK8HAAARIqhQadiwocaNGxfqWQAAAEoJKlRycnJCPQcAAEAZQV2jIknffvut1q5dqwULFqiwsFCSdOrUKRUVFYVsOAAAENmCOqNy9OhRDR8+XMeOHZPP59Ntt92m2NhYzZ49Wz6fT/Pnzw/1nAAAIAIFdUZl6tSp6t27t7788kvVrVs3sH/cuHFat25dyIYDAACRLagzKv/+97+1efNmxcTElNrfsmVLnTx5MiSDAQAABHVGxe/3q6SkpMz+EydOKDY29pqHAgAAkIIMlaFDh+rFF18M3Ha5XCoqKtKMGTOq5GP1AQBAZArqpZ85c+Zo2LBh6tixoy5cuKB77rlHBw8eVOPGjfW3v/0t1DMCAIAIFVSoNG/eXB999JEWL16sPXv2qKioSOnp6ZowYUKpi2sBAACuRVChIknR0dG69957QzkLAABAKUGFyqJFi8r9+cSJE4MaBgAA4IeCCpWpU6eWun3x4kV9/fXXiomJUb169QgVAAAQEkG96+fLL78stRUVFenAgQPq378/F9MCAICQCfq7fi7Vrl07PfPMM2XOtgAAAAQrZKEifXeB7alTp0L5kAAAIIIFdY3KO++8U+q2MUYej0cvv/yybrrpppAMBgAAEFSojB07ttRtl8ulJk2a6NZbb9WcOXNCMRcAAEBwoeL3+0M9BwAAQBkhvUYFAAAglII6o5KRkVHhtdnZ2cH8CgAAgOBCZdeuXdq1a5cuXryo9u3bS5I+/fRTRUVFqWfPnoF1LpcrNFMCAICIFFSojB49WrGxsXr99dd13XXXSfruQ+AmTZqkAQMG6JFHHgnpkAAAIDIFdY3KnDlzlJWVFYgUSbruuuv09NNP864fAAAQMkGFitfr1blz58rsP3funAoLC695KAAAACnIUBk3bpwmTZqkZcuW6cSJEzpx4oT+8Y9/KD09XbfffnuoZwQAABEqqGtU5s+fr+nTp+uee+7RxYsXv3ug6Gilp6frueeeC+mAAAAgcgUVKvXq1dMrr7yi5557TocPH5YktWnTRvXr1w/pcAAAILJd0we+eTweeTwetWvXTvXr15cxJlRzAQAABBcqX3zxhQYPHqzU1FSNHDlSHo9HkpSens5bkwEAQMgEFSq/+c1vVLt2bR07dkz16tUL7L/rrru0atWqkA0HAAAiW1DXqLz33ntavXq1mjdvXmp/u3btdPTo0ZAMBgAAENQZleLi4lJnUr53/vx5ud3uax4KAABACjJUBgwYoEWLFgVuu1wu+f1+Pfvssxo0aFDIhgMAAJEtqJd+nn32WQ0ePFg7duzQN998o8cee0z79+/X+fPn9cEHH4R6RgAAEKGCOqPSuXNnffrpp+rfv7/GjBmj4uJi3X777dq1a5fatGkT6hkBAECEqvQZlYsXL2r48OGaP3++nnzyyaqYCQAAQFIQZ1Rq166tPXv2VMUsAAAApQT10s+9996r1157LdSzAAAAlBLUxbTffvutFi5cqLVr16pXr15lvuMnOzs7JMMBAIDIVqlQ+eyzz9SyZUvt27dPPXv2lCR9+umnpda4XK7QTQcAACJapUKlXbt28ng82rBhg6TvPjL/j3/8o5o2bVolwwEAgMhWqWtULv125JUrV6q4uDikAwEAAHwvqItpv3dpuAAAAIRSpULF5XKVuQaFa1IAAEBVqdQ1KsYY3X///YEvHrxw4YIefvjhMu/6WbZsWegmBAAAEatSoZKWllbq9r333hvSYQAAAH6oUqGSk5NTVXMAAACUcU0X0wIAAFQlQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtRwNlaysLN1www2KjY1VYmKixo4dqwMHDjg5EgAAsIijobJx40ZNnjxZW7du1Zo1a3Tx4kUNHTpUxcXFTo4FAAAsUamP0A+1VatWlbqdm5urxMRE5efn6+abb3ZoKgAAYAtHQ+VSBQUFkqSEhITL/tzn88nn8wVue73esMwFAACcYc3FtH6/X9OmTdNNN92kzp07X3ZNVlaW4uPjA1tKSkqYpwQAAOFkTahMnjxZ+/bt0+LFi6+4JjMzUwUFBYHt+PHjYZwQAACEmxUv/UyZMkXvvvuuNm3apObNm19xndvtltvtDuNkAADASY6GijFGv/rVr7R8+XLl5eWpVatWTo4DAAAs42ioTJ48WW+++abefvttxcbG6vTp05Kk+Ph41a1b18nRAACABRy9RmXevHkqKCjQwIEDlZSUFNiWLFni5FgAAMASjr/0AwAAcCXWvOsHAADgUoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALBWtNMDANWRt7BICU2alrsmKSlJ+/fsDs9AAFBDESpAEIzfr6GzVpS75r0nx4ZlFgCoyXjpBwAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1HQ2XTpk0aPXq0kpOT5XK5tGLFCifHAQAAlnE0VIqLi9WtWzfNnTvXyTEAAIClop385SNGjNCIESOcHAHVRKeu3eXxeMpd4y0sDNM0AIBwcTRUKsvn88nn8wVue71eB6dBOHk8Hg2dtaLcNUun3BqeYQAAYVOtLqbNyspSfHx8YEtJSXF6JAAAUIWqVahkZmaqoKAgsB0/ftzpkQAAQBWqVi/9uN1uud1up8cAAABhUq3OqAAAgMji6BmVoqIiHTp0KHD7yJEj2r17txISEnT99dc7OBkAALCBo6GyY8cODRo0KHA7IyNDkpSWlqbc3FyHpgIAALZwNFQGDhwoY4yTIwAAAItxjQoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArBXt9ABATeUtLFJCk6blrklKStL+PbvDMxAAVEOEClBFjN+vobNWlLvmvSfHhmUWAKiueOkHAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtfiuHziuU9fu8ng85a7xFhaGaRoAgE0IFTjO4/Fc9cv7lk65NTzDAACswks/AADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGvxgW+Ag7yFRUpo0rTcNUlJSdq/Z3d4BgIAyxAqgIOM33/VT+V978mxYZkFAGzESz8AAMBaVoTK3Llz1bJlS9WpU0d9+/bVhx9+6PRICJFOXbsroUnTcje+cBAAcCWOv/SzZMkSZWRkaP78+erbt69efPFFDRs2TAcOHFBiYqLT4+Ea8YWDAIBr4fgZlezsbD3wwAOaNGmSOnbsqPnz56tevXpauHCh06MBAACHOXpG5ZtvvlF+fr4yMzMD+2rVqqUhQ4Zoy5YtZdb7fD75fL7A7YKCAkmS1+ut+mERFOP36+L/istfYwxrylHgLdR1jZqUu6Zps2b6cMsH5a4BAFt8//+2Mebqi42DTp48aSSZzZs3l9r/6KOPmj59+pRZP2PGDCOJjY2NjY2NrQZsx48fv2orOH6NSmVkZmYqIyMjcNvv9+v8+fNq1KiRXC6Xg5PZx+v1KiUlRcePH1dcXJzT41iNY1VxHKuK41hVHMeq4mrKsTLGqLCwUMnJyVdd62ioNG7cWFFRUTpz5kyp/WfOnFGzZs3KrHe73XK73aX2NWzYsCpHrPbi4uKq9ZM5nDhWFcexqjiOVcVxrCquJhyr+Pj4Cq1z9GLamJgY9erVS+vWrQvs8/v9Wrdunfr16+fgZAAAwAaOv/STkZGhtLQ09e7dW3369NGLL76o4uJiTZo0yenRAACAwxwPlbvuukvnzp3T7373O50+fVrdu3fXqlWr1LRp+d9/gvK53W7NmDGjzEtlKItjVXEcq4rjWFUcx6riIvFYuYypyHuDAAAAws/xD3wDAAC4EkIFAABYi1ABAADWIlQAAIC1CJUa5Pz585owYYLi4uLUsGFDpaenq6ioqNz7DBw4UC6Xq9T28MMPh2ni8Jk7d65atmypOnXqqG/fvvrwww/LXb906VJ16NBBderUUZcuXfSvf/0rTJM6rzLHKjc3t8zzp06dOmGc1jmbNm3S6NGjlZycLJfLpRUrVlz1Pnl5eerZs6fcbrfatm2r3NzcKp/TaZU9Tnl5eWWeUy6XS6dPnw7PwA7KysrSDTfcoNjYWCUmJmrs2LE6cODAVe9X0/+9IlRqkAkTJmj//v1as2aN3n33XW3atEkPPvjgVe/3wAMPyOPxBLZnn302DNOGz5IlS5SRkaEZM2Zo586d6tatm4YNG6azZ89edv3mzZs1fvx4paena9euXRo7dqzGjh2rffv2hXny8KvssZK++4TMHz5/jh49GsaJnVNcXKxu3bpp7ty5FVp/5MgRjRo1SoMGDdLu3bs1bdo0/fznP9fq1aureFJnVfY4fe/AgQOlnleJiYlVNKE9Nm7cqMmTJ2vr1q1as2aNLl68qKFDh6q4+MpfXBoR/16F5usF4bSPP/7YSDLbt28P7Fu5cqVxuVzm5MmTV7zfLbfcYqZOnRqGCZ3Tp08fM3ny5MDtkpISk5ycbLKysi67/s477zSjRo0qta9v377moYceqtI5bVDZY5WTk2Pi4+PDNJ29JJnly5eXu+axxx4znTp1KrXvrrvuMsOGDavCyexSkeO0YcMGI8l8+eWXYZnJZmfPnjWSzMaNG6+4JhL+veKMSg2xZcsWNWzYUL179w7sGzJkiGrVqqVt27aVe9833nhDjRs3VufOnZWZmamvv/66qscNm2+++Ub5+fkaMmRIYF+tWrU0ZMgQbdmy5bL32bJlS6n1kjRs2LArrq8pgjlWklRUVKQWLVooJSVFY8aM0f79+8MxbrUTqc+rYHXv3l1JSUm67bbb9MEHHzg9jiMKCgokSQkJCVdcEwnPK8c/mRahcfr06TKnRqOjo5WQkFDua7v33HOPWrRooeTkZO3Zs0ePP/64Dhw4oGXLllX1yGHx3//+VyUlJWU+6bhp06b6z3/+c9n7nD59+rLra/pr5MEcq/bt22vhwoXq2rWrCgoK9Pzzz+vGG2/U/v371bx583CMXW1c6Xnl9Xr1v//9T3Xr1nVoMrskJSVp/vz56t27t3w+n1599VUNHDhQ27ZtU8+ePZ0eL2z8fr+mTZumm266SZ07d77iukj494pQsdwTTzyh2bNnl7vmk08+Cfrxf3gNS5cuXZSUlKTBgwfr8OHDatOmTdCPi8jQr1+/Ul8geuONN+rHP/6xFixYoKeeesrByVBdtW/fXu3btw/cvvHGG3X48GG98MIL+stf/uLgZOE1efJk7du3T++//77ToziOULHcI488ovvvv7/cNa1bt1azZs3KXPD47bff6vz582rWrFmFf1/fvn0lSYcOHaoRodK4cWNFRUXpzJkzpfafOXPmiselWbNmlVpfUwRzrC5Vu3Zt9ejRQ4cOHaqKEau1Kz2v4uLiOJtyFX369Imo/7CnTJkSeEPE1c5MRsK/V1yjYrkmTZqoQ4cO5W4xMTHq16+fvvrqK+Xn5wfuu379evn9/kB8VMTu3bslfXf6tSaIiYlRr169tG7dusA+v9+vdevWlToT8EP9+vUrtV6S1qxZc8X1NUUwx+pSJSUl2rt3b415/oRSpD6vQmH37t0R8ZwyxmjKlClavny51q9fr1atWl31PhHxvHL6al6EzvDhw02PHj3Mtm3bzPvvv2/atWtnxo8fH/j5iRMnTPv27c22bduMMcYcOnTI/N///Z/ZsWOHOXLkiHn77bdN69atzc033+zUn1AlFi9ebNxut8nNzTUff/yxefDBB03Dhg3N6dOnjTHG3HfffeaJJ54IrP/ggw9MdHS0ef75580nn3xiZsyYYWrXrm327t3r1J8QNpU9VjNnzjSrV682hw8fNvn5+ebuu+82derUMfv373fqTwibwsJCs2vXLrNr1y4jyWRnZ5tdu3aZo0ePGmOMeeKJJ8x9990XWP/ZZ5+ZevXqmUcffdR88sknZu7cuSYqKsqsWrXKqT8hLCp7nF544QWzYsUKc/DgQbN3714zdepUU6tWLbN27Vqn/oSw+cUvfmHi4+NNXl6e8Xg8ge3rr78OrInEf68IlRrkiy++MOPHjzcNGjQwcXFxZtKkSaawsDDw8yNHjhhJZsOGDcYYY44dO2Zuvvlmk5CQYNxut2nbtq159NFHTUFBgUN/QdX505/+ZK6//noTExNj+vTpY7Zu3Rr42S233GLS0tJKrX/rrbdMamqqiYmJMZ06dTL//Oc/wzyxcypzrKZNmxZY27RpUzNy5Eizc+dOB6YOv+/fRnvp9v3xSUtLM7fcckuZ+3Tv3t3ExMSY1q1bm5ycnLDPHW6VPU6zZ882bdq0MXXq1DEJCQlm4MCBZv369c4MH2aXO06SSj1PIvHfK5cxxoT5JA4AAECFcI0KAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWv8PfS//MJi8CX4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = model.get_weights()\n",
    "flattened_weights = [w.flatten() for w in weights]\n",
    "weights_array = [item for sublist in flattened_weights for item in sublist]\n",
    "sns.histplot(weights_array, stat='frequency', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie was extremely boring and [UNK] it was just too long to see the actual series\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This\"\n",
    "generate_length = 16\n",
    "\n",
    "tokens_index = dict(enumerate(text_vectorization.get_vocabulary())) \n",
    "\n",
    "def sample_next(predictions, temperature=0.8): \n",
    " predictions = np.asarray(predictions).astype(\"float64\")\n",
    " predictions = np.log(predictions) / temperature\n",
    " exp_preds = np.exp(predictions)\n",
    " predictions = exp_preds / np.sum(exp_preds)\n",
    " probas = np.random.multinomial(1, predictions, 1)\n",
    " return np.argmax(probas)\n",
    "\n",
    "for i in range(generate_length):\n",
    " tokenized_sentence = text_vectorization([sentence]) \n",
    " predictions = model(tokenized_sentence) \n",
    " next_token = sample_next(predictions[0, i, :]) \n",
    " sampled_token = tokens_index[next_token] \n",
    " sentence += \" \" + sampled_token \n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model converting the weights to Posit<16,0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('float32')]\n"
     ]
    }
   ],
   "source": [
    "K.set_floatx('posit160')\n",
    "\n",
    "# Get the original weights\n",
    "ws = model.get_weights()\n",
    "print(np.unique([w.dtype for w in model.get_weights()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype(posit160)]\n"
     ]
    }
   ],
   "source": [
    "# Convert the weights to Posit <16,0> and load a new model\n",
    "wsp = [w.astype(K.floatx()) for w in ws]\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)\n",
    "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "model_posit = keras.Model(inputs, outputs)\n",
    "model_posit.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "model_posit.set_weights(wsp)\n",
    "\n",
    "print(np.unique([w.dtype for w in model_posit.get_weights()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This film was a disappointment i did not recommend it to anyone who likes michael caine wishes\n"
     ]
    }
   ],
   "source": [
    "for i in range(generate_length):\n",
    " tokenized_sentence = text_vectorization([sentence]) \n",
    " predictions = model(tokenized_sentence) \n",
    " next_token = sample_next(predictions[0, i, :]) \n",
    " sampled_token = tokens_index[next_token] \n",
    " sentence += \" \" + sampled_token \n",
    "\n",
    "print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

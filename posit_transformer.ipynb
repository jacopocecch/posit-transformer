{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T09:37:13.523583019Z",
     "start_time": "2023-05-15T09:37:09.733727398Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 11:37:11.030281: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/count\n",
      "2023-05-15 11:37:11.030955: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/count\n",
      "2023-05-15 11:37:11.030998: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/api\n",
      "2023-05-15 11:37:11.031014: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/api\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import backend as K\n",
    "import os, pathlib, shutil, random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_floatx('posit160')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T09:45:21.313117114Z",
     "start_time": "2023-05-15T09:45:21.249646312Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim \n",
    "        self.dense_dim = dense_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"),layers.Dense(embed_dim),])\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None): \n",
    "        if mask is not None: \n",
    "            mask = mask[:, tf.newaxis, :] \n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "    \n",
    "    def get_config(self): \n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "        \"embed_dim\": self.embed_dim,\n",
    "        \"num_heads\": self.num_heads,\n",
    "        \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim) \n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None): \n",
    "        return tf.math.not_equal(inputs, 0) \n",
    "    \n",
    "    def get_config(self): \n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "        \"output_dim\": self.output_dim,\n",
    "        \"sequence_length\": self.sequence_length,\n",
    "        \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T09:50:52.040758513Z",
     "start_time": "2023-05-15T09:45:24.682730216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 301s 4us/step\n",
      "84140032/84125825 [==============================] - 301s 4us/step\n"
     ]
    }
   ],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "shutil.rmtree('aclImdb/train/unsup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T09:51:13.645633578Z",
     "start_time": "2023-05-15T09:51:13.265904909Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files) \n",
    "    num_val_samples = int(0.2 * len(files)) \n",
    "    val_files = files[-num_val_samples:] \n",
    "    for fname in val_files: \n",
    "        shutil.move(train_dir / category / fname, val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T09:51:23.404763515Z",
     "start_time": "2023-05-15T09:51:16.565791698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 11:51:20.154718: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:164] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_ds = keras.utils.text_dataset_from_directory( \"aclImdb/train\", batch_size=batch_size)\n",
    "val_ds = keras.utils.text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n",
    "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)\n",
    "\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x) \n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = TextVectorization(\n",
    " max_tokens=max_tokens,\n",
    " output_mode=\"int\",\n",
    " output_sequence_length=max_length, \n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T09:51:23.841764799Z",
     "start_time": "2023-05-15T09:51:23.414177429Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "sequence_length = 600\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs) \n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\",\n",
    " loss=\"binary_crossentropy\",\n",
    " metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8850fd0820>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"model/best_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'positional_embedding/embedding/embeddings:0' shape=(20000, 256) dtype=float32, numpy=\n",
      "array([[ 0.03739503, -0.06100216,  0.05121558, ...,  0.03595575,\n",
      "         0.0024836 ,  0.00336652],\n",
      "       [-0.00596904, -0.02471746,  0.01501249, ...,  0.00329701,\n",
      "        -0.02990483,  0.01573665],\n",
      "       [-0.04841526, -0.00022331, -0.0136003 , ..., -0.01757703,\n",
      "         0.0250284 , -0.04963886],\n",
      "       ...,\n",
      "       [ 0.02936665,  0.02552247, -0.01700588, ..., -0.01531127,\n",
      "         0.04560084, -0.00388065],\n",
      "       [ 0.00868333,  0.03133388,  0.00624219, ...,  0.03978611,\n",
      "        -0.01659929,  0.0709249 ],\n",
      "       [ 0.02855214,  0.03318401,  0.02619697, ..., -0.07201208,\n",
      "        -0.0371513 ,  0.02101573]], dtype=float32)>, <tf.Variable 'positional_embedding/embedding_1/embeddings:0' shape=(600, 256) dtype=float32, numpy=\n",
      "array([[ 0.02885527, -0.03422101, -0.0183788 , ...,  0.00225723,\n",
      "         0.00010679,  0.03315101],\n",
      "       [-0.03442131, -0.06718445, -0.01684681, ...,  0.00540662,\n",
      "        -0.03414644, -0.00175236],\n",
      "       [ 0.03997789,  0.04784407, -0.01734078, ...,  0.01212583,\n",
      "         0.00055019, -0.05299553],\n",
      "       ...,\n",
      "       [ 0.07602318,  0.00353942, -0.08416985, ..., -0.01822723,\n",
      "         0.01823145,  0.0677538 ],\n",
      "       [ 0.03683903,  0.01252821,  0.02595314, ...,  0.03071107,\n",
      "        -0.0190728 ,  0.03848042],\n",
      "       [-0.03626513, -0.00182839, -0.07148832, ..., -0.01791068,\n",
      "        -0.03752854, -0.00301532]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/query/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[ 0.02040909, -0.01481514,  0.02162656, ...,  0.02646832,\n",
      "          0.02581593,  0.03175477],\n",
      "        [ 0.01074212, -0.02126838, -0.01953249, ..., -0.03276222,\n",
      "          0.02112397, -0.02056869]],\n",
      "\n",
      "       [[ 0.00254384, -0.0004261 ,  0.00889832, ...,  0.0162819 ,\n",
      "          0.01530376,  0.01654082],\n",
      "        [-0.00427555, -0.00629697, -0.01580392, ..., -0.0193453 ,\n",
      "          0.01011501, -0.0116341 ]],\n",
      "\n",
      "       [[ 0.00355885, -0.01523843,  0.00107523, ...,  0.01925077,\n",
      "          0.01466459,  0.01279243],\n",
      "        [-0.01247899, -0.01913904, -0.03443166, ..., -0.01979836,\n",
      "          0.01855579, -0.02662241]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.02279986,  0.02834705, -0.03822089, ..., -0.01845905,\n",
      "         -0.01909025, -0.03014872],\n",
      "        [-0.04414343,  0.01206912,  0.00204685, ...,  0.00935424,\n",
      "         -0.01752488,  0.01320717]],\n",
      "\n",
      "       [[ 0.03488143, -0.03115044,  0.0299772 , ...,  0.03933975,\n",
      "          0.03284188,  0.03169756],\n",
      "        [ 0.02466709, -0.03333445, -0.06341918, ..., -0.04266356,\n",
      "          0.0447768 , -0.05291567]],\n",
      "\n",
      "       [[ 0.06050174, -0.05344301,  0.05531825, ...,  0.07155296,\n",
      "          0.05414613,  0.06113275],\n",
      "        [ 0.04043477, -0.05841038, -0.08547419, ..., -0.06366554,\n",
      "          0.0740004 , -0.06524774]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/query/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[-0.03166784,  0.05370068, -0.04995467, -0.04188215,  0.04475181,\n",
      "         0.03589845, -0.05933474,  0.0395014 ,  0.0467785 , -0.0512954 ,\n",
      "        -0.04228402,  0.04483116, -0.05542193, -0.03229695,  0.03166906,\n",
      "        -0.0398252 ,  0.05089184,  0.00295116,  0.04701733,  0.04554403,\n",
      "        -0.04742667, -0.05251729, -0.04172243,  0.05656457, -0.06084046,\n",
      "         0.05174848,  0.05347523, -0.05435492, -0.04252691,  0.03555615,\n",
      "         0.03844881, -0.04573162,  0.03687452,  0.03667698, -0.04723745,\n",
      "         0.04656682,  0.04176421, -0.03974482, -0.03532848,  0.05279642,\n",
      "         0.04542866,  0.06014746,  0.0614882 , -0.03590624,  0.05142029,\n",
      "        -0.04851207, -0.05614467,  0.04801136,  0.0408476 ,  0.04188671,\n",
      "         0.04978371, -0.03397418, -0.04947962,  0.03596261, -0.02968456,\n",
      "        -0.04879418, -0.03861361,  0.03063283,  0.05948223,  0.02650115,\n",
      "         0.06267744,  0.03374107,  0.05112569,  0.05677779,  0.05617561,\n",
      "        -0.04608063,  0.04767627, -0.02630902, -0.05617419,  0.06124048,\n",
      "         0.0474076 ,  0.06090389, -0.05243812, -0.0340381 , -0.06329025,\n",
      "        -0.04750043,  0.0432363 ,  0.03680647,  0.04530632,  0.0446833 ,\n",
      "         0.03685702,  0.05629683, -0.0458819 , -0.06259036,  0.04541837,\n",
      "        -0.04232357,  0.02848433, -0.04638686, -0.04814475,  0.0552812 ,\n",
      "        -0.0461717 , -0.05997983,  0.04168909,  0.05855836,  0.05579246,\n",
      "         0.0468186 ,  0.05444772, -0.06281483, -0.04322871, -0.05015085,\n",
      "        -0.05017268,  0.04859254,  0.06270248,  0.050778  ,  0.02166072,\n",
      "         0.03564601,  0.04540718,  0.04385761, -0.05680493, -0.05246983,\n",
      "         0.02916224, -0.04853864, -0.04654924, -0.05373051, -0.0473078 ,\n",
      "         0.04905415, -0.05407241, -0.06099441, -0.03161671,  0.04095946,\n",
      "         0.06806067, -0.06417253, -0.03380005, -0.04858686,  0.04462888,\n",
      "        -0.02872756, -0.0550013 , -0.06077632, -0.06314356, -0.05024696,\n",
      "        -0.04702551, -0.04806747,  0.04437392,  0.05537957, -0.06270991,\n",
      "         0.06038705,  0.05447775, -0.03788937, -0.04723429,  0.0515519 ,\n",
      "        -0.03302241, -0.04856055,  0.04083339,  0.05934587, -0.05293636,\n",
      "         0.03762256, -0.03659848,  0.05196451,  0.04582626,  0.04855714,\n",
      "        -0.05271209, -0.05662927, -0.0462409 , -0.05617887, -0.04690826,\n",
      "         0.04112157,  0.05749027, -0.05341611,  0.06531826,  0.05560028,\n",
      "        -0.05357809, -0.05135043, -0.04196633, -0.05555653, -0.04727517,\n",
      "         0.04612393,  0.05995972, -0.04936474, -0.04192555,  0.06241446,\n",
      "         0.03545026,  0.03607167,  0.02775122, -0.03992561, -0.04292934,\n",
      "         0.0540539 , -0.04252864,  0.05172896,  0.03903922, -0.04332688,\n",
      "        -0.05703069, -0.06096786, -0.05519412,  0.05058917, -0.05024653,\n",
      "        -0.03577496,  0.04213482, -0.05979989,  0.05004659,  0.06058932,\n",
      "         0.04867637,  0.0524486 , -0.06152571, -0.05458747,  0.03322522,\n",
      "        -0.05038729,  0.04927979, -0.02894529,  0.05811732,  0.05833104,\n",
      "        -0.04763629, -0.03458797,  0.04785123, -0.04258074,  0.05621447,\n",
      "         0.04748288,  0.05686003, -0.04029633, -0.04829794,  0.0412658 ,\n",
      "         0.04984007, -0.04566842,  0.05185884,  0.05051501, -0.05284015,\n",
      "        -0.04732821,  0.04762042, -0.0371175 ,  0.04897559, -0.0615639 ,\n",
      "        -0.03143069, -0.05925561,  0.04689689,  0.05661248,  0.05850415,\n",
      "         0.05977112,  0.05336906, -0.03342064, -0.0564297 ,  0.03838843,\n",
      "         0.04971734, -0.04817043,  0.05340951, -0.04572148, -0.04100793,\n",
      "        -0.05567269, -0.04418269, -0.03450868, -0.0432683 , -0.06404879,\n",
      "        -0.0506312 ,  0.05616189, -0.0449154 , -0.04708715,  0.05772877,\n",
      "         0.04714456,  0.05079036, -0.03426381, -0.03092105,  0.05249434,\n",
      "         0.04331494,  0.04056041,  0.05241381, -0.05004625, -0.04189005,\n",
      "        -0.05707062],\n",
      "       [-0.02138918,  0.04752554,  0.03402156, -0.04824367,  0.03698061,\n",
      "         0.02376012, -0.03747378,  0.03593923, -0.03071087, -0.04601124,\n",
      "        -0.03894813, -0.03371261,  0.0328262 , -0.0275662 ,  0.02947201,\n",
      "         0.03317058, -0.04019476,  0.03327544, -0.03079337,  0.050743  ,\n",
      "        -0.03458628, -0.04289883,  0.0475616 , -0.04443362,  0.03345979,\n",
      "        -0.03634897, -0.03114143,  0.04027218, -0.03074877, -0.04598438,\n",
      "         0.04529562,  0.03337163, -0.02120692, -0.03803318,  0.03955181,\n",
      "        -0.03384153,  0.01855192,  0.04363065,  0.02762645,  0.03314933,\n",
      "        -0.02267938, -0.04360366,  0.03326637,  0.03383417, -0.03637492,\n",
      "        -0.026605  ,  0.03024205, -0.03954414, -0.02902841,  0.04229886,\n",
      "         0.0311999 , -0.03335562, -0.04109489, -0.03507686,  0.03692535,\n",
      "         0.00668256,  0.03613155, -0.04015654, -0.0404633 , -0.02775453,\n",
      "        -0.03327838,  0.04334115,  0.02374337, -0.03924472,  0.02815892,\n",
      "        -0.05087976, -0.04677582,  0.032737  ,  0.02595522, -0.04293546,\n",
      "         0.04081881, -0.04241258, -0.03559887,  0.03713395,  0.0374454 ,\n",
      "        -0.03320361,  0.03529778, -0.02172416,  0.02709367, -0.04347551,\n",
      "        -0.04082509,  0.03356645, -0.04690166,  0.03850842,  0.04035059,\n",
      "        -0.02830384, -0.04834849, -0.04712141,  0.04643326, -0.03210643,\n",
      "        -0.03702622, -0.02766379, -0.03342719, -0.03539097, -0.03606468,\n",
      "        -0.03690429,  0.02938679, -0.04672283, -0.0439535 ,  0.026484  ,\n",
      "         0.0365366 , -0.01496788,  0.03069537,  0.03196932,  0.03293137,\n",
      "        -0.04131735,  0.03795282,  0.04304181, -0.03091272, -0.02253071,\n",
      "        -0.03521423, -0.020701  , -0.0499085 ,  0.04379534,  0.03864418,\n",
      "         0.02769904, -0.04438157, -0.02986158,  0.03613109, -0.04913146,\n",
      "        -0.02745946,  0.03683292, -0.04292162, -0.04382892,  0.03745249,\n",
      "        -0.02825603,  0.04326707,  0.02501634,  0.03951798, -0.04165856,\n",
      "         0.02405425,  0.03024073, -0.03777798, -0.02888952,  0.03323647,\n",
      "        -0.03711987, -0.02666657, -0.03677238,  0.03724298,  0.03438768,\n",
      "         0.03068293, -0.04301612, -0.03740046,  0.04780996, -0.04702167,\n",
      "        -0.04165407,  0.03298208, -0.03889091, -0.04254686, -0.03155959,\n",
      "        -0.0419971 , -0.03141666, -0.05411591,  0.02301912, -0.03878532,\n",
      "         0.03975513,  0.02717494,  0.03747929,  0.03005827, -0.04165827,\n",
      "         0.04259906, -0.04062644,  0.03116672,  0.03199649,  0.02679581,\n",
      "        -0.05120773,  0.03742687,  0.03381864,  0.03505762, -0.04348633,\n",
      "        -0.03428875,  0.02537913,  0.03124598, -0.03530911,  0.02807452,\n",
      "         0.03616036,  0.03928819, -0.03859065, -0.04207272, -0.02766629,\n",
      "         0.03799089, -0.04020672, -0.05236452, -0.04365987, -0.02301518,\n",
      "        -0.01366458,  0.0454816 , -0.03896347,  0.03639159, -0.04667651,\n",
      "        -0.0286398 , -0.02625173, -0.0229158 ,  0.03622313, -0.02785248,\n",
      "        -0.04345138,  0.04586312,  0.03695898, -0.04458623, -0.0363855 ,\n",
      "        -0.04920303, -0.03565622,  0.03326435, -0.03182829, -0.02521781,\n",
      "        -0.0451486 , -0.03310923,  0.02840078, -0.03834802, -0.03090052,\n",
      "         0.03243499, -0.03296187,  0.02852425,  0.03935575,  0.03037743,\n",
      "        -0.03997164, -0.04260697,  0.05269883,  0.04564125, -0.03714724,\n",
      "        -0.03639738,  0.04203265, -0.03346719, -0.02013652,  0.03864245,\n",
      "         0.03312178,  0.04537214, -0.04908135,  0.02937609, -0.05000057,\n",
      "        -0.04260861, -0.02220635, -0.04340187,  0.02070881,  0.02949729,\n",
      "         0.03115753, -0.04732328, -0.03261523, -0.03601486, -0.03986137,\n",
      "         0.00034476, -0.04436921,  0.03181918,  0.02922348,  0.01862773,\n",
      "         0.02568837,  0.02170558, -0.05115101, -0.02807437,  0.04283333,\n",
      "        -0.02611109, -0.04897524,  0.03634122,  0.04337177, -0.03355445,\n",
      "         0.04159738]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/key/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[-0.0163558 ,  0.02113008, -0.02819226, ..., -0.01763385,\n",
      "         -0.03031485, -0.02254849],\n",
      "        [-0.02015349,  0.01368298,  0.01614119, ...,  0.02063267,\n",
      "         -0.01967438,  0.02641001]],\n",
      "\n",
      "       [[ 0.05920943, -0.06397967,  0.0718611 , ...,  0.06688254,\n",
      "          0.0678198 ,  0.06852357],\n",
      "        [ 0.0652754 , -0.07416141, -0.05693625, ..., -0.06144203,\n",
      "          0.07231556, -0.07131074]],\n",
      "\n",
      "       [[ 0.02049868, -0.03589848,  0.04317589, ...,  0.0390839 ,\n",
      "          0.03837131,  0.03610978],\n",
      "        [ 0.01526725, -0.02913506, -0.02649205, ..., -0.02334173,\n",
      "          0.03717893, -0.03210832]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.02500228, -0.02344216,  0.02988864, ...,  0.03374323,\n",
      "          0.02629894,  0.04136233],\n",
      "        [ 0.03201025, -0.03299999, -0.03498842, ..., -0.0368381 ,\n",
      "          0.03927938, -0.03968996]],\n",
      "\n",
      "       [[-0.00923162,  0.00758881, -0.00344755, ...,  0.00359299,\n",
      "          0.00579724,  0.00513959],\n",
      "        [-0.01106552,  0.00284407, -0.00347166, ..., -0.00800859,\n",
      "          0.01339205, -0.00385493]],\n",
      "\n",
      "       [[-0.01677825,  0.02044402, -0.02174418, ..., -0.02765002,\n",
      "         -0.02347977, -0.01497619],\n",
      "        [-0.00200077,  0.01710631,  0.03240792, ...,  0.01238072,\n",
      "         -0.01996654,  0.01391469]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/key/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[-0.00296614,  0.00328179, -0.00311351, -0.00305993,  0.00324167,\n",
      "         0.00322456, -0.00355793,  0.00323171,  0.00305753, -0.00328503,\n",
      "        -0.00306523,  0.00343857, -0.00315125, -0.00299453,  0.00285192,\n",
      "        -0.00242088,  0.00169862, -0.00146194,  0.00358257,  0.0029882 ,\n",
      "        -0.00316042, -0.00305052, -0.00352744,  0.00312037, -0.00363843,\n",
      "         0.00300527,  0.00220229, -0.00316872, -0.00303772,  0.00346178,\n",
      "         0.0033637 , -0.003498  ,  0.00296164,  0.00287533, -0.00291991,\n",
      "         0.00293764,  0.00256269, -0.00313178, -0.00307718,  0.00338785,\n",
      "         0.00335036,  0.00344077,  0.00352039, -0.00269585,  0.00264486,\n",
      "        -0.00325216, -0.00326715,  0.00182913,  0.00314858,  0.0034719 ,\n",
      "         0.00318254, -0.00321431, -0.0023258 ,  0.0032167 , -0.00112219,\n",
      "        -0.00179439, -0.00299339,  0.00268697,  0.00330846,  0.00224623,\n",
      "         0.00328856,  0.00236501,  0.00311864,  0.00167454,  0.00312192,\n",
      "        -0.00356432,  0.00327322, -0.00203953, -0.0033577 ,  0.00353757,\n",
      "         0.00295247,  0.0032745 , -0.00323851, -0.00240234, -0.00359435,\n",
      "        -0.0033743 ,  0.00289233,  0.00196015,  0.00315043,  0.00335006,\n",
      "         0.00265779,  0.00336247, -0.0031174 , -0.0025159 ,  0.00338411,\n",
      "        -0.00301426,  0.0028412 , -0.00305678, -0.00365028,  0.00311089,\n",
      "        -0.00317544, -0.00238308,  0.00320493,  0.00289096,  0.00336777,\n",
      "         0.00323479,  0.0033856 , -0.00377705, -0.00349185, -0.00297761,\n",
      "        -0.0028034 ,  0.00228277,  0.00325711,  0.00344222,  0.00134814,\n",
      "         0.00259166,  0.00242039,  0.00283663, -0.00324799, -0.00303222,\n",
      "         0.00280234, -0.00369555, -0.00341163, -0.00256492, -0.00253456,\n",
      "         0.00344042, -0.00320574, -0.00367422, -0.0023816 ,  0.00314675,\n",
      "         0.00340056, -0.00345131, -0.00285676, -0.0026522 ,  0.00103076,\n",
      "        -0.00162384, -0.0034218 , -0.00333427, -0.00351141, -0.00284394,\n",
      "        -0.00343764, -0.0029226 ,  0.00358134,  0.00350582, -0.00323015,\n",
      "         0.00332878,  0.00248598, -0.00341487, -0.00262934,  0.00336315,\n",
      "        -0.00184152, -0.00326764,  0.0021956 ,  0.00207812, -0.00311659,\n",
      "         0.00165867, -0.00335889,  0.00336805,  0.00332028,  0.00288672,\n",
      "        -0.0031891 , -0.00181384, -0.00236893, -0.00319556, -0.00337916,\n",
      "         0.00346832,  0.00327042, -0.00342688,  0.00319322,  0.00363873,\n",
      "        -0.00326071, -0.00330154, -0.002951  , -0.0025074 , -0.00289919,\n",
      "         0.00332959,  0.00328518, -0.00329602, -0.00334872,  0.00324522,\n",
      "         0.00325116,  0.00361871,  0.00212602, -0.00287321, -0.0032798 ,\n",
      "         0.00322073, -0.00266896,  0.00299781,  0.00266325, -0.00292262,\n",
      "        -0.00315181, -0.00337648, -0.00332959,  0.00345984, -0.00285811,\n",
      "        -0.00234805,  0.00334515, -0.00341124,  0.00316434,  0.00327042,\n",
      "         0.003509  ,  0.00327778, -0.00339417, -0.00339317,  0.00287745,\n",
      "        -0.00355419,  0.00263941, -0.00254275,  0.00271622,  0.00337072,\n",
      "        -0.00313038, -0.00325792,  0.00302495, -0.00336345,  0.0030469 ,\n",
      "         0.00321757,  0.0034245 , -0.00315355, -0.00194622,  0.00292612,\n",
      "         0.00342614, -0.00336671,  0.00281836,  0.00341913, -0.00318467,\n",
      "        -0.00326471,  0.00297152, -0.00267889,  0.00342363, -0.00355013,\n",
      "        -0.00202085, -0.00329853,  0.0030009 ,  0.00288797,  0.00355406,\n",
      "         0.00310001,  0.0031127 , -0.0011899 , -0.00331753,  0.00241841,\n",
      "         0.00335827, -0.00323132,  0.00325976, -0.00301783, -0.00320521,\n",
      "        -0.00285024, -0.0031897 , -0.00309138, -0.00335765, -0.00336959,\n",
      "        -0.00213493,  0.00354804, -0.00336371, -0.00331977,  0.00349966,\n",
      "         0.00363427,  0.00277961, -0.00259343, -0.00267203,  0.00214848,\n",
      "         0.00309204,  0.00310035,  0.00312454, -0.00315721, -0.00330117,\n",
      "        -0.00310461],\n",
      "       [-0.00173277,  0.00280991,  0.00340049, -0.00268311,  0.00266342,\n",
      "         0.00202979, -0.00314429,  0.00260048, -0.00240211, -0.00281538,\n",
      "        -0.00273071, -0.00301906,  0.00277192, -0.00296287,  0.00261906,\n",
      "         0.00324033, -0.00323247,  0.00294784, -0.00220923,  0.00174745,\n",
      "        -0.00267684, -0.0028927 ,  0.00291726, -0.00214958,  0.00304379,\n",
      "        -0.00302537, -0.00176086,  0.00307362, -0.00288036, -0.00272758,\n",
      "         0.00202439,  0.00288083, -0.00141484, -0.00291635,  0.00304674,\n",
      "        -0.00320822,  0.00114963,  0.00298671,  0.00302505,  0.00269741,\n",
      "        -0.00230673, -0.00241376,  0.00193242,  0.00227562, -0.0026006 ,\n",
      "        -0.0027732 ,  0.00129649, -0.0031054 , -0.00265228,  0.00298598,\n",
      "         0.00251862, -0.001642  , -0.00305482, -0.00194254,  0.00324657,\n",
      "        -0.00081981,  0.00282434, -0.00298701, -0.00335183, -0.00301788,\n",
      "        -0.00283405,  0.00270972,  0.00255987, -0.00311179,  0.00292479,\n",
      "        -0.00269966, -0.00315363,  0.00260482,  0.00260419, -0.00269759,\n",
      "         0.00141406, -0.00275293, -0.00248224,  0.00323471,  0.00278359,\n",
      "        -0.00237357,  0.0024557 , -0.00157706,  0.00318409, -0.00149869,\n",
      "        -0.00326766,  0.00243343, -0.00323186,  0.00239079,  0.00265981,\n",
      "        -0.00258587, -0.00317028, -0.00292396,  0.00315166, -0.00341349,\n",
      "        -0.0034018 , -0.00307195, -0.00305566, -0.00317435, -0.001683  ,\n",
      "        -0.00271609,  0.00256473, -0.00177375, -0.00343384,  0.00262142,\n",
      "         0.0025954 , -0.00141411,  0.00270731,  0.00240494,  0.00324075,\n",
      "        -0.00283057,  0.00288735,  0.00248892, -0.00169161, -0.00186665,\n",
      "        -0.00264299, -0.00229334, -0.00301179,  0.00247136,  0.00336022,\n",
      "         0.0019636 , -0.00273688, -0.00291072,  0.00311896, -0.002884  ,\n",
      "        -0.00241562,  0.00233141, -0.00311141, -0.00256486,  0.00329932,\n",
      "        -0.00206077,  0.00269025,  0.00259136,  0.00280908, -0.00270435,\n",
      "         0.00172663,  0.00321518, -0.00232478, -0.00290123,  0.00301846,\n",
      "        -0.00314588, -0.00190517, -0.00232912,  0.00303369,  0.00298822,\n",
      "         0.00134322, -0.00310179, -0.00299672,  0.00307263, -0.00260376,\n",
      "        -0.00237029,  0.00285038, -0.00213817, -0.00307948, -0.00286822,\n",
      "        -0.0028608 , -0.00292438, -0.00244347,  0.00285831, -0.00210576,\n",
      "         0.0014416 ,  0.00298743,  0.00274246,  0.00213669, -0.0029777 ,\n",
      "         0.00323682, -0.00327968,  0.00288133,  0.00294313,  0.0029938 ,\n",
      "        -0.00306023,  0.00335853,  0.00349892,  0.00167948, -0.00253608,\n",
      "        -0.00261414,  0.00239126,  0.00321496, -0.00240678,  0.0015714 ,\n",
      "         0.00301312,  0.00297898, -0.00234792, -0.003339  , -0.00276847,\n",
      "         0.0027213 , -0.00258229, -0.0026886 , -0.00273761, -0.00212712,\n",
      "        -0.00159853,  0.00301787, -0.00281361,  0.00321923, -0.00251352,\n",
      "        -0.00149608, -0.00311243, -0.00234071,  0.00229672, -0.00320804,\n",
      "        -0.00164832,  0.0029742 ,  0.00305762, -0.0027812 , -0.00320899,\n",
      "        -0.0028473 , -0.00336481,  0.00259539, -0.00306092, -0.00242778,\n",
      "        -0.00296018, -0.00348343,  0.00285956, -0.0031034 , -0.00251552,\n",
      "         0.00133159, -0.00255592,  0.00293507,  0.00293982,  0.00304565,\n",
      "        -0.00348315, -0.00273271,  0.00286074,  0.00159231, -0.00292999,\n",
      "        -0.00319964,  0.00190025, -0.00242815, -0.00229316,  0.00278191,\n",
      "         0.00321769,  0.00283509, -0.00271851,  0.00159685, -0.00274166,\n",
      "        -0.00253937, -0.00276528, -0.00322196,  0.00226103,  0.00334276,\n",
      "         0.00278324, -0.00299641, -0.00263174, -0.00252582, -0.00241668,\n",
      "         0.00112595, -0.00285177,  0.00195329,  0.00136019,  0.00135096,\n",
      "         0.00173949,  0.00203741, -0.00287303, -0.00169058,  0.00249482,\n",
      "        -0.0026499 , -0.00307253,  0.00273452,  0.00276703, -0.00310683,\n",
      "         0.00300482]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/value/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[ 1.58231780e-02,  2.06253752e-02, -2.03112066e-02, ...,\n",
      "          4.80289198e-03, -1.45064713e-02, -1.62790413e-03],\n",
      "        [-1.03353756e-02,  5.10873133e-03, -7.13460939e-03, ...,\n",
      "          3.19308974e-03, -1.85090806e-02, -3.43274674e-03]],\n",
      "\n",
      "       [[-6.52530976e-03, -2.24473071e-03,  6.42174156e-03, ...,\n",
      "          1.52413733e-03,  1.78943034e-02,  7.14700145e-05],\n",
      "        [ 1.65799055e-02, -9.29789804e-03, -9.16608144e-03, ...,\n",
      "          1.40054356e-02,  2.43536406e-03,  3.03662918e-03]],\n",
      "\n",
      "       [[ 1.47383930e-02,  7.09437672e-03,  8.00635898e-04, ...,\n",
      "         -4.50727623e-03, -5.85464342e-03, -2.24212022e-03],\n",
      "        [-2.51701307e-02,  1.16783043e-03, -1.35660050e-02, ...,\n",
      "         -1.29860388e-02,  3.10187251e-03,  6.32349961e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-7.92050362e-03,  1.31866466e-02, -5.76815661e-03, ...,\n",
      "          2.45459117e-02,  6.28544344e-03, -2.92159314e-03],\n",
      "        [-3.28652328e-03, -1.21966256e-02,  1.26226814e-02, ...,\n",
      "         -7.97115080e-03,  6.88082119e-03, -2.00300477e-03]],\n",
      "\n",
      "       [[ 4.72976500e-03,  3.87651548e-02, -3.20375785e-02, ...,\n",
      "          5.33641949e-02, -2.70398352e-02,  8.68534204e-04],\n",
      "        [-1.60847278e-03,  1.40096415e-02,  8.55677575e-03, ...,\n",
      "          3.14758681e-02, -4.73995917e-02, -4.81592454e-02]],\n",
      "\n",
      "       [[ 2.32650172e-02,  3.91421877e-02, -2.27407850e-02, ...,\n",
      "          2.96137556e-02, -4.68664877e-02,  1.34114241e-02],\n",
      "        [-2.82497844e-03,  2.24890709e-02,  3.02115176e-02, ...,\n",
      "          4.37498130e-02, -4.49117683e-02, -6.42046928e-02]]],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/value/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[ 5.09578211e-04, -3.16463597e-03, -4.86382050e-03,\n",
      "         1.06221465e-02, -1.51814008e-03,  1.11538339e-02,\n",
      "         1.66601851e-03,  1.41501706e-02,  2.27079378e-04,\n",
      "         5.03608631e-03, -8.45201034e-03, -1.55545697e-02,\n",
      "        -4.93845809e-03,  1.24730123e-02,  6.55699708e-03,\n",
      "         2.10144673e-03,  6.43620826e-03,  1.11832311e-02,\n",
      "        -1.05753429e-02,  6.19104132e-03, -6.72271941e-04,\n",
      "        -1.38710474e-03,  6.83058845e-03, -6.76164171e-04,\n",
      "         3.85438814e-03,  6.33763522e-03,  1.16051733e-03,\n",
      "         4.08860389e-03, -9.63168498e-03, -1.25848977e-02,\n",
      "         1.09006241e-02,  2.67726574e-02, -1.79459918e-02,\n",
      "         2.05601449e-03, -2.47527193e-02, -6.96810614e-03,\n",
      "         2.05514929e-03,  9.46317101e-04, -7.60338444e-05,\n",
      "         5.32408524e-03,  1.30293919e-02,  4.06894134e-03,\n",
      "         1.56539753e-02, -1.24748703e-02, -1.42273623e-02,\n",
      "         3.13806511e-03,  8.79432261e-03, -1.68226205e-03,\n",
      "         2.01774831e-03, -6.26609055e-03, -9.74923652e-03,\n",
      "        -8.59466847e-03, -5.46555873e-03,  7.68990256e-04,\n",
      "         2.74611730e-03, -7.81429093e-03, -1.67840831e-02,\n",
      "        -1.37263967e-03,  1.52207203e-02,  9.54890437e-03,\n",
      "        -2.09495309e-03,  2.02337420e-03,  1.81457400e-02,\n",
      "        -6.09067176e-03,  3.55693488e-03, -1.54608237e-02,\n",
      "        -8.48558440e-04, -2.85580615e-03,  5.14885236e-04,\n",
      "        -3.84266488e-03, -5.54090366e-03, -1.44258479e-03,\n",
      "         9.78903472e-03, -4.34892997e-03,  1.21239887e-03,\n",
      "         2.36927019e-03,  2.14407407e-02, -2.41689151e-03,\n",
      "         1.67694706e-02, -7.28018233e-04,  2.99210940e-02,\n",
      "        -1.25271408e-02, -3.12095450e-04, -9.68744978e-03,\n",
      "         8.76542367e-03,  1.77297611e-02, -3.00400355e-03,\n",
      "        -1.83352958e-02,  2.16666739e-02,  1.32896332e-02,\n",
      "         1.38745029e-02, -2.29534181e-03,  1.18382489e-02,\n",
      "        -4.01820475e-03, -1.43904630e-02,  1.33097381e-03,\n",
      "         5.52329049e-03, -3.70653230e-03,  2.71564201e-02,\n",
      "         9.53217875e-03, -2.68996391e-03, -1.80641795e-03,\n",
      "        -1.07073057e-02, -6.07997179e-03, -1.46994554e-02,\n",
      "         1.15983067e-02, -4.54174995e-04,  9.83387791e-03,\n",
      "        -1.35309659e-02, -1.19445780e-02,  1.47062130e-02,\n",
      "        -8.21506663e-04,  4.65313066e-03, -1.06484806e-02,\n",
      "        -1.76660400e-02,  8.51594436e-04,  6.42222213e-03,\n",
      "        -1.61636584e-02,  4.25268168e-04,  1.35643268e-02,\n",
      "         1.55605725e-03, -1.13705108e-02,  8.65811948e-03,\n",
      "         9.76673886e-03,  4.85384557e-03,  1.08422553e-02,\n",
      "        -2.82810954e-03, -9.35432594e-03,  3.49811791e-03,\n",
      "         1.87941757e-03, -2.01866217e-03, -5.37717296e-03,\n",
      "         1.07360613e-02, -2.53408030e-03,  1.10323466e-02,\n",
      "         1.86709594e-02, -5.96782798e-03, -2.64854245e-02,\n",
      "         1.38034782e-04,  1.10732820e-02,  1.27540231e-02,\n",
      "        -6.70562312e-03,  6.13368349e-03,  1.38787525e-02,\n",
      "        -2.46745511e-03,  2.16941582e-03, -1.02028623e-02,\n",
      "         4.58062999e-03,  6.12802338e-04, -1.67481485e-03,\n",
      "         9.87453386e-03, -1.22959195e-02,  1.19868107e-02,\n",
      "        -1.17370216e-02, -2.61220208e-04,  2.64472291e-02,\n",
      "        -9.27104987e-03, -2.63622729e-03,  1.63115207e-02,\n",
      "        -5.07643353e-03, -1.26693621e-02,  6.90549379e-03,\n",
      "        -4.60971380e-03,  1.13927899e-03,  5.21560153e-03,\n",
      "        -2.23878212e-03,  1.54865896e-02,  1.53173218e-02,\n",
      "         3.21807079e-02,  2.73131747e-02,  5.27291140e-03,\n",
      "         1.20795155e-02,  5.52855665e-03,  1.47735071e-03,\n",
      "         6.02286635e-03,  2.08035260e-02, -2.04140395e-02,\n",
      "         1.88130401e-02,  2.09286045e-02, -5.45623386e-03,\n",
      "        -5.22007421e-03, -8.56028311e-03, -1.19684720e-02,\n",
      "        -1.96585301e-02, -2.29685451e-03, -1.16182258e-03,\n",
      "         9.58769210e-03, -1.64241099e-03,  2.07937416e-03,\n",
      "         1.00445491e-03,  3.60230776e-03, -2.49098055e-03,\n",
      "        -9.70187690e-03, -1.59893669e-02,  1.02773160e-02,\n",
      "        -6.53125625e-03, -1.03611788e-02,  2.17225240e-03,\n",
      "         7.21836230e-03,  3.28682479e-04,  9.35674470e-04,\n",
      "         4.82122356e-04, -7.01429928e-03,  1.15457166e-04,\n",
      "        -3.08510195e-03, -2.38760859e-02, -2.61399802e-02,\n",
      "         8.90637457e-04,  8.92016664e-03, -1.72187621e-03,\n",
      "        -6.41259539e-04, -1.50792561e-02, -6.83070952e-03,\n",
      "        -3.63480859e-03,  2.31664367e-02, -2.04397030e-02,\n",
      "         4.42659296e-03,  2.97902012e-03,  2.19751112e-02,\n",
      "         1.64849497e-02,  8.81763175e-03, -3.36781633e-03,\n",
      "        -7.06400583e-03, -6.81803329e-04,  2.46420357e-04,\n",
      "         4.72229626e-03, -8.82371503e-04, -1.41182018e-03,\n",
      "        -2.81982531e-04,  8.70908704e-03,  9.09015257e-03,\n",
      "         1.84856239e-03, -1.11902058e-02,  1.20508187e-02,\n",
      "        -4.10619145e-03, -6.45806734e-03,  1.17158815e-02,\n",
      "        -6.55647076e-04,  4.65482380e-03, -1.88706238e-02,\n",
      "        -1.78532563e-02,  9.03567113e-03,  9.98036121e-04,\n",
      "        -2.22792733e-03,  6.00221148e-03,  4.29329975e-03,\n",
      "        -8.14557262e-03, -1.17258877e-02,  7.95917877e-04,\n",
      "        -1.12041002e-02, -1.03606032e-02, -1.02581307e-02,\n",
      "        -4.60008252e-03, -5.93332900e-03, -3.61033424e-04,\n",
      "        -1.61412172e-02],\n",
      "       [-1.84480585e-02,  3.99503112e-03,  5.75732673e-03,\n",
      "        -2.45799730e-03, -7.66753312e-03,  1.21487798e-02,\n",
      "        -1.19769135e-02, -2.47561256e-03, -5.73020661e-03,\n",
      "        -6.30509015e-03, -1.79959123e-03,  3.75137897e-03,\n",
      "        -3.75999231e-03,  3.42640420e-03,  1.71861984e-03,\n",
      "         6.09301729e-03,  2.69442028e-03,  3.08843702e-03,\n",
      "         3.60511988e-03, -3.79624614e-03, -1.11905038e-02,\n",
      "         6.29402418e-03,  7.69999530e-03, -1.92900316e-03,\n",
      "         2.06880588e-02, -1.02986638e-02,  2.51069944e-03,\n",
      "         6.21789834e-03, -5.37664117e-03,  2.81295925e-03,\n",
      "        -1.56952199e-02,  1.86802034e-04,  2.98841717e-03,\n",
      "        -1.93640532e-03, -1.18531764e-03, -1.96844582e-02,\n",
      "        -1.53857721e-02, -9.02806781e-03,  3.35435057e-03,\n",
      "        -1.44878980e-02,  1.14633525e-02,  2.26405496e-03,\n",
      "        -1.61600355e-02, -4.60390234e-03,  1.15564680e-02,\n",
      "        -1.84403453e-02, -1.77856274e-02,  1.61996447e-02,\n",
      "         1.27322957e-04,  7.18991412e-03, -1.39542129e-02,\n",
      "        -9.34650097e-03,  1.23193972e-02,  4.75996034e-03,\n",
      "         1.13979988e-02, -4.30862157e-04, -1.84439681e-03,\n",
      "         1.05689531e-02, -3.48602198e-02, -6.90990547e-03,\n",
      "         2.98902066e-03, -9.68415104e-03, -1.64893456e-02,\n",
      "         1.10917753e-02, -5.61637152e-03,  1.61908586e-02,\n",
      "        -7.32226856e-03,  8.96839076e-04,  2.39971280e-02,\n",
      "         1.18522272e-02, -2.06131898e-02,  3.43235512e-03,\n",
      "         1.62793929e-03, -6.58894982e-03,  2.88392534e-03,\n",
      "         1.41783589e-02, -7.42867123e-03,  1.84877440e-02,\n",
      "        -2.28773728e-02, -2.46979184e-02, -2.71241106e-02,\n",
      "         9.82504990e-03, -1.14932237e-03,  5.51661104e-03,\n",
      "        -2.36037769e-03,  3.54156108e-03,  9.82593838e-03,\n",
      "         7.32230546e-04,  3.01710684e-02,  1.90935342e-03,\n",
      "        -5.87313343e-03,  4.47302038e-04,  1.15935295e-03,\n",
      "         1.70170609e-02,  7.25730183e-03, -6.48570666e-03,\n",
      "         1.27139105e-03,  1.01239793e-02,  6.50682999e-03,\n",
      "        -1.11234011e-02,  9.79818031e-03, -6.31931191e-03,\n",
      "        -3.51247727e-03,  7.44681479e-03, -1.12000275e-02,\n",
      "        -5.16012963e-03,  9.06068459e-03,  3.66442109e-04,\n",
      "        -1.23824459e-02, -1.16158221e-02, -6.47776481e-03,\n",
      "        -4.91482858e-03, -1.90819474e-03,  6.48476882e-03,\n",
      "        -5.66277094e-03, -1.15444520e-02, -1.66917983e-02,\n",
      "         8.66381393e-04,  1.51684973e-02,  1.06035769e-02,\n",
      "        -4.36939346e-03, -1.39649184e-02,  1.50727089e-02,\n",
      "        -1.23967547e-02, -1.62545424e-02,  1.43675981e-02,\n",
      "        -7.72251841e-03,  6.99484441e-03,  2.69531775e-02,\n",
      "        -5.81194833e-03, -4.79921000e-03,  1.44561650e-02,\n",
      "        -5.00229246e-04, -3.74648720e-03,  9.96805541e-03,\n",
      "         1.59386937e-02, -3.27245635e-03, -1.07470434e-02,\n",
      "        -4.61456971e-03, -2.11756397e-02,  1.87001619e-02,\n",
      "        -3.58210783e-03,  8.68434552e-04, -1.25789065e-02,\n",
      "         7.53388507e-03,  3.06640333e-03, -7.72357034e-03,\n",
      "         9.81397554e-03, -1.12719312e-02,  2.47230362e-02,\n",
      "         1.89790428e-02,  1.76443160e-02, -3.26933898e-03,\n",
      "        -7.02107418e-03,  2.89930496e-03, -5.63467154e-03,\n",
      "         6.36897376e-03,  5.65457158e-03,  1.13335287e-03,\n",
      "        -2.70688720e-02, -1.01132169e-02, -1.48794269e-02,\n",
      "        -1.96322817e-02,  1.13854744e-03, -6.54208299e-04,\n",
      "        -8.93869787e-04,  1.84179954e-02,  2.75325924e-02,\n",
      "        -7.45962607e-03, -5.24156913e-03, -1.43477740e-02,\n",
      "        -1.18777086e-03,  2.72323121e-03,  5.55946957e-04,\n",
      "         1.72808545e-03, -4.60482715e-03,  1.72436349e-02,\n",
      "        -7.97508284e-03,  3.31731699e-03,  9.66351666e-03,\n",
      "        -9.79881547e-03,  5.00299968e-04, -6.15444267e-03,\n",
      "        -8.70108511e-03,  5.11784898e-03,  2.47631135e-04,\n",
      "        -5.68258623e-03,  1.62841715e-02, -2.96623148e-02,\n",
      "         9.70272347e-03,  1.27268145e-02, -1.58687700e-02,\n",
      "        -2.67803529e-03,  5.60578005e-03,  8.46063718e-03,\n",
      "         3.98575561e-03, -6.74147066e-03,  2.57908422e-02,\n",
      "         2.43708957e-02, -5.14138583e-03, -4.99708904e-03,\n",
      "         7.05370156e-04,  8.20077397e-03,  2.33754087e-02,\n",
      "        -3.14467726e-03,  1.65740810e-02, -2.55393572e-02,\n",
      "         2.37432569e-02, -9.93052032e-04,  3.48938140e-03,\n",
      "        -6.51311548e-03,  8.24976154e-03,  1.29108764e-02,\n",
      "         3.55979265e-03, -1.64012914e-03, -2.43356116e-02,\n",
      "         2.56891665e-03, -3.29332496e-03,  1.56114064e-02,\n",
      "        -5.23038255e-03,  1.73126571e-02,  5.80588356e-04,\n",
      "         2.08606059e-03,  1.24436663e-02, -8.84549110e-04,\n",
      "         6.81511452e-03, -4.82721534e-03,  4.23534773e-03,\n",
      "         5.49248047e-03, -1.25958503e-03, -1.83828399e-02,\n",
      "         4.69922926e-03,  1.07353693e-02,  1.16467951e-02,\n",
      "        -1.59107372e-02,  3.47550679e-03, -2.70574994e-04,\n",
      "         1.14203664e-03, -3.64680123e-03,  2.38897395e-03,\n",
      "         1.08736539e-02,  1.13535263e-02, -5.42399706e-03,\n",
      "        -1.94818545e-02,  1.87356248e-02,  1.08782705e-02,\n",
      "         2.05341028e-03, -2.94825644e-03,  1.80975604e-03,\n",
      "        -1.63339805e-02,  3.57652456e-03, -5.79940667e-03,\n",
      "        -1.87860150e-02, -3.70043935e-03,  2.03599664e-03,\n",
      "         6.23114686e-03]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/attention_output/kernel:0' shape=(2, 256, 256) dtype=float32, numpy=\n",
      "array([[[-0.02857796, -0.00041194, -0.01411509, ...,  0.06240053,\n",
      "          0.07967914,  0.03411998],\n",
      "        [ 0.0071319 , -0.046831  ,  0.02428792, ..., -0.0650846 ,\n",
      "          0.02147296,  0.06058642],\n",
      "        [-0.02636665, -0.03921273, -0.13291481, ..., -0.06017832,\n",
      "         -0.02405857, -0.00847109],\n",
      "        ...,\n",
      "        [-0.06853335,  0.05146891,  0.01458639, ...,  0.00692671,\n",
      "         -0.02166597,  0.02279169],\n",
      "        [ 0.05885595,  0.03194395, -0.07482035, ..., -0.08037979,\n",
      "          0.02135783, -0.0762539 ],\n",
      "        [ 0.01125119,  0.05792256, -0.01929352, ..., -0.00505582,\n",
      "          0.06285026, -0.05680688]],\n",
      "\n",
      "       [[ 0.049975  , -0.00015932, -0.14319837, ..., -0.12291076,\n",
      "          0.01164846, -0.02378286],\n",
      "        [-0.07679999, -0.00486536, -0.01643644, ...,  0.06408649,\n",
      "         -0.05922979, -0.0194917 ],\n",
      "        [ 0.03723655, -0.00547399,  0.08617636, ...,  0.08812966,\n",
      "          0.0433915 ,  0.02625931],\n",
      "        ...,\n",
      "        [-0.05514643,  0.03165463, -0.00613327, ..., -0.00415933,\n",
      "          0.02799386,  0.07487848],\n",
      "        [-0.01898648, -0.09662006, -0.07955515, ...,  0.02295411,\n",
      "         -0.01120021, -0.08959356],\n",
      "        [-0.01188129,  0.03418023,  0.079979  , ...,  0.07386066,\n",
      "         -0.09046787, -0.07077741]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/attention_output/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-7.53352279e-03,  8.27032235e-03,  4.46640328e-02, -1.01185516e-02,\n",
      "        2.87417639e-02,  4.18379717e-03,  4.27355291e-03, -1.08154686e-02,\n",
      "       -1.00473175e-02, -1.09925987e-02, -6.33303029e-03, -1.02011207e-02,\n",
      "       -5.15943673e-03,  4.19780007e-03,  1.96345840e-02, -5.48039330e-04,\n",
      "       -1.10564660e-02, -6.13216544e-03,  7.41236331e-03, -2.13252064e-02,\n",
      "       -7.82342814e-03,  8.28777533e-03, -3.61035788e-03,  2.17000488e-02,\n",
      "       -5.73488465e-03,  4.05578651e-02, -8.51419568e-03,  1.54436631e-02,\n",
      "       -1.06223277e-03,  1.89799024e-03, -1.21467952e-02,  4.44468372e-02,\n",
      "       -2.09296634e-03,  6.96721626e-03, -9.22863558e-03, -5.10269543e-03,\n",
      "        2.50202254e-04,  2.12196750e-03, -1.49268853e-02, -4.94562648e-03,\n",
      "        2.09344248e-03,  4.42910008e-03, -6.12153625e-03, -2.01341249e-02,\n",
      "        3.20917764e-03, -1.88671960e-03,  2.92604603e-02, -1.56235637e-03,\n",
      "       -7.88201485e-03, -5.74616250e-03, -5.50566567e-03,  4.39089350e-03,\n",
      "        1.19106669e-03, -6.29491289e-04, -1.29967853e-02,  1.72496936e-03,\n",
      "        4.00937647e-02, -4.85184509e-03,  6.95213675e-03, -8.41224391e-07,\n",
      "        4.28678328e-03,  1.99667253e-02, -3.42073361e-03,  1.42314304e-02,\n",
      "       -4.82653687e-03,  1.30715780e-02,  1.05937803e-03, -5.96229080e-03,\n",
      "        7.93696661e-03,  2.58435588e-03,  3.20156664e-02,  3.98917869e-03,\n",
      "        4.79322346e-03, -4.85570123e-03,  6.00644969e-04,  3.05927498e-03,\n",
      "        8.65813065e-03,  1.96511252e-03,  1.14345318e-02,  9.29705519e-03,\n",
      "       -5.90162212e-03, -3.12515534e-02, -9.53906216e-03,  6.99755875e-03,\n",
      "       -4.99727065e-03,  2.82140309e-03, -1.20888813e-03,  1.60384122e-02,\n",
      "       -7.76421092e-03,  1.45084239e-04, -3.80354235e-03, -5.08094672e-03,\n",
      "       -6.30074786e-03,  1.73189938e-02,  3.21151386e-03,  1.58981793e-02,\n",
      "        2.96736136e-02,  4.67443839e-02,  1.18690357e-02,  4.02969588e-03,\n",
      "       -7.73642212e-03,  5.72201721e-02,  7.87543785e-03, -7.44976057e-03,\n",
      "       -2.27967626e-03, -1.67617912e-03, -8.69218912e-03, -1.79969030e-03,\n",
      "        1.22964592e-03,  1.50927333e-02, -2.70213792e-03, -5.32253832e-03,\n",
      "        5.47238858e-03, -5.76152932e-03,  7.54797249e-04, -1.03506427e-02,\n",
      "       -2.50998535e-03,  3.43516911e-03, -1.29553266e-02, -7.17971288e-03,\n",
      "        1.63735151e-02,  5.80978766e-02, -1.09572138e-03,  2.09540944e-03,\n",
      "        7.00371398e-04,  2.44658776e-02,  2.77007255e-03, -2.33319774e-03,\n",
      "       -5.83649799e-03, -1.99222006e-03, -5.05851931e-04, -5.34915773e-04,\n",
      "       -1.83616614e-03,  8.35882965e-03,  1.50419015e-03, -5.01368567e-03,\n",
      "       -2.25852965e-03, -2.72456487e-03, -4.10475675e-03, -6.33197790e-03,\n",
      "       -6.95318449e-04,  2.52852985e-03,  1.06669394e-02,  1.05458573e-02,\n",
      "        4.76390676e-04,  3.78014408e-02,  3.43540596e-04, -1.83774047e-02,\n",
      "        2.87908353e-02, -1.81191992e-02,  1.56412981e-02, -4.04694956e-03,\n",
      "       -1.66072999e-03, -6.54709199e-03,  3.58466841e-02, -4.18783212e-03,\n",
      "       -4.69476962e-03, -8.08280800e-03,  1.77837966e-03,  1.30729619e-02,\n",
      "       -6.94608456e-03,  1.45050511e-02, -7.10350170e-04, -2.99005071e-03,\n",
      "       -5.42004639e-03, -4.31381341e-04,  5.73166739e-03, -5.05272159e-03,\n",
      "        4.83481353e-03,  3.17919790e-03, -2.61698081e-03,  4.61883144e-03,\n",
      "       -4.56935866e-03,  6.21308014e-03,  3.21567990e-04,  4.74795792e-03,\n",
      "        9.00261002e-05,  1.81642681e-04, -6.98612398e-03,  8.02003592e-03,\n",
      "        3.79790249e-03,  4.53801267e-03, -2.39015138e-03, -2.27356097e-03,\n",
      "       -3.24190158e-04,  1.64790289e-03,  4.09978740e-02, -1.09667741e-02,\n",
      "       -7.03050056e-03,  4.19741450e-03, -1.96054787e-03, -7.25146569e-03,\n",
      "        5.14096469e-02,  1.43799661e-02, -3.18354033e-02,  1.26356469e-03,\n",
      "       -5.11820428e-03,  1.54525237e-02, -6.42223237e-03,  7.55700516e-03,\n",
      "        1.06625399e-02,  4.75433283e-03,  5.15265344e-03,  1.68411632e-03,\n",
      "       -3.77421849e-03, -5.36855822e-03, -3.72477737e-03,  6.34506298e-03,\n",
      "        6.72840187e-03, -2.04691384e-03, -5.39892726e-03, -2.56199599e-03,\n",
      "        2.90415678e-02, -2.92372406e-02, -6.28585462e-03, -3.30406800e-03,\n",
      "        5.79264062e-03,  2.11188849e-02, -6.72325352e-03,  4.31023166e-03,\n",
      "       -2.48346548e-03, -1.21976109e-03,  3.74291255e-03, -9.06354003e-03,\n",
      "       -8.63022986e-04, -2.64283991e-03, -4.29484854e-03,  7.32500013e-03,\n",
      "        4.69035320e-02, -1.95690617e-03,  1.30772861e-02,  4.37021209e-03,\n",
      "       -7.76153244e-03, -2.27168053e-02, -3.35787470e-03, -4.60730540e-03,\n",
      "        6.31575612e-03,  3.87643208e-03, -3.40402056e-03, -5.77553967e-03,\n",
      "       -1.19058983e-02, -6.54914510e-03,  1.43153011e-03,  3.15781659e-03,\n",
      "        1.49144686e-03, -2.48203706e-03, -5.72119327e-03,  4.67769423e-04,\n",
      "       -4.40177601e-03, -2.15143189e-02,  3.08038876e-03, -6.25611341e-04,\n",
      "       -9.07631125e-03,  3.55568826e-02, -4.46531316e-03, -2.57601333e-03],\n",
      "      dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(256, 32) dtype=float32, numpy=\n",
      "array([[-0.03633049, -0.03204968, -0.10271911, ...,  0.02649385,\n",
      "        -0.04720194,  0.08797648],\n",
      "       [ 0.11573762, -0.04067804,  0.04013691, ..., -0.01598223,\n",
      "         0.08783187, -0.14261697],\n",
      "       [-0.00621237,  0.11050386,  0.00381321, ...,  0.06765676,\n",
      "         0.08194723,  0.0920223 ],\n",
      "       ...,\n",
      "       [-0.05217152,  0.05946878, -0.07055626, ..., -0.04051173,\n",
      "        -0.00081448, -0.01260424],\n",
      "       [ 0.07442758, -0.1346241 , -0.02522461, ...,  0.04650578,\n",
      "         0.12783904,  0.02992305],\n",
      "       [-0.06135168, -0.00574253,  0.03607664, ..., -0.09953886,\n",
      "        -0.08526678,  0.0997579 ]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([-0.00340474,  0.00205084, -0.01452733, -0.00184541, -0.00557164,\n",
      "        0.00163701,  0.01714049, -0.00445197,  0.00029329, -0.01502358,\n",
      "       -0.0097656 , -0.00453271,  0.00966224,  0.01937813, -0.00300124,\n",
      "       -0.00840612,  0.00670207,  0.00220081, -0.01373656, -0.01350116,\n",
      "       -0.00709196,  0.02052045, -0.00723019,  0.01887392,  0.02552342,\n",
      "       -0.00327214, -0.00074156, -0.01895425,  0.02120522,  0.00262756,\n",
      "       -0.0102284 , -0.0121283 ], dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(32, 256) dtype=float32, numpy=\n",
      "array([[-0.08295918, -0.02490737,  0.15595892, ..., -0.09644476,\n",
      "         0.09638882,  0.13900582],\n",
      "       [-0.15689386, -0.05120059,  0.1426452 , ...,  0.0542042 ,\n",
      "        -0.08131795, -0.09370283],\n",
      "       [-0.10396218,  0.11983861,  0.18653278, ..., -0.02007509,\n",
      "         0.00228966, -0.14037368],\n",
      "       ...,\n",
      "       [-0.14494534, -0.01794294,  0.2517903 , ...,  0.0034884 ,\n",
      "        -0.04785762, -0.00408625],\n",
      "       [-0.13135238,  0.07462022, -0.04182281, ..., -0.01430637,\n",
      "         0.05159739,  0.05303623],\n",
      "       [-0.07102   ,  0.10775707, -0.06656287, ...,  0.00661632,\n",
      "         0.09473777,  0.10023817]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-2.24392973e-02,  6.82915142e-03,  9.30611268e-02,  8.47462192e-03,\n",
      "        1.05431989e-01, -2.34965608e-03,  6.64173486e-03, -7.69779179e-03,\n",
      "       -1.22130103e-02, -7.11461203e-03, -6.02092408e-03, -3.39537207e-03,\n",
      "       -1.63004491e-02,  1.98759953e-03,  7.35260248e-02, -7.48512242e-03,\n",
      "       -1.25036081e-02, -9.40930471e-03,  1.71051510e-02, -4.89431713e-03,\n",
      "       -1.48007758e-02,  1.42496778e-02, -9.00123548e-03,  1.15249522e-01,\n",
      "       -8.79917294e-03,  9.23147872e-02, -1.09413974e-02,  2.10712850e-02,\n",
      "       -1.26926135e-03,  1.68151874e-02, -8.44683591e-03,  6.68633282e-02,\n",
      "        2.64480431e-03,  4.72393110e-02,  1.18745212e-02, -8.14637914e-03,\n",
      "        9.94606316e-03,  9.85636259e-04, -1.90964006e-02, -4.74886689e-03,\n",
      "        6.02351315e-03, -3.28089250e-03, -9.29269940e-03, -1.87833197e-02,\n",
      "        3.45920469e-03, -8.67675059e-03,  4.46650498e-02, -1.54184876e-04,\n",
      "       -1.16528748e-02, -1.60551146e-02, -1.61478091e-02,  8.89015011e-03,\n",
      "       -9.42111597e-04, -1.58051755e-02, -2.85760593e-03, -2.09556194e-03,\n",
      "        7.03626797e-02,  5.35397441e-04,  1.93440809e-03,  1.42718675e-02,\n",
      "        1.16061112e-02,  6.98377937e-02, -1.30072776e-02,  1.63237508e-02,\n",
      "       -6.60502061e-04,  2.22962014e-02,  6.92613050e-03, -1.23321842e-02,\n",
      "        7.06536649e-03,  2.71103709e-05,  8.95989984e-02,  4.76559903e-03,\n",
      "       -2.31359643e-03,  3.48665263e-03, -3.78076173e-03,  1.91891957e-02,\n",
      "        4.84399796e-02, -2.90781911e-03,  2.74450202e-02,  5.01065813e-02,\n",
      "       -4.79958998e-03, -1.43231940e-03, -1.44904025e-03,  9.43277701e-06,\n",
      "       -1.43219884e-02, -3.76976700e-03, -7.44910212e-03,  8.41410160e-02,\n",
      "       -1.47812981e-02,  6.20595319e-03, -6.88204076e-03, -9.83825047e-03,\n",
      "       -1.49314143e-02,  2.40872148e-02,  4.25773766e-03,  7.82680288e-02,\n",
      "        4.03081700e-02,  8.20800513e-02,  1.13824932e-02,  3.51614202e-03,\n",
      "       -1.73898914e-03,  1.01773091e-01,  6.24409504e-02, -9.06387623e-03,\n",
      "       -2.96682538e-03, -4.39631724e-04, -7.01351417e-03,  1.02870017e-02,\n",
      "        2.81840190e-03,  1.65753271e-02, -1.06820874e-02, -3.25351022e-03,\n",
      "        6.85654860e-03,  8.78125988e-03, -1.33741542e-03, -2.02566367e-02,\n",
      "       -1.18270498e-02,  2.34185834e-03, -1.16204405e-02, -8.68586544e-03,\n",
      "        1.43796662e-02,  1.17814757e-01,  1.13796890e-02, -7.39097130e-04,\n",
      "        3.61551419e-02,  1.36180287e-02,  6.01724302e-03, -5.51206619e-03,\n",
      "       -5.62572200e-03,  5.50716184e-03,  1.77423109e-03, -4.89429152e-03,\n",
      "        1.32559100e-03,  9.99993552e-03, -4.74076206e-03, -6.43988256e-04,\n",
      "        5.80940489e-03, -5.17848926e-03, -8.45550909e-04, -7.65984133e-03,\n",
      "        5.62103046e-03,  5.57702221e-03,  1.40475249e-02,  2.18465123e-02,\n",
      "       -6.92266272e-03,  7.08856434e-02, -5.47398999e-03, -1.90621894e-02,\n",
      "        4.31628600e-02, -2.31560282e-02,  3.15804929e-02, -1.23738172e-03,\n",
      "       -3.30053712e-03, -9.71245114e-03,  8.19127336e-02, -9.00718942e-03,\n",
      "        5.54771256e-03, -3.25957825e-03,  3.09005752e-03,  3.81019786e-02,\n",
      "       -1.03141442e-02,  3.45588550e-02, -9.69428662e-03, -1.27693098e-02,\n",
      "        8.47161282e-03,  1.68390367e-02,  1.64949917e-03,  1.69639511e-03,\n",
      "       -5.47720410e-04,  3.24105751e-03, -6.36622123e-03,  4.74029826e-03,\n",
      "       -1.06715690e-02, -5.99553459e-04, -3.96312447e-03,  5.85775531e-04,\n",
      "        2.75350409e-03, -1.26756392e-02, -1.24474559e-02, -3.00985621e-03,\n",
      "        6.67674094e-02,  1.28180068e-02, -4.52881306e-03, -1.22042065e-02,\n",
      "        1.97666185e-03, -5.17039699e-03,  6.37231767e-02, -1.66141633e-02,\n",
      "       -5.57151949e-03,  3.60828638e-02,  3.39128985e-03, -1.30798016e-02,\n",
      "        9.70189199e-02,  8.49152077e-03, -4.57155481e-02,  1.54060966e-04,\n",
      "       -5.36107225e-03,  9.31465700e-02, -2.45895260e-03,  9.75916162e-04,\n",
      "        1.54852672e-02,  1.72278453e-02, -3.58749996e-03, -2.08645221e-03,\n",
      "       -1.01065068e-02, -7.98033644e-03,  2.51446781e-03,  5.30969864e-03,\n",
      "        6.98372163e-03, -7.71170855e-03, -7.14766467e-03,  7.80509668e-04,\n",
      "        8.82591233e-02, -4.45761718e-02,  2.75524938e-03, -5.09641087e-03,\n",
      "        4.03668266e-03,  2.16684882e-02, -2.07626354e-02,  5.34531474e-03,\n",
      "       -2.73268227e-03, -2.91260099e-03,  3.42084630e-03, -1.40596563e-02,\n",
      "       -5.59497532e-03,  5.79780014e-03, -1.12970201e-02,  1.16500948e-02,\n",
      "        9.21003520e-02,  1.87517665e-02,  7.10626841e-02,  3.43714207e-02,\n",
      "       -1.31541686e-02, -3.21544372e-02, -1.54061923e-02, -1.00561352e-02,\n",
      "        1.86628085e-02,  1.40588032e-02, -7.20239291e-03, -1.83478277e-02,\n",
      "       -1.26148239e-02, -2.61662412e-03,  8.47731344e-03,  1.20194476e-04,\n",
      "        8.04844545e-04, -1.54543743e-02, -6.67556934e-03,  3.88188777e-03,\n",
      "       -2.52321386e-03, -1.56179089e-02,  4.18749191e-02, -1.42577197e-03,\n",
      "       -5.13420673e-03,  3.18646692e-02,  3.71506740e-03,  8.43270100e-04],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0.9825788 , 1.006423  , 1.0832365 , 1.0192192 , 1.044077  ,\n",
      "       0.9978604 , 0.99847156, 0.9958319 , 1.001537  , 0.9931866 ,\n",
      "       0.9932974 , 0.99293685, 1.0019149 , 0.99747205, 1.0147071 ,\n",
      "       0.99040663, 1.02131   , 0.9988445 , 1.0039991 , 1.0145385 ,\n",
      "       0.98317754, 0.9947525 , 0.9939026 , 1.0423427 , 0.9940943 ,\n",
      "       1.0781606 , 0.9895751 , 1.0064054 , 0.9980771 , 1.0095235 ,\n",
      "       1.0088598 , 1.0546713 , 0.99230254, 1.0106784 , 0.9988941 ,\n",
      "       0.99201065, 1.0051134 , 0.9940341 , 0.9914461 , 1.0024743 ,\n",
      "       1.0162532 , 0.99634427, 0.99191236, 1.0014752 , 0.9943121 ,\n",
      "       0.9919932 , 1.0201626 , 1.0046014 , 0.9902432 , 0.9903836 ,\n",
      "       0.99298924, 0.9973498 , 0.994449  , 0.9905776 , 0.99949586,\n",
      "       1.0003346 , 1.0589198 , 0.9991202 , 1.0028303 , 1.0154582 ,\n",
      "       1.0053335 , 1.0396832 , 0.99147534, 0.99725085, 0.9947873 ,\n",
      "       1.0039195 , 1.0019404 , 0.99763465, 1.0096157 , 0.9992602 ,\n",
      "       1.0784539 , 1.0058303 , 0.99599963, 0.9985271 , 0.99713135,\n",
      "       1.0036051 , 1.0107244 , 0.9911579 , 1.0049717 , 1.0357562 ,\n",
      "       0.9948454 , 1.0150617 , 0.99850374, 0.99779135, 0.98518294,\n",
      "       0.9945879 , 0.9948778 , 1.0063818 , 0.9998375 , 1.0024205 ,\n",
      "       0.992144  , 1.0085815 , 0.98900425, 1.0039135 , 1.0114471 ,\n",
      "       1.014732  , 1.0234762 , 1.0636706 , 1.0016859 , 0.9999857 ,\n",
      "       0.9937338 , 1.0993319 , 1.0268096 , 0.9816634 , 0.99793375,\n",
      "       0.9981228 , 0.99310654, 1.007092  , 1.0060397 , 1.0088323 ,\n",
      "       0.98924214, 0.9952407 , 1.0011774 , 0.9968021 , 0.99690807,\n",
      "       0.99319756, 0.9918308 , 0.9924759 , 0.9879307 , 0.9906247 ,\n",
      "       1.0040547 , 1.1101874 , 1.004527  , 1.0053118 , 1.0131046 ,\n",
      "       1.01861   , 1.0120282 , 0.9924493 , 0.99843496, 0.9954387 ,\n",
      "       1.0029489 , 0.9907014 , 0.9974383 , 0.9997806 , 0.9982255 ,\n",
      "       0.9929721 , 1.0048977 , 0.99758655, 1.0016174 , 0.9978288 ,\n",
      "       1.0190122 , 1.0029284 , 1.0030273 , 1.0078655 , 0.99553996,\n",
      "       1.0567062 , 0.9917279 , 0.99797136, 1.019096  , 1.0211734 ,\n",
      "       1.0006983 , 1.0034893 , 1.000379  , 0.9956946 , 1.0596983 ,\n",
      "       0.98976934, 0.9938087 , 0.99052984, 1.000289  , 1.0073664 ,\n",
      "       0.9843725 , 1.0251286 , 0.9813837 , 0.9830701 , 1.023833  ,\n",
      "       1.0095308 , 0.99742556, 0.9952567 , 0.998701  , 0.99601436,\n",
      "       0.9963583 , 0.9973271 , 0.9917284 , 1.0007257 , 0.99906117,\n",
      "       1.0027599 , 1.0027071 , 0.9966305 , 0.98782957, 0.9977884 ,\n",
      "       1.0176966 , 0.9967571 , 0.99696517, 0.9958447 , 0.99493843,\n",
      "       1.021497  , 1.0261022 , 0.98416805, 1.0115417 , 1.0179397 ,\n",
      "       0.99498755, 0.99117774, 1.0402347 , 1.0045152 , 1.0458956 ,\n",
      "       0.9921321 , 0.9911569 , 1.0389544 , 0.99367374, 0.9924044 ,\n",
      "       0.99845463, 1.0157217 , 0.99765646, 0.99010515, 0.9954972 ,\n",
      "       0.9896633 , 0.9961759 , 1.0179989 , 1.0021387 , 0.99608123,\n",
      "       0.99375236, 0.99774206, 1.0652415 , 1.0518748 , 0.9911322 ,\n",
      "       1.0010825 , 1.0038875 , 1.0065563 , 0.9927299 , 1.0004969 ,\n",
      "       0.9957164 , 0.9950041 , 1.0035111 , 0.9914442 , 0.99593425,\n",
      "       0.9987292 , 0.99320924, 0.993538  , 1.0684363 , 0.99251723,\n",
      "       1.0079219 , 1.002779  , 0.9862766 , 1.0120956 , 0.9902182 ,\n",
      "       0.9916213 , 1.000312  , 1.0088211 , 0.9996662 , 0.9888871 ,\n",
      "       1.0014178 , 1.0069538 , 0.9872187 , 0.9944611 , 1.0008811 ,\n",
      "       0.9928484 , 0.99601173, 1.0010716 , 0.9897754 , 1.0050832 ,\n",
      "       1.0088897 , 0.99174064, 1.0026982 , 1.0191119 , 1.0002742 ,\n",
      "       1.0030541 ], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-1.27443783e-02,  9.42461658e-03,  6.66562617e-02, -8.09584558e-03,\n",
      "        4.24171388e-02, -2.17098347e-03,  4.93328879e-03, -1.46755418e-02,\n",
      "       -1.63860489e-02, -1.26406327e-02, -6.42867060e-03, -9.99130122e-03,\n",
      "       -1.09575773e-02,  4.49054455e-03,  2.58044284e-02, -2.30193324e-03,\n",
      "       -1.45678921e-02, -7.73141114e-03,  1.90433152e-02, -2.37813983e-02,\n",
      "       -9.53602418e-03,  1.33754695e-02, -5.46446117e-03,  3.33402753e-02,\n",
      "       -6.69422327e-03,  5.88716790e-02, -1.67000722e-02,  1.48921777e-02,\n",
      "       -4.52423748e-03,  1.18606025e-02, -1.65143013e-02,  5.76515161e-02,\n",
      "        5.71867032e-03,  1.50005417e-02, -7.75224529e-03, -8.61301646e-03,\n",
      "        3.99006438e-03,  6.47994597e-03, -1.78934485e-02, -2.44151661e-03,\n",
      "        1.11511117e-03,  4.98949143e-04, -8.09013005e-03, -1.74588133e-02,\n",
      "        2.38052593e-03, -5.03044669e-03,  3.91821377e-02, -1.03397539e-03,\n",
      "       -1.39164245e-02, -5.18307742e-03, -1.14448899e-02,  1.05960919e-02,\n",
      "        8.25389009e-03, -1.05765592e-02, -1.12233860e-02, -4.89929086e-03,\n",
      "        5.44308312e-02,  9.28849331e-04,  6.34696614e-03, -2.85039144e-03,\n",
      "        1.03661995e-02,  3.14548574e-02, -1.27271274e-02,  1.63161401e-02,\n",
      "       -1.39071199e-03,  2.30657291e-02,  2.00691656e-03, -1.23035479e-02,\n",
      "        1.06737325e-02,  4.17481549e-03,  4.77452464e-02,  9.04979464e-03,\n",
      "        2.69717560e-03, -6.86895335e-04, -1.57059229e-03,  7.35357404e-03,\n",
      "        1.34031828e-02,  2.82754772e-03,  1.54353920e-02,  8.44557583e-03,\n",
      "       -4.31016367e-03, -2.93454751e-02, -1.01405019e-02,  4.85272519e-03,\n",
      "       -1.01653235e-02, -9.80292796e-04, -3.47531424e-03,  2.36390606e-02,\n",
      "       -1.73276514e-02,  3.33903590e-03, -4.46977746e-03, -1.20141227e-02,\n",
      "       -1.25025902e-02,  1.76819209e-02,  6.40109042e-03,  2.35930346e-02,\n",
      "        3.61861773e-02,  5.95419370e-02,  1.78413093e-02,  4.33777971e-03,\n",
      "       -7.23710097e-03,  7.80073255e-02,  1.32679744e-02, -9.94805526e-03,\n",
      "       -1.28526834e-03,  2.12443084e-03, -9.84705146e-03,  6.42455998e-04,\n",
      "        1.92386727e-03,  1.45214694e-02, -2.35640071e-03, -3.60936695e-03,\n",
      "        1.66738976e-03, -4.41188371e-04, -2.30460404e-03, -1.81240868e-02,\n",
      "       -6.68502366e-03,  6.05426403e-03, -1.53168775e-02, -2.21307855e-03,\n",
      "        1.99255012e-02,  7.78540000e-02, -3.86449602e-03, -1.46422209e-03,\n",
      "        1.01008276e-02,  3.00030056e-02,  5.83057664e-03, -1.55243289e-03,\n",
      "       -7.43287848e-03,  4.75415523e-04,  1.04998774e-03, -4.06363630e-04,\n",
      "        2.08694558e-03,  1.44749423e-02,  4.69851017e-04, -2.90596770e-04,\n",
      "       -1.43157656e-03, -2.04213639e-03, -5.95634617e-03, -4.42503253e-03,\n",
      "       -1.98532944e-03,  7.36503210e-03,  1.54598486e-02,  1.72752477e-02,\n",
      "       -2.27911561e-03,  5.90341017e-02, -3.83922656e-04, -2.55386513e-02,\n",
      "        2.66042892e-02, -2.24320069e-02,  2.36779191e-02, -7.93979969e-03,\n",
      "       -4.00877278e-03, -8.29327293e-03,  4.67993356e-02, -7.88389333e-03,\n",
      "        2.84784450e-03, -7.27355154e-03,  6.25168346e-03,  2.03378480e-02,\n",
      "       -5.35592856e-03,  2.18971465e-02, -5.93117857e-03, -6.12353999e-03,\n",
      "        3.53866071e-03,  7.04499334e-03,  9.27675236e-03, -7.28431565e-04,\n",
      "        7.48924026e-03,  6.23394619e-04, -4.94588213e-03,  7.28525547e-03,\n",
      "       -9.69402120e-03,  5.09939902e-03,  1.39694300e-03,  6.91825384e-03,\n",
      "        3.15922475e-03, -8.60997103e-03, -9.43366438e-03,  4.75823274e-03,\n",
      "        1.00247329e-02,  8.43398273e-03, -6.83325110e-04, -9.80783440e-03,\n",
      "        3.79304169e-03,  5.68079343e-03,  5.87218143e-02, -1.92526337e-02,\n",
      "       -9.21305548e-03,  1.45697361e-02, -3.58580472e-03, -1.09841572e-02,\n",
      "        6.38528243e-02,  1.29347397e-02, -3.84088345e-02,  3.66023928e-03,\n",
      "       -4.90533467e-03,  2.74895374e-02, -4.02722834e-03,  5.63078187e-03,\n",
      "        1.53751401e-02,  4.72375564e-03,  8.11997452e-05,  2.97323498e-03,\n",
      "       -5.28488215e-03, -5.68438321e-03,  3.73923243e-03,  5.59140276e-03,\n",
      "        9.24002938e-03, -3.75064532e-03, -7.51790171e-03,  1.00275094e-03,\n",
      "        4.43970263e-02, -3.65977436e-02,  3.00125219e-03, -6.00593444e-03,\n",
      "        1.17651420e-02,  2.73511112e-02, -1.72050111e-02,  4.10653977e-03,\n",
      "       -7.38219684e-03, -4.13582800e-03,  3.52336071e-03, -1.43923406e-02,\n",
      "       -2.10732059e-03, -1.82203425e-03, -9.90780909e-03,  6.73494255e-03,\n",
      "        6.23577386e-02,  1.49963319e-03,  1.86700188e-02,  1.19941281e-02,\n",
      "       -1.25611117e-02, -1.91881191e-02, -1.16713541e-02, -8.19262303e-03,\n",
      "        5.07607637e-03,  1.33392597e-02, -3.59070650e-03, -1.20368404e-02,\n",
      "       -1.78554785e-02, -7.26386579e-03,  3.73189338e-04,  5.45257586e-04,\n",
      "        2.47777440e-03, -1.22484500e-02, -1.11592375e-02,  5.24038728e-03,\n",
      "       -5.82517590e-04, -1.74197499e-02,  9.71130189e-03,  1.23299251e-04,\n",
      "       -1.04866261e-02,  4.85214964e-02,  1.74037542e-03,  5.41602552e-04],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization_1/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0.9880506 , 0.99561065, 0.9842291 , 0.9935733 , 0.9714747 ,\n",
      "       0.99273026, 0.9900798 , 0.98533374, 0.9949759 , 0.9817947 ,\n",
      "       0.9868663 , 0.9831817 , 0.99881   , 0.98819476, 0.97556865,\n",
      "       0.99009323, 0.98363155, 0.9885414 , 0.99536407, 1.0013533 ,\n",
      "       0.98769134, 0.98194087, 0.9891366 , 0.9331409 , 0.985597  ,\n",
      "       0.9881013 , 0.97822547, 0.9881304 , 0.9972238 , 0.97498333,\n",
      "       0.99493104, 0.9805933 , 0.98842865, 0.99703085, 0.9944745 ,\n",
      "       0.98391706, 0.9858794 , 0.9942344 , 0.9798539 , 0.9953184 ,\n",
      "       0.99453914, 0.99323124, 0.9876354 , 0.99534816, 0.9814643 ,\n",
      "       0.9882125 , 0.9802804 , 0.99370784, 0.9923323 , 0.979835  ,\n",
      "       0.9816287 , 0.99443644, 0.99404883, 0.97775424, 0.98178864,\n",
      "       0.98689246, 0.98411787, 0.98571044, 1.0012901 , 1.0036469 ,\n",
      "       0.97934115, 1.0004083 , 0.9937511 , 0.974102  , 0.9883817 ,\n",
      "       0.99007696, 0.99377227, 0.99416   , 1.0004866 , 1.0025125 ,\n",
      "       0.98175085, 0.99311584, 0.9916403 , 0.99008036, 0.99265355,\n",
      "       0.988462  , 0.98431516, 0.97369874, 0.9969666 , 0.9934545 ,\n",
      "       0.9921836 , 0.9981261 , 0.9854927 , 0.9876799 , 0.98582906,\n",
      "       0.98574185, 0.9943769 , 0.96986693, 0.9863656 , 0.9906431 ,\n",
      "       0.9875626 , 1.0081165 , 0.97601074, 0.9788184 , 0.98799896,\n",
      "       1.012704  , 0.9813542 , 0.9798606 , 0.99145234, 0.98756766,\n",
      "       0.99544257, 0.9769909 , 0.99242234, 0.9866048 , 0.9906168 ,\n",
      "       0.9894608 , 0.995141  , 1.0018454 , 0.995246  , 0.9917562 ,\n",
      "       0.9887588 , 0.989899  , 0.98637754, 0.98500085, 0.9934971 ,\n",
      "       0.9857283 , 0.98422164, 0.98946226, 0.9817677 , 0.98667586,\n",
      "       0.98103154, 0.97140354, 1.0005805 , 1.0008869 , 0.9934111 ,\n",
      "       0.9882546 , 1.0076951 , 0.99278957, 0.9918186 , 0.9838406 ,\n",
      "       0.99544144, 0.9880883 , 0.9895949 , 0.9868727 , 0.9912164 ,\n",
      "       0.9873404 , 0.9952029 , 0.9832328 , 0.9832125 , 0.9941316 ,\n",
      "       1.0169663 , 0.9879904 , 0.9859769 , 0.99237233, 0.99551743,\n",
      "       0.97626716, 0.9847159 , 0.9900994 , 1.002965  , 0.9796074 ,\n",
      "       0.97831506, 0.99700224, 0.9942844 , 0.98627466, 0.98417395,\n",
      "       0.9782676 , 0.9817712 , 0.98989844, 0.9911577 , 0.97701067,\n",
      "       0.9834877 , 0.9908184 , 0.9767509 , 0.9824622 , 0.99622625,\n",
      "       0.99913645, 0.98579556, 0.9887588 , 0.99211365, 0.99899805,\n",
      "       0.9909636 , 0.9915685 , 0.98915195, 0.9934327 , 0.9914651 ,\n",
      "       0.98731285, 0.9941082 , 0.9959723 , 0.9883939 , 0.9986273 ,\n",
      "       0.98443997, 0.99009997, 0.9928997 , 0.9886152 , 0.9930373 ,\n",
      "       1.0062712 , 0.980736  , 0.9752361 , 1.0005157 , 0.9849538 ,\n",
      "       0.9897625 , 0.99639964, 0.9801353 , 0.99195224, 0.9809041 ,\n",
      "       0.98892164, 0.9867546 , 0.9328004 , 0.9853931 , 0.9650575 ,\n",
      "       0.98208565, 0.99850804, 0.999181  , 0.98423505, 0.9914499 ,\n",
      "       0.9870402 , 0.98570925, 1.0192475 , 0.9949692 , 1.002849  ,\n",
      "       0.98754126, 0.9924382 , 0.9706101 , 0.98695844, 0.9775268 ,\n",
      "       0.98956764, 0.99121964, 0.9785168 , 0.99025255, 0.98977757,\n",
      "       0.9836521 , 0.99209726, 0.9854341 , 0.9920537 , 0.98707485,\n",
      "       0.98535454, 0.9965154 , 0.97627807, 0.9772956 , 0.98288614,\n",
      "       0.9784743 , 0.9801046 , 0.992475  , 0.98543257, 0.98793197,\n",
      "       0.9975582 , 1.0092963 , 0.9980194 , 0.990687  , 0.9890829 ,\n",
      "       0.9845243 , 0.99651533, 0.9812105 , 0.9957354 , 0.99802583,\n",
      "       0.98540074, 0.9934928 , 0.99115235, 0.9844705 , 0.9841824 ,\n",
      "       0.9887824 , 0.9884188 , 0.9973572 , 0.97901815, 0.9877768 ,\n",
      "       0.9949447 ], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization_1/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-3.61156799e-02,  4.30153683e-03, -1.39702233e-02,  1.18035795e-02,\n",
      "       -2.34159771e-02, -2.68676598e-02, -1.70361735e-02, -1.53054195e-02,\n",
      "       -2.27500703e-02, -2.27189879e-03, -1.35410149e-02, -4.58998838e-03,\n",
      "       -2.63123736e-02, -1.82760824e-02, -2.40494981e-02, -1.69495139e-02,\n",
      "        2.03391816e-03, -2.23256163e-02,  1.83821656e-02, -6.71213167e-03,\n",
      "       -2.63662562e-02, -1.43048353e-02, -2.24858448e-02, -5.96529730e-02,\n",
      "       -1.15406550e-02, -1.03613511e-02, -3.67006809e-02, -1.47665916e-02,\n",
      "       -8.57500453e-03,  3.07232756e-02,  5.23643277e-04, -1.80339664e-02,\n",
      "       -3.68244969e-03, -1.29403584e-02,  1.15519622e-02, -2.72646733e-02,\n",
      "        1.61656141e-02, -4.10719309e-03, -3.48007195e-02, -5.43493778e-03,\n",
      "        7.81339314e-03, -2.47907303e-02, -1.40346736e-02,  3.18471029e-05,\n",
      "       -2.28462704e-02, -1.43933557e-02, -1.90601926e-02,  3.26102204e-03,\n",
      "       -1.92506518e-02, -2.19446104e-02, -3.18021923e-02,  9.16393753e-03,\n",
      "        6.41979859e-04, -3.76147740e-02, -2.31395047e-02, -2.31203623e-02,\n",
      "       -1.28202150e-02,  2.24286364e-03, -9.51304659e-03, -9.32187773e-03,\n",
      "        1.73712857e-02, -7.92359095e-03, -2.51083132e-02, -3.20474543e-02,\n",
      "       -1.87474664e-03, -1.67765096e-02,  7.11466139e-03, -1.59890316e-02,\n",
      "        4.98898141e-03, -5.35558537e-03, -1.89210717e-02,  4.55318158e-03,\n",
      "       -1.28366081e-02,  1.70381693e-03, -1.82178635e-02, -1.28998449e-02,\n",
      "       -1.42438915e-02, -3.27331275e-02, -9.53473058e-03, -5.42183081e-03,\n",
      "       -6.59240177e-03, -5.26709808e-03, -1.69374829e-03, -1.74403042e-02,\n",
      "       -2.75649317e-02, -2.57721599e-02, -1.08709112e-02, -3.47401649e-02,\n",
      "       -3.38283852e-02, -1.14325918e-02, -8.38596933e-03, -2.26289015e-02,\n",
      "       -3.28361392e-02, -2.77816094e-02,  9.25173517e-03,  2.46364623e-04,\n",
      "       -2.02851817e-02, -1.87749807e-02, -7.78954104e-03, -1.49963573e-02,\n",
      "       -3.97005584e-03, -2.27582790e-02, -2.15533935e-02, -1.18754841e-02,\n",
      "        7.75150722e-04, -4.85688495e-03, -9.62546933e-03,  2.52973824e-03,\n",
      "        5.72697539e-03, -1.51635651e-02, -1.96168926e-02, -8.40800162e-03,\n",
      "       -2.85499562e-02, -1.54064316e-02, -1.26694301e-02, -3.21649611e-02,\n",
      "       -3.15170884e-02, -9.53644980e-03, -2.05510259e-02, -1.49229290e-02,\n",
      "       -3.41513380e-02, -2.54213065e-02, -4.97718249e-03, -3.66479857e-03,\n",
      "       -5.60303638e-03, -1.35130836e-02,  2.32198578e-03, -4.67054499e-03,\n",
      "       -1.18935257e-02,  1.13896402e-02, -2.23562378e-03, -1.35281207e-02,\n",
      "       -4.23206436e-03, -1.28425872e-02, -7.04124151e-03, -6.90906832e-04,\n",
      "        3.23039875e-03, -2.81368122e-02,  1.37857988e-03, -1.06742736e-02,\n",
      "        3.19186575e-03,  4.95561026e-03, -1.82451624e-02, -1.94186799e-03,\n",
      "       -1.53429694e-02, -2.37873401e-02, -1.85830109e-02, -2.61663496e-02,\n",
      "       -3.58771184e-04,  1.36645101e-02, -2.57483087e-02, -8.81544966e-03,\n",
      "       -6.08175900e-03, -8.36590677e-03, -1.52223781e-02, -2.52813902e-02,\n",
      "        1.11332098e-02,  2.62538879e-03,  4.55086259e-03, -2.53504142e-02,\n",
      "       -1.57929175e-02, -1.08430097e-02, -3.31888273e-02, -3.28552462e-02,\n",
      "       -1.43208168e-02,  3.37061327e-04, -1.69748403e-02,  4.88938438e-03,\n",
      "       -1.21880346e-03, -3.78525141e-03, -1.40583590e-02, -8.42799805e-03,\n",
      "       -2.42923815e-02, -9.61416401e-03, -2.81398953e-03,  4.22089477e-04,\n",
      "       -9.38846264e-03, -2.46337075e-02, -1.49408048e-02, -1.93753764e-02,\n",
      "       -2.31654458e-02, -7.82154314e-03, -1.52829732e-03, -2.75155678e-02,\n",
      "       -4.96346829e-03, -4.83436137e-03, -1.60946865e-02, -3.50637883e-02,\n",
      "       -7.77333369e-03, -1.56278182e-02, -1.55381849e-02, -1.70753244e-02,\n",
      "       -2.03499664e-02, -1.62574723e-02,  1.34859458e-02, -9.77863185e-03,\n",
      "       -1.69922896e-02, -5.06460294e-02, -1.19586475e-02, -4.34833467e-02,\n",
      "       -2.07052473e-02, -9.61488055e-04, -1.44446641e-02, -1.76269244e-02,\n",
      "       -1.29369907e-02, -1.62979104e-02,  4.71653510e-03,  2.53772666e-03,\n",
      "       -7.61431816e-04, -1.10156955e-02, -1.59730855e-02,  2.40958738e-03,\n",
      "       -2.76693888e-02,  1.52593739e-02,  1.28143430e-02, -1.04200952e-02,\n",
      "        1.82047347e-03, -2.52574459e-02, -3.30655165e-02, -1.71371065e-02,\n",
      "       -1.52434977e-02, -1.19655486e-02, -2.23476849e-02, -1.46673229e-02,\n",
      "       -1.21647511e-02, -6.58218632e-04, -1.78527944e-02, -2.66924221e-02,\n",
      "       -1.95081588e-02, -2.02745348e-02, -2.10997574e-02, -2.19365191e-02,\n",
      "       -1.55704068e-02,  1.67289823e-02, -3.56828421e-02, -1.32141383e-02,\n",
      "       -9.61026270e-03,  1.43673988e-02, -1.12197653e-03, -2.88586896e-02,\n",
      "       -2.68477816e-02, -1.13726053e-02, -2.17271484e-02, -8.56132619e-03,\n",
      "       -3.94250685e-03, -3.39393690e-02, -1.40749887e-02, -7.07568228e-03,\n",
      "       -4.91760997e-03,  1.33978855e-02, -1.20298099e-02, -1.01257144e-02,\n",
      "       -1.34309242e-02, -2.06834450e-02,  4.35893238e-03,  1.88032910e-03],\n",
      "      dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(256, 1) dtype=float32, numpy=\n",
      "array([[-4.94128577e-02],\n",
      "       [-1.12849645e-01],\n",
      "       [ 1.04641616e-02],\n",
      "       [-3.60860862e-02],\n",
      "       [ 2.85442150e-03],\n",
      "       [-5.33528849e-02],\n",
      "       [-5.23636788e-02],\n",
      "       [-6.60454631e-02],\n",
      "       [-1.42239138e-01],\n",
      "       [-8.15464705e-02],\n",
      "       [ 1.15534149e-01],\n",
      "       [ 9.09861624e-02],\n",
      "       [-6.23260289e-02],\n",
      "       [ 5.12361042e-02],\n",
      "       [-5.27235912e-03],\n",
      "       [ 1.23826280e-01],\n",
      "       [-3.19423266e-02],\n",
      "       [-7.45214298e-02],\n",
      "       [ 5.69769032e-02],\n",
      "       [-2.04229206e-02],\n",
      "       [-6.89526126e-02],\n",
      "       [ 1.94935761e-02],\n",
      "       [ 1.17683046e-01],\n",
      "       [-4.03375924e-03],\n",
      "       [ 1.37809798e-01],\n",
      "       [ 1.13239679e-02],\n",
      "       [-6.39305487e-02],\n",
      "       [-2.53573693e-02],\n",
      "       [-1.21978395e-01],\n",
      "       [ 5.71946837e-02],\n",
      "       [-4.02443819e-02],\n",
      "       [-2.34558852e-03],\n",
      "       [ 5.26956357e-02],\n",
      "       [-2.25117449e-02],\n",
      "       [-2.71189846e-02],\n",
      "       [ 5.69612645e-02],\n",
      "       [-1.11097768e-01],\n",
      "       [ 1.39074296e-01],\n",
      "       [ 1.20881230e-01],\n",
      "       [ 1.00270465e-01],\n",
      "       [-8.15699175e-02],\n",
      "       [-9.70971808e-02],\n",
      "       [ 1.37788445e-01],\n",
      "       [ 2.42501888e-02],\n",
      "       [ 4.90480810e-02],\n",
      "       [-1.25365749e-01],\n",
      "       [ 1.69619992e-02],\n",
      "       [-1.04094937e-01],\n",
      "       [-1.34977400e-01],\n",
      "       [ 1.01869710e-01],\n",
      "       [-8.96121413e-02],\n",
      "       [ 4.37596440e-02],\n",
      "       [-6.10784553e-02],\n",
      "       [-1.18942477e-01],\n",
      "       [ 2.18761973e-02],\n",
      "       [-6.85263276e-02],\n",
      "       [-1.70705130e-03],\n",
      "       [ 1.26243114e-01],\n",
      "       [-6.22010119e-02],\n",
      "       [-4.59931716e-02],\n",
      "       [ 4.97537218e-02],\n",
      "       [ 2.21077744e-02],\n",
      "       [-7.39687905e-02],\n",
      "       [-1.82958022e-02],\n",
      "       [ 1.26552343e-01],\n",
      "       [-3.44199538e-02],\n",
      "       [-6.07764088e-02],\n",
      "       [-9.15673301e-02],\n",
      "       [-4.14278135e-02],\n",
      "       [ 7.87727684e-02],\n",
      "       [-7.64652574e-03],\n",
      "       [ 1.34930313e-01],\n",
      "       [-6.83921501e-02],\n",
      "       [ 4.88490574e-02],\n",
      "       [-7.38653615e-02],\n",
      "       [ 2.60860436e-02],\n",
      "       [-2.45409133e-03],\n",
      "       [ 5.79562783e-02],\n",
      "       [-2.30705943e-02],\n",
      "       [-4.77604102e-03],\n",
      "       [ 1.11321494e-01],\n",
      "       [ 2.44907849e-02],\n",
      "       [-7.76387081e-02],\n",
      "       [-5.16190454e-02],\n",
      "       [-1.08679406e-01],\n",
      "       [ 6.49795458e-02],\n",
      "       [-1.37157589e-01],\n",
      "       [ 2.20103073e-03],\n",
      "       [-1.05155855e-01],\n",
      "       [ 3.48422565e-02],\n",
      "       [ 7.70192593e-02],\n",
      "       [-7.03703761e-02],\n",
      "       [-6.26607686e-02],\n",
      "       [-1.26652829e-02],\n",
      "       [-4.37170044e-02],\n",
      "       [-2.52099950e-02],\n",
      "       [ 1.13773458e-02],\n",
      "       [ 8.45775299e-04],\n",
      "       [ 5.43868318e-02],\n",
      "       [ 5.25846072e-02],\n",
      "       [-1.06465936e-01],\n",
      "       [ 9.42360330e-03],\n",
      "       [-8.47105123e-03],\n",
      "       [-1.28662392e-01],\n",
      "       [-1.36187240e-01],\n",
      "       [ 9.07056853e-02],\n",
      "       [-1.10161588e-01],\n",
      "       [-5.81141859e-02],\n",
      "       [-1.12812102e-01],\n",
      "       [-3.54856066e-02],\n",
      "       [ 9.41021219e-02],\n",
      "       [ 1.42225102e-01],\n",
      "       [-4.73547243e-02],\n",
      "       [ 3.35093550e-02],\n",
      "       [ 8.33196342e-02],\n",
      "       [-9.98517498e-02],\n",
      "       [ 1.00149803e-01],\n",
      "       [ 6.26393184e-02],\n",
      "       [ 1.21303476e-01],\n",
      "       [ 5.70606105e-02],\n",
      "       [-2.91221626e-02],\n",
      "       [-4.69111511e-03],\n",
      "       [-3.32798734e-02],\n",
      "       [-1.19877078e-01],\n",
      "       [ 1.93040650e-02],\n",
      "       [-2.72744391e-02],\n",
      "       [ 1.11608863e-01],\n",
      "       [-1.17645383e-01],\n",
      "       [-1.23135038e-01],\n",
      "       [-1.24217376e-01],\n",
      "       [ 5.82584329e-02],\n",
      "       [-1.10702865e-01],\n",
      "       [ 1.25857487e-01],\n",
      "       [ 4.37884219e-02],\n",
      "       [-1.31550863e-01],\n",
      "       [ 1.18288927e-01],\n",
      "       [-7.58314729e-02],\n",
      "       [ 4.56825681e-02],\n",
      "       [-8.56586769e-02],\n",
      "       [ 8.94781798e-02],\n",
      "       [-5.96923046e-02],\n",
      "       [ 1.07938074e-01],\n",
      "       [ 1.83904562e-02],\n",
      "       [ 3.89436595e-02],\n",
      "       [-7.28042498e-02],\n",
      "       [-5.32900356e-03],\n",
      "       [ 1.08100891e-01],\n",
      "       [-1.13754861e-01],\n",
      "       [-3.74009907e-02],\n",
      "       [ 1.95558372e-04],\n",
      "       [-4.38886974e-03],\n",
      "       [-8.06377754e-02],\n",
      "       [-1.39030129e-01],\n",
      "       [-1.22783698e-01],\n",
      "       [-4.09241347e-03],\n",
      "       [ 9.71878469e-02],\n",
      "       [ 1.31290525e-01],\n",
      "       [-1.36621997e-01],\n",
      "       [ 1.40475050e-01],\n",
      "       [-2.21818103e-03],\n",
      "       [ 9.82443988e-02],\n",
      "       [-2.29935311e-02],\n",
      "       [-3.95140722e-02],\n",
      "       [-4.43246514e-02],\n",
      "       [ 2.30144691e-02],\n",
      "       [ 2.92704143e-02],\n",
      "       [ 5.48078008e-02],\n",
      "       [ 5.56288026e-02],\n",
      "       [ 9.46522281e-02],\n",
      "       [-8.99321586e-02],\n",
      "       [ 1.03105165e-01],\n",
      "       [ 6.13058247e-02],\n",
      "       [-6.76171109e-02],\n",
      "       [-9.43942443e-02],\n",
      "       [-1.39796808e-01],\n",
      "       [-9.98368636e-02],\n",
      "       [ 7.16480017e-02],\n",
      "       [-8.96107480e-02],\n",
      "       [-1.40285462e-01],\n",
      "       [-6.86064139e-02],\n",
      "       [-5.07672969e-03],\n",
      "       [ 3.81613858e-02],\n",
      "       [-5.38719743e-02],\n",
      "       [-1.06149346e-01],\n",
      "       [ 1.21571593e-01],\n",
      "       [-3.04028541e-02],\n",
      "       [ 2.70260894e-03],\n",
      "       [-6.62599951e-02],\n",
      "       [-3.29637378e-02],\n",
      "       [-6.69329567e-03],\n",
      "       [ 4.17412333e-02],\n",
      "       [-1.24565192e-01],\n",
      "       [ 1.20383147e-02],\n",
      "       [-4.84227836e-02],\n",
      "       [-6.13966584e-03],\n",
      "       [ 7.10968152e-02],\n",
      "       [ 9.50076506e-02],\n",
      "       [-1.86960539e-03],\n",
      "       [ 7.80334398e-02],\n",
      "       [-2.12598797e-02],\n",
      "       [ 3.15707587e-02],\n",
      "       [-3.16687077e-02],\n",
      "       [-8.31392407e-02],\n",
      "       [ 5.26684225e-02],\n",
      "       [-1.30577549e-01],\n",
      "       [ 1.28863916e-01],\n",
      "       [ 1.31926179e-01],\n",
      "       [-1.16281405e-01],\n",
      "       [ 1.00372560e-01],\n",
      "       [-1.26405030e-01],\n",
      "       [ 8.77448171e-02],\n",
      "       [-1.00480556e-01],\n",
      "       [ 1.04973034e-04],\n",
      "       [ 3.00007267e-03],\n",
      "       [ 1.08659968e-01],\n",
      "       [ 1.04553036e-01],\n",
      "       [ 4.74045612e-02],\n",
      "       [ 6.76769158e-03],\n",
      "       [-1.36052623e-01],\n",
      "       [ 6.57297820e-02],\n",
      "       [-8.43997449e-02],\n",
      "       [-7.11498260e-02],\n",
      "       [-4.11746837e-02],\n",
      "       [-9.56844017e-02],\n",
      "       [ 9.77614671e-02],\n",
      "       [ 5.13876230e-02],\n",
      "       [-1.11122712e-01],\n",
      "       [-2.60395519e-02],\n",
      "       [ 9.95737966e-04],\n",
      "       [-8.79256334e-03],\n",
      "       [-1.03103127e-02],\n",
      "       [ 2.09931191e-03],\n",
      "       [-1.33009702e-01],\n",
      "       [ 6.13802113e-03],\n",
      "       [-7.45437518e-02],\n",
      "       [-1.26241326e-01],\n",
      "       [-3.10125966e-02],\n",
      "       [ 1.37329206e-01],\n",
      "       [-1.08114675e-01],\n",
      "       [-1.05911955e-01],\n",
      "       [-5.37403300e-02],\n",
      "       [-1.07088163e-01],\n",
      "       [ 3.89550962e-02],\n",
      "       [-1.35937646e-01],\n",
      "       [ 1.12440765e-01],\n",
      "       [-1.00506388e-01],\n",
      "       [-8.11509341e-02],\n",
      "       [ 6.21967763e-02],\n",
      "       [ 5.73809296e-02],\n",
      "       [-1.96477044e-02],\n",
      "       [ 3.87200643e-03],\n",
      "       [ 5.88347055e-02],\n",
      "       [ 4.12088670e-02],\n",
      "       [ 1.21821126e-03],\n",
      "       [ 7.42494166e-02],\n",
      "       [ 1.17405772e-01]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.00427872], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72/782 [=>............................] - ETA: 2:14 - loss: 1.0331 - accuracy: 0.5516"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m/home/franc/posit_transformer.ipynb Cell 9\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/franc/posit_transformer.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mTest acc: \u001B[39m\u001B[39m{\u001B[39;00mmodel\u001B[39m.\u001B[39mevaluate(int_test_ds)[\u001B[39m1\u001B[39m]\u001B[39m:\u001B[39;00m\u001B[39m.3f\u001B[39m\u001B[39m}\u001B[39;00m\u001B[39m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1509\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   1507\u001B[0m \u001B[39mwith\u001B[39;00m trace\u001B[39m.\u001B[39mTrace(\u001B[39m'\u001B[39m\u001B[39mtest\u001B[39m\u001B[39m'\u001B[39m, step_num\u001B[39m=\u001B[39mstep, _r\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m):\n\u001B[1;32m   1508\u001B[0m   callbacks\u001B[39m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 1509\u001B[0m   tmp_logs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtest_function(iterator)\n\u001B[1;32m   1510\u001B[0m   \u001B[39mif\u001B[39;00m data_handler\u001B[39m.\u001B[39mshould_sync:\n\u001B[1;32m   1511\u001B[0m     context\u001B[39m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    882\u001B[0m compiler \u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mxla\u001B[39m\u001B[39m\"\u001B[39m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_jit_compile \u001B[39melse\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39mnonXla\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    884\u001B[0m \u001B[39mwith\u001B[39;00m OptionalXlaContext(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 885\u001B[0m   result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_call(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwds)\n\u001B[1;32m    887\u001B[0m new_tracing_count \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    888\u001B[0m without_tracing \u001B[39m=\u001B[39m (tracing_count \u001B[39m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:917\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    914\u001B[0m   \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_lock\u001B[39m.\u001B[39mrelease()\n\u001B[1;32m    915\u001B[0m   \u001B[39m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    916\u001B[0m   \u001B[39m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 917\u001B[0m   \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_stateless_fn(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwds)  \u001B[39m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    918\u001B[0m \u001B[39melif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_stateful_fn \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    919\u001B[0m   \u001B[39m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    920\u001B[0m   \u001B[39m# in parallel.\u001B[39;00m\n\u001B[1;32m    921\u001B[0m   \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_lock\u001B[39m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3032\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3029\u001B[0m \u001B[39mwith\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_lock:\n\u001B[1;32m   3030\u001B[0m   (graph_function,\n\u001B[1;32m   3031\u001B[0m    filtered_flat_args) \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3032\u001B[0m \u001B[39mreturn\u001B[39;00m graph_function\u001B[39m.\u001B[39;49m_call_flat(\n\u001B[1;32m   3033\u001B[0m     filtered_flat_args, captured_inputs\u001B[39m=\u001B[39;49mgraph_function\u001B[39m.\u001B[39;49mcaptured_inputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1956\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1952\u001B[0m possible_gradient_type \u001B[39m=\u001B[39m gradients_util\u001B[39m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1953\u001B[0m \u001B[39mif\u001B[39;00m (possible_gradient_type \u001B[39m==\u001B[39m gradients_util\u001B[39m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1954\u001B[0m     \u001B[39mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1955\u001B[0m   \u001B[39m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1956\u001B[0m   \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_build_call_outputs(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_inference_function\u001B[39m.\u001B[39;49mcall(\n\u001B[1;32m   1957\u001B[0m       ctx, args, cancellation_manager\u001B[39m=\u001B[39;49mcancellation_manager))\n\u001B[1;32m   1958\u001B[0m forward_backward \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1959\u001B[0m     args,\n\u001B[1;32m   1960\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1961\u001B[0m     executing_eagerly)\n\u001B[1;32m   1962\u001B[0m forward_function, args_with_tangents \u001B[39m=\u001B[39m forward_backward\u001B[39m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m \u001B[39mwith\u001B[39;00m _InterpolateFunctionError(\u001B[39mself\u001B[39m):\n\u001B[1;32m    590\u001B[0m   \u001B[39mif\u001B[39;00m cancellation_manager \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m--> 591\u001B[0m     outputs \u001B[39m=\u001B[39m execute\u001B[39m.\u001B[39;49mexecute(\n\u001B[1;32m    592\u001B[0m         \u001B[39mstr\u001B[39;49m(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49msignature\u001B[39m.\u001B[39;49mname),\n\u001B[1;32m    593\u001B[0m         num_outputs\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_num_outputs,\n\u001B[1;32m    594\u001B[0m         inputs\u001B[39m=\u001B[39;49margs,\n\u001B[1;32m    595\u001B[0m         attrs\u001B[39m=\u001B[39;49mattrs,\n\u001B[1;32m    596\u001B[0m         ctx\u001B[39m=\u001B[39;49mctx)\n\u001B[1;32m    597\u001B[0m   \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    598\u001B[0m     outputs \u001B[39m=\u001B[39m execute\u001B[39m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    599\u001B[0m         \u001B[39mstr\u001B[39m(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39msignature\u001B[39m.\u001B[39mname),\n\u001B[1;32m    600\u001B[0m         num_outputs\u001B[39m=\u001B[39m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    603\u001B[0m         ctx\u001B[39m=\u001B[39mctx,\n\u001B[1;32m    604\u001B[0m         cancellation_manager\u001B[39m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m     58\u001B[0m   ctx\u001B[39m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 59\u001B[0m   tensors \u001B[39m=\u001B[39m pywrap_tfe\u001B[39m.\u001B[39;49mTFE_Py_Execute(ctx\u001B[39m.\u001B[39;49m_handle, device_name, op_name,\n\u001B[1;32m     60\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m \u001B[39mexcept\u001B[39;00m core\u001B[39m.\u001B[39m_NotOkStatusException \u001B[39mas\u001B[39;00m e:\n\u001B[1;32m     62\u001B[0m   \u001B[39mif\u001B[39;00m name \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "199/625 [========>.....................] - ETA: 7:14 - loss: 0.7362 - accuracy: 0.6203"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m/home/franc/posit_transformer.ipynb Cell 8\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/franc/posit_transformer.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001B[0m callbacks \u001B[39m=\u001B[39m [\n\u001B[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/franc/posit_transformer.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001B[0m  keras\u001B[39m.\u001B[39mcallbacks\u001B[39m.\u001B[39mModelCheckpoint(\u001B[39m\"\u001B[39m\u001B[39mmodel/full_transformer_encoder_posit.keras\u001B[39m\u001B[39m\"\u001B[39m,\n\u001B[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/franc/posit_transformer.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001B[0m  save_best_only\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m)\n\u001B[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/franc/posit_transformer.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001B[0m ] \n\u001B[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/franc/posit_transformer.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001B[0m model\u001B[39m.\u001B[39;49mfit(int_train_ds, validation_data\u001B[39m=\u001B[39;49mint_val_ds, epochs\u001B[39m=\u001B[39;49m\u001B[39m20\u001B[39;49m, \n\u001B[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/franc/posit_transformer.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001B[0m callbacks\u001B[39m=\u001B[39;49mcallbacks)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1198\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1191\u001B[0m \u001B[39mwith\u001B[39;00m trace\u001B[39m.\u001B[39mTrace(\n\u001B[1;32m   1192\u001B[0m     \u001B[39m'\u001B[39m\u001B[39mtrain\u001B[39m\u001B[39m'\u001B[39m,\n\u001B[1;32m   1193\u001B[0m     epoch_num\u001B[39m=\u001B[39mepoch,\n\u001B[1;32m   1194\u001B[0m     step_num\u001B[39m=\u001B[39mstep,\n\u001B[1;32m   1195\u001B[0m     batch_size\u001B[39m=\u001B[39mbatch_size,\n\u001B[1;32m   1196\u001B[0m     _r\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m):\n\u001B[1;32m   1197\u001B[0m   callbacks\u001B[39m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1198\u001B[0m   tmp_logs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtrain_function(iterator)\n\u001B[1;32m   1199\u001B[0m   \u001B[39mif\u001B[39;00m data_handler\u001B[39m.\u001B[39mshould_sync:\n\u001B[1;32m   1200\u001B[0m     context\u001B[39m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    882\u001B[0m compiler \u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mxla\u001B[39m\u001B[39m\"\u001B[39m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_jit_compile \u001B[39melse\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39mnonXla\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    884\u001B[0m \u001B[39mwith\u001B[39;00m OptionalXlaContext(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 885\u001B[0m   result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_call(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwds)\n\u001B[1;32m    887\u001B[0m new_tracing_count \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    888\u001B[0m without_tracing \u001B[39m=\u001B[39m (tracing_count \u001B[39m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:917\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    914\u001B[0m   \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_lock\u001B[39m.\u001B[39mrelease()\n\u001B[1;32m    915\u001B[0m   \u001B[39m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    916\u001B[0m   \u001B[39m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 917\u001B[0m   \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_stateless_fn(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwds)  \u001B[39m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    918\u001B[0m \u001B[39melif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_stateful_fn \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    919\u001B[0m   \u001B[39m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    920\u001B[0m   \u001B[39m# in parallel.\u001B[39;00m\n\u001B[1;32m    921\u001B[0m   \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_lock\u001B[39m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3032\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3029\u001B[0m \u001B[39mwith\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_lock:\n\u001B[1;32m   3030\u001B[0m   (graph_function,\n\u001B[1;32m   3031\u001B[0m    filtered_flat_args) \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3032\u001B[0m \u001B[39mreturn\u001B[39;00m graph_function\u001B[39m.\u001B[39;49m_call_flat(\n\u001B[1;32m   3033\u001B[0m     filtered_flat_args, captured_inputs\u001B[39m=\u001B[39;49mgraph_function\u001B[39m.\u001B[39;49mcaptured_inputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1956\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1952\u001B[0m possible_gradient_type \u001B[39m=\u001B[39m gradients_util\u001B[39m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1953\u001B[0m \u001B[39mif\u001B[39;00m (possible_gradient_type \u001B[39m==\u001B[39m gradients_util\u001B[39m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1954\u001B[0m     \u001B[39mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1955\u001B[0m   \u001B[39m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1956\u001B[0m   \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_build_call_outputs(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_inference_function\u001B[39m.\u001B[39;49mcall(\n\u001B[1;32m   1957\u001B[0m       ctx, args, cancellation_manager\u001B[39m=\u001B[39;49mcancellation_manager))\n\u001B[1;32m   1958\u001B[0m forward_backward \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1959\u001B[0m     args,\n\u001B[1;32m   1960\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1961\u001B[0m     executing_eagerly)\n\u001B[1;32m   1962\u001B[0m forward_function, args_with_tangents \u001B[39m=\u001B[39m forward_backward\u001B[39m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m \u001B[39mwith\u001B[39;00m _InterpolateFunctionError(\u001B[39mself\u001B[39m):\n\u001B[1;32m    590\u001B[0m   \u001B[39mif\u001B[39;00m cancellation_manager \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m--> 591\u001B[0m     outputs \u001B[39m=\u001B[39m execute\u001B[39m.\u001B[39;49mexecute(\n\u001B[1;32m    592\u001B[0m         \u001B[39mstr\u001B[39;49m(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49msignature\u001B[39m.\u001B[39;49mname),\n\u001B[1;32m    593\u001B[0m         num_outputs\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_num_outputs,\n\u001B[1;32m    594\u001B[0m         inputs\u001B[39m=\u001B[39;49margs,\n\u001B[1;32m    595\u001B[0m         attrs\u001B[39m=\u001B[39;49mattrs,\n\u001B[1;32m    596\u001B[0m         ctx\u001B[39m=\u001B[39;49mctx)\n\u001B[1;32m    597\u001B[0m   \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    598\u001B[0m     outputs \u001B[39m=\u001B[39m execute\u001B[39m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    599\u001B[0m         \u001B[39mstr\u001B[39m(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39msignature\u001B[39m.\u001B[39mname),\n\u001B[1;32m    600\u001B[0m         num_outputs\u001B[39m=\u001B[39m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    603\u001B[0m         ctx\u001B[39m=\u001B[39mctx,\n\u001B[1;32m    604\u001B[0m         cancellation_manager\u001B[39m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m     58\u001B[0m   ctx\u001B[39m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 59\u001B[0m   tensors \u001B[39m=\u001B[39m pywrap_tfe\u001B[39m.\u001B[39;49mTFE_Py_Execute(ctx\u001B[39m.\u001B[39;49m_handle, device_name, op_name,\n\u001B[1;32m     60\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m \u001B[39mexcept\u001B[39;00m core\u001B[39m.\u001B[39m_NotOkStatusException \u001B[39mas\u001B[39;00m e:\n\u001B[1;32m     62\u001B[0m   \u001B[39mif\u001B[39;00m name \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    " keras.callbacks.ModelCheckpoint(\"model/full_transformer_encoder_posit.keras\",\n",
    " save_best_only=True)\n",
    "] \n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, \n",
    "callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T09:52:25.486308466Z",
     "start_time": "2023-05-15T09:52:25.001356366Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown optimizer: Custom>Adam. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel.h5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTransformerEncoder\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mTransformerEncoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPositionalEmbedding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mPositionalEmbedding\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/keras/saving/save.py:200\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m load_context\u001B[38;5;241m.\u001B[39mload_context(options):\n\u001B[1;32m    198\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (h5py \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    199\u001B[0m       (\u001B[38;5;28misinstance\u001B[39m(filepath, h5py\u001B[38;5;241m.\u001B[39mFile) \u001B[38;5;129;01mor\u001B[39;00m h5py\u001B[38;5;241m.\u001B[39mis_hdf5(filepath))):\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhdf5_format\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model_from_hdf5\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    201\u001B[0m \u001B[43m                                            \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    203\u001B[0m   filepath \u001B[38;5;241m=\u001B[39m path_to_string(filepath)\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/keras/saving/hdf5_format.py:198\u001B[0m, in \u001B[0;36mload_model_from_hdf5\u001B[0;34m(filepath, custom_objects, compile)\u001B[0m\n\u001B[1;32m    195\u001B[0m training_config \u001B[38;5;241m=\u001B[39m json_utils\u001B[38;5;241m.\u001B[39mdecode(training_config)\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# Compile model.\u001B[39;00m\n\u001B[0;32m--> 198\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[43msaving_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_args_from_training_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m)\u001B[49m, from_serialized\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    200\u001B[0m saving_utils\u001B[38;5;241m.\u001B[39mtry_build_compiled_arguments(model)\n\u001B[1;32m    202\u001B[0m \u001B[38;5;66;03m# Set optimizer weights.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/keras/saving/saving_utils.py:202\u001B[0m, in \u001B[0;36mcompile_args_from_training_config\u001B[0;34m(training_config, custom_objects)\u001B[0m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m generic_utils\u001B[38;5;241m.\u001B[39mCustomObjectScope(custom_objects):\n\u001B[1;32m    201\u001B[0m   optimizer_config \u001B[38;5;241m=\u001B[39m training_config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer_config\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m--> 202\u001B[0m   optimizer \u001B[38;5;241m=\u001B[39m \u001B[43moptimizers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;66;03m# Recover losses.\u001B[39;00m\n\u001B[1;32m    205\u001B[0m   loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/keras/optimizers.py:95\u001B[0m, in \u001B[0;36mdeserialize\u001B[0;34m(config, custom_objects)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass_name\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;129;01min\u001B[39;00m all_classes:\n\u001B[1;32m     94\u001B[0m   config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass_name\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass_name\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mlower()\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moptimizer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/keras/utils/generic_utils.py:659\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(identifier, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    657\u001B[0m   \u001B[38;5;66;03m# In this case we are dealing with a Keras config dictionary.\u001B[39;00m\n\u001B[1;32m    658\u001B[0m   config \u001B[38;5;241m=\u001B[39m identifier\n\u001B[0;32m--> 659\u001B[0m   (\u001B[38;5;28mcls\u001B[39m, cls_config) \u001B[38;5;241m=\u001B[39m \u001B[43mclass_and_config_for_serialized_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    660\u001B[0m \u001B[43m      \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    662\u001B[0m   \u001B[38;5;66;03m# If this object has already been loaded (i.e. it's shared between multiple\u001B[39;00m\n\u001B[1;32m    663\u001B[0m   \u001B[38;5;66;03m# objects), return the already-loaded object.\u001B[39;00m\n\u001B[1;32m    664\u001B[0m   shared_object_id \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mget(SHARED_OBJECT_KEY)\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/keras/utils/generic_utils.py:556\u001B[0m, in \u001B[0;36mclass_and_config_for_serialized_keras_object\u001B[0;34m(config, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m get_registered_object(class_name, custom_objects, module_objects)\n\u001B[1;32m    555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 556\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    557\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnknown \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. Please ensure this object is \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    558\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpassed to the `custom_objects` argument. See \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    559\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    560\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#registering_the_custom_object for details.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    561\u001B[0m       \u001B[38;5;241m.\u001B[39mformat(printable_module_name, class_name))\n\u001B[1;32m    563\u001B[0m cls_config \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    564\u001B[0m \u001B[38;5;66;03m# Check if `cls_config` is a list. If it is a list, return the class and the\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;66;03m# associated class configs for recursively deserialization. This case will\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;66;03m# happen on the old version of sequential model (e.g. `keras_version` ==\u001B[39;00m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;66;03m# \"2.0.6\"), which is serialized in a different structure, for example\u001B[39;00m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;66;03m# \"{'class_name': 'Sequential',\u001B[39;00m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;66;03m#   'config': [{'class_name': 'Embedding', 'config': ...}, {}, ...]}\".\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown optimizer: Custom>Adam. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"model.h5\",\n",
    "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
    "                    \"PositionalEmbedding\": PositionalEmbedding})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'positional_embedding/embedding/embeddings:0' shape=(20000, 256) dtype=float32, numpy=\n",
      "array([[-0.03150397,  0.00373997, -0.03244636, ...,  0.03043887,\n",
      "        -0.05167284,  0.03323204],\n",
      "       [-0.00318759, -0.00405039,  0.04254161, ..., -0.01668963,\n",
      "         0.04274717,  0.02822473],\n",
      "       [ 0.0233761 , -0.04159024,  0.04559259, ...,  0.00379981,\n",
      "        -0.03726941,  0.03221758],\n",
      "       ...,\n",
      "       [-0.01635022,  0.04602778, -0.03338681, ..., -0.02754178,\n",
      "        -0.04257899, -0.05332807],\n",
      "       [-0.05452348, -0.04753804,  0.034722  , ...,  0.01256795,\n",
      "        -0.01627147,  0.0019415 ],\n",
      "       [ 0.04122843,  0.00530811, -0.01852891, ..., -0.02590084,\n",
      "        -0.03846217,  0.03773504]], dtype=float32)>, <tf.Variable 'positional_embedding/embedding_1/embeddings:0' shape=(600, 256) dtype=float32, numpy=\n",
      "array([[ 0.01230673, -0.03902837, -0.05263768, ...,  0.02777611,\n",
      "        -0.00754173, -0.02190994],\n",
      "       [ 0.00509173,  0.01386093, -0.02932673, ...,  0.0414314 ,\n",
      "         0.01057568,  0.0395157 ],\n",
      "       [-0.01554729, -0.0449503 , -0.02898062, ...,  0.02004098,\n",
      "        -0.02064834, -0.02815597],\n",
      "       ...,\n",
      "       [ 0.00030992, -0.02117897,  0.02920722, ...,  0.04087241,\n",
      "        -0.00573925, -0.06581715],\n",
      "       [ 0.01750796,  0.04187512,  0.00338568, ..., -0.04085676,\n",
      "         0.01356466, -0.02775514],\n",
      "       [ 0.00171509,  0.05309919, -0.04906914, ..., -0.03806351,\n",
      "         0.02884597, -0.04248426]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/query/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[-0.00897669,  0.00665849,  0.01787482, ...,  0.02180378,\n",
      "          0.00750925, -0.01257297],\n",
      "        [ 0.01875287,  0.02076074, -0.00854151, ..., -0.01224499,\n",
      "          0.01473786, -0.00554009]],\n",
      "\n",
      "       [[-0.04509726,  0.01926505,  0.03224761, ...,  0.00714147,\n",
      "          0.0096025 , -0.02071199],\n",
      "        [ 0.00684673,  0.01411908, -0.02136354, ..., -0.02497246,\n",
      "          0.01626648, -0.02695196]],\n",
      "\n",
      "       [[-0.05308963,  0.00782915,  0.06630801, ...,  0.00325393,\n",
      "          0.00426425,  0.00826997],\n",
      "        [ 0.01552427, -0.01968287,  0.00322843, ...,  0.00382133,\n",
      "          0.00303019, -0.00156766]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.02617601, -0.03588182,  0.02084137, ..., -0.03259308,\n",
      "         -0.02920961,  0.02889208],\n",
      "        [-0.02363651, -0.02631208,  0.03586027, ...,  0.03686972,\n",
      "         -0.03264197,  0.03067526]],\n",
      "\n",
      "       [[ 0.02488901, -0.00442905, -0.03711541, ...,  0.01259349,\n",
      "         -0.01012202, -0.00203713],\n",
      "        [ 0.00671598,  0.03330297,  0.00574183, ..., -0.01591265,\n",
      "          0.01132131,  0.0016144 ]],\n",
      "\n",
      "       [[-0.00056172, -0.01504254, -0.00747664, ..., -0.01224543,\n",
      "          0.00089446,  0.01479857],\n",
      "        [-0.01087681, -0.00511869,  0.00862859, ...,  0.02064845,\n",
      "          0.00497297,  0.01136793]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/query/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[ 0.02627618, -0.06395978, -0.05357984, -0.04469851,  0.10016701,\n",
      "        -0.04615734,  0.06140406,  0.04128941, -0.07691101,  0.00250486,\n",
      "        -0.05144621, -0.06250361,  0.03678861,  0.01743587, -0.01776521,\n",
      "        -0.05194933,  0.09337387,  0.01431883,  0.04640203, -0.05196878,\n",
      "        -0.02579908, -0.00753203, -0.06324395,  0.08286488, -0.07572257,\n",
      "         0.00763727, -0.07804755,  0.09818094,  0.07330711, -0.04734226,\n",
      "         0.04478291,  0.06989695, -0.11479007,  0.01675233, -0.04485011,\n",
      "         0.08400811,  0.03014493,  0.08832502,  0.028151  ,  0.02458311,\n",
      "         0.07760985,  0.0251143 ,  0.09871259, -0.05771184, -0.05842889,\n",
      "         0.07627718, -0.1126536 ,  0.10037797,  0.05535614, -0.08022217,\n",
      "        -0.08137914,  0.00724612,  0.02626866, -0.08162541, -0.03538232,\n",
      "         0.04696311, -0.04360163, -0.02724806, -0.01864155,  0.04885494,\n",
      "        -0.01367119,  0.01256302, -0.01755426, -0.02456551, -0.06103494,\n",
      "        -0.09012572,  0.04612804,  0.00068525,  0.08693407,  0.05320892,\n",
      "        -0.06009137,  0.016656  , -0.05296703,  0.07296354, -0.02301407,\n",
      "        -0.06962755,  0.00651751, -0.05617523,  0.09991628, -0.08132394,\n",
      "        -0.09120932,  0.08532992,  0.03576755,  0.0748371 ,  0.07681001,\n",
      "        -0.09528647, -0.00758992, -0.09691982,  0.03864663, -0.04459694,\n",
      "        -0.0668017 , -0.09207827,  0.0547688 , -0.05319397, -0.08816044,\n",
      "         0.08126469, -0.08617839, -0.01498414, -0.01365163, -0.06064671,\n",
      "        -0.02383772, -0.07367437, -0.06153246, -0.02989906, -0.05427149,\n",
      "         0.07858234,  0.07362195,  0.04293016,  0.07126469, -0.06093249,\n",
      "        -0.06561934, -0.01568304, -0.03791243, -0.09303709, -0.02208054,\n",
      "        -0.03992478,  0.07194059,  0.07037129, -0.09231117,  0.02242829,\n",
      "        -0.06916976, -0.05808606,  0.04035508, -0.08292979, -0.0219205 ,\n",
      "        -0.06227617, -0.01189892, -0.09007178,  0.01909287,  0.04581454,\n",
      "         0.00213614,  0.00688984, -0.0180987 , -0.06749114, -0.07807133,\n",
      "         0.02744669, -0.0857508 , -0.10245958,  0.0701802 ,  0.09959173,\n",
      "        -0.09159743, -0.06198769, -0.01518241, -0.07741036, -0.05146015,\n",
      "        -0.09710312, -0.08663537, -0.08765434, -0.10405505, -0.00601833,\n",
      "         0.03751582,  0.01459346, -0.03308027,  0.0800276 ,  0.00837688,\n",
      "         0.00506982,  0.06420432, -0.0490079 , -0.03294707,  0.04168381,\n",
      "         0.02243227,  0.09478171, -0.01655104,  0.0634074 , -0.04475761,\n",
      "         0.09612614,  0.03237251,  0.04218156, -0.05611219, -0.0675078 ,\n",
      "         0.03532873, -0.0097783 ,  0.03032441, -0.0521562 ,  0.0693562 ,\n",
      "         0.08124506, -0.03794002, -0.02199334, -0.00433856, -0.05778443,\n",
      "         0.00604198,  0.03303369,  0.06603396,  0.01893634,  0.09055027,\n",
      "         0.05193008,  0.07979611, -0.07204185,  0.06238578,  0.0531003 ,\n",
      "         0.02027903,  0.0337959 , -0.06404265,  0.07187397,  0.0652189 ,\n",
      "        -0.01113016, -0.09112076, -0.07783546,  0.08554579, -0.0534904 ,\n",
      "        -0.01686242, -0.08275393,  0.05544762,  0.01457067,  0.07326712,\n",
      "         0.0474717 ,  0.0102598 ,  0.07797343,  0.00215617, -0.0242124 ,\n",
      "         0.03885244, -0.04897505, -0.03613725,  0.07608204,  0.05183208,\n",
      "         0.01755472,  0.06034788,  0.06524154,  0.023568  , -0.09024429,\n",
      "         0.03620455, -0.05718953, -0.05893522, -0.06888849, -0.08951159,\n",
      "        -0.00335253,  0.04979332,  0.08175118, -0.02564974,  0.0199972 ,\n",
      "         0.04431903,  0.06392708, -0.09058881, -0.00577845,  0.03927638,\n",
      "         0.02744348,  0.06652953, -0.07338237,  0.01454824, -0.00608512,\n",
      "         0.06420238,  0.03005825,  0.042092  ,  0.07665521,  0.04086461,\n",
      "        -0.00560103, -0.01577446, -0.06543019, -0.07974252,  0.00756952,\n",
      "         0.08133882,  0.00481498, -0.07388488, -0.02274492, -0.05174092,\n",
      "         0.03061182],\n",
      "       [-0.05639135, -0.00519485,  0.09668126,  0.09253383,  0.09295124,\n",
      "         0.0271913 , -0.0318128 , -0.08677544,  0.09202945, -0.0899886 ,\n",
      "        -0.03993395,  0.01610053, -0.06032208,  0.08346614, -0.01718626,\n",
      "         0.10542236,  0.04442714, -0.03147411, -0.06500252,  0.07668802,\n",
      "        -0.07413125,  0.08809412,  0.05148105, -0.10618517, -0.06066542,\n",
      "         0.10226929, -0.10341089, -0.01857089, -0.00391636, -0.00510706,\n",
      "        -0.06219741,  0.0241488 ,  0.12078747,  0.04049742,  0.02909137,\n",
      "         0.06346055,  0.0645009 , -0.0467779 ,  0.10971039,  0.03429766,\n",
      "         0.07933472, -0.00519556,  0.07556968, -0.08798458,  0.10218612,\n",
      "         0.06053108,  0.10010765,  0.07461122, -0.10897458,  0.01012724,\n",
      "        -0.03639414,  0.0754762 ,  0.03529071, -0.03669058,  0.08355396,\n",
      "        -0.0197578 , -0.0736547 ,  0.10269223,  0.09164149, -0.00297397,\n",
      "         0.1263068 , -0.07350145,  0.07088187, -0.04197323, -0.08962119,\n",
      "        -0.03153897, -0.0549779 , -0.10614783,  0.10917865,  0.00799807,\n",
      "         0.12106601,  0.0912011 , -0.07686109,  0.02308849, -0.05591609,\n",
      "         0.06921349,  0.12189607,  0.0663345 , -0.03278204,  0.07526413,\n",
      "         0.07399639, -0.05284733,  0.04159836, -0.08971175, -0.06813297,\n",
      "         0.00686977, -0.06833102, -0.00791358,  0.07850163, -0.0586553 ,\n",
      "         0.02924895, -0.10993307, -0.10049398,  0.12127692, -0.01593588,\n",
      "        -0.06022981,  0.03618721, -0.11924792,  0.06517316, -0.09507029,\n",
      "        -0.03008101,  0.04624389,  0.13086976, -0.08132991, -0.08029089,\n",
      "         0.06235036,  0.03068105, -0.02533864, -0.09842163, -0.08771577,\n",
      "        -0.02676167, -0.0705525 , -0.0396826 ,  0.04444729, -0.08284936,\n",
      "         0.08326706, -0.04592362, -0.0747074 , -0.10242277,  0.03565595,\n",
      "        -0.0439854 , -0.09112738,  0.12499028, -0.00840729,  0.03989141,\n",
      "         0.07434715, -0.03880521, -0.0666977 , -0.07715866,  0.08231816,\n",
      "        -0.01499026,  0.07840788, -0.08614762,  0.07877347, -0.02894888,\n",
      "         0.07726832, -0.08231491,  0.06229679, -0.02443364,  0.09621585,\n",
      "         0.03913577, -0.10366534,  0.0629961 , -0.05011417,  0.05075321,\n",
      "        -0.0360445 ,  0.0151435 ,  0.07396396,  0.00948111, -0.00253492,\n",
      "        -0.03806396, -0.05144813, -0.10847305,  0.08391102,  0.05939344,\n",
      "        -0.06080524, -0.05065453, -0.10621201, -0.06374054,  0.07209016,\n",
      "         0.11226095, -0.00613381,  0.01168028,  0.02243197,  0.05926368,\n",
      "         0.08888647, -0.08664334, -0.05428493, -0.07916347, -0.01047435,\n",
      "         0.0478571 ,  0.02942798,  0.03030185, -0.1025336 , -0.10309253,\n",
      "        -0.0300878 ,  0.11025215, -0.05250391, -0.11588418, -0.03337662,\n",
      "         0.09022292,  0.02410372, -0.09069242,  0.02021714,  0.07053247,\n",
      "        -0.07518324,  0.05731697, -0.09715377, -0.09112849, -0.10540518,\n",
      "        -0.0220831 ,  0.10312036, -0.11894149,  0.09824008, -0.11114057,\n",
      "        -0.09274063,  0.05085152,  0.10856076, -0.0503194 ,  0.03228052,\n",
      "         0.0154062 ,  0.06217355, -0.06444041, -0.12708317,  0.03245186,\n",
      "         0.06273263, -0.00733484,  0.08696631, -0.10880944, -0.07657477,\n",
      "         0.06379998, -0.0778544 , -0.106557  , -0.06759465, -0.01768068,\n",
      "        -0.08378354, -0.1061541 , -0.02022249, -0.05634277, -0.01305669,\n",
      "         0.07395698, -0.03885009, -0.05432628,  0.00368148,  0.06944774,\n",
      "        -0.05695274, -0.12149104, -0.10032897, -0.13047233, -0.02782129,\n",
      "         0.07071553,  0.00023734,  0.04362059, -0.04660157, -0.00559872,\n",
      "        -0.0924167 , -0.07413451,  0.0091496 ,  0.05234462, -0.0522141 ,\n",
      "         0.00808137, -0.08445045,  0.06009742, -0.07863699,  0.06032162,\n",
      "         0.067152  , -0.01563742, -0.11161651,  0.06730686,  0.06218578,\n",
      "         0.07512197, -0.0880166 , -0.06474192,  0.05113805, -0.04555824,\n",
      "         0.1044542 ]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/key/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[ 0.02211001,  0.03189614, -0.01238929, ...,  0.03468731,\n",
      "          0.03236062, -0.04380549],\n",
      "        [ 0.02249459,  0.04706128, -0.03039415, ..., -0.0413533 ,\n",
      "          0.02953587, -0.01626266]],\n",
      "\n",
      "       [[-0.02644398, -0.00976906,  0.04772041, ..., -0.00865429,\n",
      "          0.00820483,  0.01238405],\n",
      "        [ 0.01382272, -0.00012884,  0.00595795, ...,  0.01211217,\n",
      "          0.00758138, -0.00667447]],\n",
      "\n",
      "       [[-0.05577791,  0.10164161,  0.09809168, ...,  0.05560733,\n",
      "          0.10034015, -0.07274479],\n",
      "        [ 0.10031632,  0.02194955, -0.11925302, ..., -0.08186955,\n",
      "          0.08833217, -0.1155104 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.04023927,  0.00452932,  0.02660535, ...,  0.02350708,\n",
      "          0.00693498, -0.01186325],\n",
      "        [ 0.00478144,  0.00707903,  0.00028562, ..., -0.01969218,\n",
      "          0.00079982,  0.00550858]],\n",
      "\n",
      "       [[ 0.03116217, -0.02928014, -0.04138237, ..., -0.01601804,\n",
      "         -0.01608682,  0.02971128],\n",
      "        [-0.01579976, -0.00469598,  0.03052375, ...,  0.0229994 ,\n",
      "         -0.02184963,  0.03788686]],\n",
      "\n",
      "       [[-0.01525136, -0.00110878,  0.00573428, ..., -0.00386146,\n",
      "          0.00344503, -0.00461994],\n",
      "        [ 0.00099749,  0.00694155, -0.00136997, ...,  0.00718821,\n",
      "          0.00216166, -0.00017043]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/key/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[ 2.0077215e-03, -4.3596537e-03, -3.2020267e-03, -4.2447848e-03,\n",
      "         5.6931502e-03, -3.5260061e-03,  4.3118661e-03,  4.1862959e-03,\n",
      "        -5.0161039e-03, -3.6335358e-04, -4.1851974e-03, -4.2742244e-03,\n",
      "         2.7807648e-03,  3.1977289e-03, -2.5505531e-03, -3.8553062e-03,\n",
      "         5.8255205e-03,  1.3310764e-03,  3.5641699e-03, -3.6272118e-03,\n",
      "        -3.3831059e-03, -1.4114314e-03, -3.7982743e-03,  5.0480943e-03,\n",
      "        -5.0820797e-03,  2.2612649e-03, -5.2994443e-03,  5.6766346e-03,\n",
      "         4.4561387e-03, -3.2653483e-03,  4.0865261e-03,  4.7438056e-03,\n",
      "        -6.1420649e-03,  2.2751626e-03, -4.1129226e-03,  4.9790666e-03,\n",
      "         3.1008576e-03,  5.4450505e-03,  2.6404907e-03,  2.9850495e-03,\n",
      "         4.5140251e-03,  3.1223241e-03,  5.5911220e-03, -4.3265717e-03,\n",
      "        -4.1048895e-03,  4.8587606e-03, -6.1832489e-03,  5.7097496e-03,\n",
      "         3.3086755e-03, -5.2290466e-03, -4.9609724e-03, -3.9721889e-04,\n",
      "         2.3503671e-03, -4.9309023e-03, -3.3590267e-03,  3.8118251e-03,\n",
      "        -3.8547404e-03, -3.2881370e-03, -3.0702415e-03,  3.8605609e-03,\n",
      "        -2.9399311e-03,  2.8014325e-03, -2.6952326e-03, -3.3968077e-03,\n",
      "        -4.1759019e-03, -5.2054664e-03,  4.5086588e-03,  2.9339417e-04,\n",
      "         5.1432815e-03,  4.5469599e-03, -4.5014513e-03,  2.5981355e-03,\n",
      "        -3.9650686e-03,  4.4784308e-03, -3.1247411e-03, -4.8919888e-03,\n",
      "        -8.1209396e-04, -3.3106250e-03,  5.7497984e-03, -4.9879835e-03,\n",
      "        -5.4025878e-03,  5.4885889e-03,  3.8240182e-03,  4.9760384e-03,\n",
      "         4.6432023e-03, -5.4074205e-03, -2.8168664e-03, -5.4220245e-03,\n",
      "         3.6618693e-03, -4.4028028e-03, -3.9994419e-03, -5.4258429e-03,\n",
      "         3.7278987e-03, -3.4579760e-03, -5.2982462e-03,  5.2346680e-03,\n",
      "        -5.3107087e-03, -2.2140511e-03, -1.0362818e-03, -3.9644483e-03,\n",
      "        -3.2366102e-03, -4.1416050e-03, -4.5494740e-03, -3.8934809e-03,\n",
      "        -4.5483494e-03,  5.3133233e-03,  5.1239608e-03,  2.9554844e-03,\n",
      "         4.7367243e-03, -4.0570758e-03, -4.1484544e-03, -2.2130732e-03,\n",
      "        -3.6868835e-03, -5.7177590e-03, -2.6360617e-03, -4.4262116e-03,\n",
      "         4.4593527e-03,  4.6235933e-03, -5.4583922e-03,  1.4370016e-03,\n",
      "        -4.6732882e-03, -4.2568031e-03,  3.8074532e-03, -5.2120886e-03,\n",
      "        -3.2674721e-03, -4.9869497e-03, -2.6032871e-03, -5.0171949e-03,\n",
      "         3.0985523e-03,  3.1715487e-03,  1.9050632e-03,  2.5676824e-03,\n",
      "        -2.0281272e-03, -4.7654528e-03, -4.8404038e-03,  2.8144356e-03,\n",
      "        -5.7108616e-03, -5.8019445e-03,  4.6827379e-03,  5.8240821e-03,\n",
      "        -5.6538866e-03, -4.0094662e-03, -2.0472598e-03, -4.7704731e-03,\n",
      "        -2.9107698e-03, -5.7723848e-03, -5.4541589e-03, -5.2528973e-03,\n",
      "        -6.0614403e-03,  1.3228371e-03,  3.0873239e-03,  3.0463287e-03,\n",
      "        -3.3082080e-03,  5.1895105e-03,  1.8467191e-03,  1.1758673e-03,\n",
      "         4.9461112e-03, -4.0884065e-03, -3.4376129e-03,  3.4892666e-03,\n",
      "         3.4466085e-03,  5.4740896e-03, -3.2712121e-03,  3.9685415e-03,\n",
      "        -4.6909330e-03,  5.9877024e-03,  4.0473025e-03,  3.3065090e-03,\n",
      "        -3.4584138e-03, -4.8079314e-03,  3.6093609e-03, -7.9879811e-04,\n",
      "         2.7326378e-03, -4.6337820e-03,  5.1074210e-03,  5.1859468e-03,\n",
      "        -3.9789118e-03, -3.7049516e-03, -1.1757038e-03, -4.3196911e-03,\n",
      "        -1.1387701e-03,  2.5442077e-03,  4.1798782e-03,  2.6152977e-03,\n",
      "         5.3763646e-03,  4.3946118e-03,  4.8007239e-03, -5.1954463e-03,\n",
      "         4.1715838e-03,  3.3347318e-03,  3.0716271e-03,  2.5714098e-03,\n",
      "        -4.0186686e-03,  4.7451067e-03,  4.4870819e-03, -1.5413121e-03,\n",
      "        -5.7824701e-03, -5.0587063e-03,  5.5923201e-03, -3.5138058e-03,\n",
      "        -2.9862663e-03, -4.6825563e-03,  4.6525216e-03,  2.8648335e-03,\n",
      "         4.5873681e-03,  3.5237705e-03,  2.5209663e-03,  4.8255250e-03,\n",
      "         5.8195845e-04, -3.5075375e-03,  3.9111688e-03, -3.7434418e-03,\n",
      "        -3.2009420e-03,  5.0676758e-03,  3.9378619e-03,  1.7400525e-03,\n",
      "         3.9725341e-03,  4.4162748e-03,  3.1571344e-03, -5.2485941e-03,\n",
      "         3.6701772e-03, -3.9314548e-03, -4.6923915e-03, -4.5521390e-03,\n",
      "        -5.5218670e-03, -9.2114566e-04,  3.4934208e-03,  5.0018723e-03,\n",
      "        -3.8617204e-03,  3.1336043e-03,  4.0923213e-03,  4.2472114e-03,\n",
      "        -5.5670980e-03, -2.1482816e-03,  3.8127208e-03,  3.9270828e-03,\n",
      "         4.5640897e-03, -4.3971185e-03,  1.9238382e-03, -1.3000086e-03,\n",
      "         4.9540652e-03,  3.8990490e-03,  3.5180459e-03,  5.0814105e-03,\n",
      "         3.4546633e-03, -5.9412059e-04, -3.3715337e-03, -3.8767376e-03,\n",
      "        -4.2967037e-03, -1.4438580e-03,  4.8290510e-03,  9.8046195e-04,\n",
      "        -4.5638606e-03, -3.3373446e-03, -3.6982344e-03,  3.7385400e-03],\n",
      "       [-1.9980688e-03, -1.0519128e-03,  2.9358428e-03,  2.8322514e-03,\n",
      "         2.6822214e-03,  1.5880787e-03, -1.7129141e-03, -2.6575143e-03,\n",
      "         2.8943925e-03, -2.4336749e-03, -1.6912874e-03,  1.3179526e-03,\n",
      "        -2.3237779e-03,  2.7697305e-03, -1.3854998e-03,  3.0669612e-03,\n",
      "         1.9101114e-03, -2.0207861e-03, -2.3888629e-03,  2.7527714e-03,\n",
      "        -2.4926809e-03,  2.7390199e-03,  1.7253825e-03, -2.9555298e-03,\n",
      "        -2.3666085e-03,  3.0507820e-03, -2.9681264e-03, -1.3094125e-03,\n",
      "         3.1978800e-04, -9.1863872e-04, -2.0971124e-03,  1.0758347e-03,\n",
      "         3.3778718e-03,  1.8034321e-03,  1.4015065e-03,  2.2762297e-03,\n",
      "         2.4026269e-03, -2.1358603e-03,  3.1846252e-03,  1.5199155e-03,\n",
      "         2.5426098e-03,  6.6587824e-04,  2.1991793e-03, -2.7174784e-03,\n",
      "         2.8819877e-03,  2.0178913e-03,  3.2449071e-03,  2.4794179e-03,\n",
      "        -2.9047013e-03,  1.1773499e-03, -1.8502809e-03,  2.4893701e-03,\n",
      "         1.6492490e-03, -1.8225241e-03,  2.5557454e-03, -1.2615204e-03,\n",
      "        -2.4163222e-03,  3.2399569e-03,  2.9074445e-03,  9.1264921e-04,\n",
      "         3.4015956e-03, -2.5421402e-03,  2.0426197e-03, -1.5837031e-03,\n",
      "        -2.7508021e-03, -1.5531182e-03, -2.2251992e-03, -3.0966608e-03,\n",
      "         3.2397704e-03,  2.5320961e-04,  3.2858087e-03,  2.8750126e-03,\n",
      "        -2.3943866e-03,  1.3384742e-03, -2.1427295e-03,  2.4455085e-03,\n",
      "         3.2681136e-03,  2.3881427e-03, -1.7962336e-03,  2.4883498e-03,\n",
      "         2.3385331e-03, -2.0312623e-03,  1.6115329e-03, -2.5725169e-03,\n",
      "        -2.4662013e-03,  1.0228910e-03, -1.7564041e-03, -1.0582712e-03,\n",
      "         2.4791271e-03, -2.1376675e-03,  5.5338285e-04, -3.2896837e-03,\n",
      "        -3.1528743e-03,  3.2758210e-03, -1.3202552e-03, -2.1134114e-03,\n",
      "         1.6279905e-03, -3.4549749e-03,  2.1840089e-03, -2.7542561e-03,\n",
      "        -1.5524863e-03,  1.9415577e-03,  3.7165270e-03, -2.6005488e-03,\n",
      "        -2.4054954e-03,  2.3154595e-03,  1.6500972e-03, -1.5980243e-03,\n",
      "        -2.9503293e-03, -2.7010588e-03, -4.1212878e-04, -2.3266522e-03,\n",
      "        -1.8580754e-03,  1.9278016e-03, -2.5111528e-03,  2.6055041e-03,\n",
      "        -1.7159235e-03, -2.4815970e-03, -3.0578615e-03,  2.0074742e-03,\n",
      "        -1.8327372e-03, -2.6435901e-03,  3.3481573e-03, -1.1665591e-03,\n",
      "         1.9089639e-03,  2.5089064e-03, -1.8029333e-03, -2.1771898e-03,\n",
      "        -2.4581999e-03,  2.7192214e-03, -1.3491232e-03,  2.7162989e-03,\n",
      "        -2.6034636e-03,  2.5410105e-03, -1.7304296e-03,  2.3185620e-03,\n",
      "        -2.6694110e-03,  2.2367851e-03, -1.3653556e-03,  2.7542531e-03,\n",
      "         1.5581384e-03, -2.9521070e-03,  2.1626491e-03, -2.1159642e-03,\n",
      "         2.1981231e-03, -1.6016050e-03,  1.4271443e-03,  2.3657437e-03,\n",
      "         1.2377572e-03, -8.1697770e-04, -1.7886194e-03, -2.1126010e-03,\n",
      "        -3.0413091e-03,  2.5226143e-03,  2.2497934e-03, -2.2902228e-03,\n",
      "        -2.4193719e-03, -3.1059366e-03, -2.1824192e-03,  2.7477662e-03,\n",
      "         3.0510044e-03, -1.1496717e-03,  1.1509240e-03,  1.6378149e-03,\n",
      "         2.4780075e-03,  2.7194500e-03, -2.5785905e-03, -2.1716212e-03,\n",
      "        -2.6270540e-03, -1.0871220e-03,  1.6708429e-03,  1.5063303e-03,\n",
      "         1.8588908e-03, -2.9262083e-03, -2.9580449e-03, -1.7829668e-03,\n",
      "         3.2019543e-03, -2.1509591e-03, -3.3427591e-03, -1.6769115e-03,\n",
      "         2.5307240e-03,  1.5692519e-03, -2.6059733e-03,  1.4408549e-03,\n",
      "         2.5850858e-03, -2.8132165e-03,  1.9802304e-03, -2.8749246e-03,\n",
      "        -2.6931046e-03, -3.2548918e-03, -1.3428063e-03,  3.0612100e-03,\n",
      "        -3.2879999e-03,  2.7079359e-03, -3.2336423e-03, -2.8101422e-03,\n",
      "         2.0913086e-03,  3.1143469e-03, -1.9790847e-03,  1.2466676e-03,\n",
      "         9.2781388e-04,  2.3158216e-03, -2.3607221e-03, -3.4761659e-03,\n",
      "         1.7477014e-03,  2.4976970e-03, -1.1090062e-03,  2.6952683e-03,\n",
      "        -3.0922664e-03, -2.6039046e-03,  2.3390576e-03, -2.5629473e-03,\n",
      "        -3.1111676e-03, -2.0375138e-03, -1.4268759e-03, -2.7286299e-03,\n",
      "        -3.1611747e-03, -4.3557203e-04, -2.0758803e-03, -1.4004997e-03,\n",
      "         2.3605749e-03, -1.7413485e-03, -2.0492605e-03, -9.5961768e-05,\n",
      "         2.4666546e-03, -2.0826331e-03, -3.3249739e-03, -3.1520908e-03,\n",
      "        -3.4140632e-03, -1.4464637e-03,  2.6425140e-03, -7.4577716e-04,\n",
      "         1.8092614e-03, -2.0191211e-03, -9.8204194e-04, -2.7665026e-03,\n",
      "        -2.6351074e-03,  1.2196637e-03,  1.9646343e-03, -1.9661908e-03,\n",
      "         1.0025919e-03, -2.4583258e-03,  2.2497710e-03, -2.8051557e-03,\n",
      "         2.2728983e-03,  2.1492287e-03, -3.2784570e-05, -3.2133113e-03,\n",
      "         2.3606231e-03,  2.1829586e-03,  2.4455418e-03, -2.6167876e-03,\n",
      "        -2.2782318e-03,  2.1087523e-03, -1.8652888e-03,  2.8579526e-03]],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/value/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[ 5.69722056e-03,  1.38181588e-03,  9.80691798e-03, ...,\n",
      "          1.75560452e-02, -5.52639039e-03,  7.82239251e-03],\n",
      "        [ 1.00798653e-02, -4.20924649e-03,  2.75510293e-03, ...,\n",
      "         -1.20963650e-02,  4.65391856e-03,  5.28181950e-03]],\n",
      "\n",
      "       [[-1.20040225e-02,  1.13380328e-02,  1.02174878e-02, ...,\n",
      "          1.82810053e-02, -9.62914608e-04, -8.23250599e-03],\n",
      "        [ 7.42682605e-04, -1.02860145e-02,  2.19076639e-03, ...,\n",
      "         -6.46439730e-04,  5.05527249e-03, -9.32967756e-03]],\n",
      "\n",
      "       [[-1.02172242e-02,  1.56402793e-02,  7.54578179e-03, ...,\n",
      "          1.54305380e-02, -4.87164216e-05, -1.11140581e-02],\n",
      "        [ 3.57839977e-03, -1.99638400e-02, -4.61886823e-03, ...,\n",
      "          1.18632481e-04, -1.00590931e-02, -4.72308462e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-9.32500511e-03, -1.08878268e-02, -1.40632801e-02, ...,\n",
      "         -5.71693247e-03, -2.54523195e-02, -4.84460220e-03],\n",
      "        [-1.27005307e-02,  1.75411794e-02,  2.67479308e-02, ...,\n",
      "          2.54271887e-02,  1.00542372e-02, -6.55789766e-03]],\n",
      "\n",
      "       [[-1.63141154e-02, -3.06193181e-03,  1.53360236e-02, ...,\n",
      "          2.21968926e-02, -3.18787545e-02, -1.76052488e-02],\n",
      "        [-8.46102368e-03, -1.98040344e-02,  1.82411056e-02, ...,\n",
      "          1.16628567e-02, -1.35840185e-03, -7.68122310e-03]],\n",
      "\n",
      "       [[-1.05410479e-02, -4.71053296e-04, -4.10260400e-03, ...,\n",
      "         -9.62795410e-03, -3.37589020e-03,  5.29942045e-04],\n",
      "        [-1.54151348e-02,  2.51368508e-02,  2.12931521e-02, ...,\n",
      "          1.81670897e-02,  1.34691419e-02, -5.16523281e-03]]],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/value/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[-4.80112445e-04,  1.82693731e-03, -3.39048542e-03,\n",
      "         2.58088689e-02,  2.45556398e-03, -1.97993522e-03,\n",
      "        -3.47330235e-03, -2.52794176e-02, -5.29117463e-03,\n",
      "         2.04366464e-02, -1.53775448e-02, -1.91993569e-03,\n",
      "         1.71757266e-02,  6.97568431e-03,  1.64110586e-02,\n",
      "        -1.69578847e-02, -1.44757405e-02,  2.41793040e-03,\n",
      "         5.60657727e-03, -5.15382458e-03, -1.27556762e-02,\n",
      "        -4.44446411e-03, -2.30438018e-04,  1.44167617e-02,\n",
      "        -6.11875905e-04, -2.88405223e-03, -9.32513736e-03,\n",
      "        -2.22865790e-02, -7.58035248e-03, -3.16847255e-03,\n",
      "        -1.77506153e-02, -4.47450066e-03,  1.01477955e-03,\n",
      "         1.66744962e-02,  2.71414849e-03,  5.09836338e-03,\n",
      "        -6.22305041e-03, -6.52501592e-03, -2.19356120e-02,\n",
      "         2.43119476e-03, -2.25542821e-02, -4.75908676e-03,\n",
      "        -1.76522899e-02,  1.31293869e-04,  4.11126483e-03,\n",
      "         1.15027875e-02, -9.96273570e-03,  7.17801740e-03,\n",
      "        -5.11189806e-04, -1.12413047e-02,  4.23868513e-03,\n",
      "         2.70161778e-02,  1.64216198e-02,  1.92768057e-03,\n",
      "        -1.58386159e-04,  6.31064456e-03, -7.94151332e-03,\n",
      "        -7.10495375e-03, -4.45821381e-04, -8.70208081e-04,\n",
      "        -9.77684930e-03,  5.61587093e-03, -4.72078827e-04,\n",
      "         4.75550210e-03, -1.68569759e-02, -2.97146500e-03,\n",
      "         9.85339656e-03,  5.50234970e-03,  5.51311672e-03,\n",
      "         2.73609604e-03,  2.92335008e-03, -3.58088466e-04,\n",
      "        -1.70709379e-02,  3.89586785e-03, -1.64501313e-02,\n",
      "         2.12291852e-02, -7.84727372e-03,  1.76549703e-02,\n",
      "         1.03651490e-02,  5.07630734e-03, -1.04581425e-02,\n",
      "        -5.84162306e-03, -7.90032325e-04,  3.39846709e-04,\n",
      "         1.61111988e-02,  7.13994680e-03, -9.50709078e-03,\n",
      "        -1.87668018e-02,  3.91409127e-03,  1.39496068e-03,\n",
      "         7.11438712e-03,  4.85829031e-03, -1.31326504e-02,\n",
      "        -5.92760742e-04,  3.05796671e-03, -8.23127292e-03,\n",
      "         1.56960636e-02,  1.05075873e-02,  6.25602668e-03,\n",
      "         1.70592349e-02,  2.18360554e-02, -3.08300630e-04,\n",
      "        -1.39653571e-02,  5.65657043e-04,  1.79233233e-04,\n",
      "        -1.11368223e-04, -5.87864965e-03,  6.73964014e-03,\n",
      "         1.63429398e-02, -6.85730856e-03, -2.27805749e-02,\n",
      "         4.93844040e-04,  8.59764777e-03,  5.95535617e-03,\n",
      "         6.88634161e-03, -4.52475809e-03, -1.02259641e-04,\n",
      "        -8.97351839e-03,  8.59806663e-04, -3.45596834e-03,\n",
      "         4.90314094e-03, -8.51043221e-03,  4.36812546e-03,\n",
      "        -1.05275987e-02,  7.23908050e-03,  5.69478748e-03,\n",
      "         1.21477554e-02,  6.30047685e-03, -5.73964976e-03,\n",
      "        -1.28958160e-02,  1.20559183e-04,  1.12614944e-03,\n",
      "        -1.28249032e-03,  4.15599134e-05,  1.99330058e-02,\n",
      "         3.02023045e-03,  1.39656542e-02, -8.30460992e-03,\n",
      "        -1.73936060e-04, -1.99994724e-03, -1.86768128e-03,\n",
      "         1.11699495e-02,  1.42107932e-02, -1.51180997e-02,\n",
      "        -9.22330935e-03,  4.44064615e-03,  4.19302378e-03,\n",
      "         6.79738121e-03,  2.70650517e-02, -2.71105906e-03,\n",
      "         1.31153651e-02, -1.52154472e-02, -6.45732787e-03,\n",
      "         1.63111649e-02, -9.09076538e-03, -1.11576170e-02,\n",
      "        -1.64620969e-02,  8.99935514e-03, -2.31619109e-03,\n",
      "        -8.27562530e-03, -7.40003400e-03,  5.20714605e-03,\n",
      "         1.25072733e-03,  2.10632826e-03, -4.13450459e-03,\n",
      "        -8.93339887e-03, -2.93576531e-03, -2.11820826e-02,\n",
      "         6.09597936e-03,  3.05304420e-03, -1.07870754e-02,\n",
      "        -5.43484930e-03,  9.06665809e-03,  5.57204243e-03,\n",
      "         1.98217873e-02, -4.57523065e-03, -1.70800444e-02,\n",
      "         3.53107520e-04, -1.88121554e-02,  1.04440594e-04,\n",
      "         1.49258943e-02, -3.97643948e-04,  1.13150338e-02,\n",
      "        -1.10535789e-02, -1.71615859e-03,  8.65265902e-05,\n",
      "         3.62350815e-03, -3.19351023e-03,  2.14587012e-03,\n",
      "         2.62659363e-04,  1.84208027e-03,  4.69002547e-03,\n",
      "        -2.35464028e-03, -9.87085141e-03, -1.97808631e-03,\n",
      "         3.11395316e-03,  2.36175694e-02, -6.15550717e-03,\n",
      "         8.58706771e-04, -7.68106431e-03,  1.51500506e-02,\n",
      "         1.60531029e-02,  6.88403007e-03, -3.20077199e-03,\n",
      "        -1.09527018e-02,  1.83251756e-03, -4.46523016e-04,\n",
      "        -6.24177326e-03, -1.53579162e-02, -8.51712469e-03,\n",
      "        -2.61055827e-02,  3.38827749e-03,  8.88713077e-03,\n",
      "        -5.21774869e-03,  8.29223823e-03, -2.71720230e-04,\n",
      "        -8.72850139e-03, -5.60375582e-03, -1.24146845e-02,\n",
      "        -1.82961263e-02, -2.86021046e-02, -3.40329087e-03,\n",
      "        -3.16491793e-03, -1.17358183e-02, -9.67586972e-03,\n",
      "         1.30052492e-02,  8.60337727e-03,  3.88403336e-04,\n",
      "         2.77586095e-03,  5.93129007e-05,  9.64925450e-04,\n",
      "        -1.07352724e-02,  2.54687760e-02,  1.07888682e-02,\n",
      "         1.54995098e-04,  6.15324033e-03, -2.01609358e-03,\n",
      "        -5.50384121e-03, -1.15125347e-02, -1.54229091e-03,\n",
      "        -1.74232498e-02,  1.60519984e-02,  2.45516878e-02,\n",
      "         6.32177899e-03, -1.21855186e-02, -2.34324057e-02,\n",
      "        -5.58744976e-03,  6.79169362e-03, -2.84833778e-02,\n",
      "        -8.27694405e-03,  8.85811076e-03, -1.43919687e-03,\n",
      "         3.12122935e-03, -9.85479355e-03, -4.92414413e-03,\n",
      "        -4.75859456e-03],\n",
      "       [-7.38333445e-03,  1.95772592e-02,  9.46982019e-03,\n",
      "        -4.47296118e-03,  5.58353635e-03,  5.46652242e-04,\n",
      "        -2.38800123e-02,  6.31300127e-03,  6.45213062e-03,\n",
      "        -1.35849845e-02,  8.13738629e-03,  2.19932813e-02,\n",
      "        -9.07815527e-03, -5.06123668e-03, -1.19234982e-03,\n",
      "         8.41673464e-03, -9.08832997e-03,  9.59047582e-03,\n",
      "         7.09033757e-03, -5.39602526e-03,  3.32725141e-03,\n",
      "         1.43633438e-02,  3.38124856e-02, -1.85505708e-03,\n",
      "         2.67843180e-03,  3.04531539e-03,  1.41400713e-02,\n",
      "        -3.21255997e-03, -4.13760683e-03,  5.71520417e-04,\n",
      "        -4.74297768e-03, -1.26638766e-02,  6.85738912e-03,\n",
      "        -7.16123404e-03,  2.25738878e-03, -4.01479006e-03,\n",
      "         1.33419931e-02, -6.39930228e-03,  6.52124733e-03,\n",
      "        -1.93543248e-02, -1.22891124e-02, -2.46059441e-04,\n",
      "        -5.95067814e-03,  9.68430005e-03,  2.50978232e-03,\n",
      "         4.30794293e-03,  9.89719294e-03, -1.39194671e-02,\n",
      "        -7.22412812e-03, -1.52594817e-03,  8.99317954e-03,\n",
      "        -7.42545817e-03, -1.93613977e-03,  2.94701220e-03,\n",
      "         5.79658477e-03, -1.54837465e-03,  4.78574773e-03,\n",
      "         1.18316887e-02, -3.37152719e-03,  2.39875936e-03,\n",
      "         1.55690091e-03,  2.75009219e-03, -8.67752451e-03,\n",
      "         4.59692761e-04, -1.06796401e-03, -3.44208558e-03,\n",
      "         5.66939299e-04, -1.01079643e-02,  1.69128701e-02,\n",
      "         1.82315614e-02, -2.03699041e-02,  1.59003865e-03,\n",
      "         1.08756339e-02, -3.56056611e-03,  1.80485751e-02,\n",
      "        -9.54297092e-03,  8.88263062e-03, -1.35633582e-03,\n",
      "        -9.57771949e-03, -1.37571216e-04,  1.27717322e-02,\n",
      "         2.96819746e-03, -2.29993351e-02, -6.89315191e-03,\n",
      "        -2.26764288e-03,  1.20361906e-03, -1.30884745e-03,\n",
      "         6.59024343e-03,  6.15423732e-03,  2.19502319e-02,\n",
      "        -2.42247502e-03,  3.31393559e-03,  5.16753225e-03,\n",
      "         1.04158802e-03,  1.38907824e-02, -4.21872223e-03,\n",
      "        -2.73438706e-03,  8.34391452e-03,  2.95561366e-03,\n",
      "         2.65599415e-03, -9.24026594e-03, -5.60182566e-03,\n",
      "        -1.44962640e-02,  1.62651367e-03,  1.05901323e-02,\n",
      "        -1.26677230e-02, -1.77635867e-02,  2.29069917e-03,\n",
      "        -6.38280110e-03, -3.60942050e-03, -9.90350265e-03,\n",
      "         1.55835459e-02, -2.25865934e-02, -5.62710408e-03,\n",
      "        -3.92419100e-03, -1.65845267e-03, -2.62732035e-03,\n",
      "         9.52694681e-04, -4.13854839e-03,  1.09943571e-02,\n",
      "         4.07908265e-05, -4.25350014e-03, -2.32888106e-03,\n",
      "         3.70539427e-02, -9.69791436e-04,  1.42060993e-02,\n",
      "        -2.15253420e-03,  3.41993128e-03,  2.68313941e-03,\n",
      "        -2.07784921e-02, -3.54635599e-03,  1.66431665e-02,\n",
      "        -1.81961444e-03, -1.83614269e-02,  4.50661872e-03,\n",
      "        -1.15103340e-02, -7.07868999e-03,  9.48813092e-03,\n",
      "         6.02292875e-03,  1.55712559e-03,  7.62966275e-03,\n",
      "         1.24967685e-02, -3.92500171e-03, -1.45700211e-02,\n",
      "        -1.39918295e-03,  7.52254017e-03, -2.32616551e-02,\n",
      "        -9.61153116e-03,  1.70498993e-02,  1.24682230e-03,\n",
      "        -9.17456299e-03,  1.52844153e-02, -2.02824194e-02,\n",
      "         3.84595385e-03, -4.40205168e-03, -9.70001705e-03,\n",
      "         8.06270260e-03,  6.09880826e-03,  6.53084135e-03,\n",
      "        -8.54168436e-04,  4.49170172e-03,  1.12494864e-02,\n",
      "        -3.84904770e-03,  7.91490637e-03, -3.72630614e-03,\n",
      "         2.65723490e-03, -2.91091558e-02, -1.72009412e-02,\n",
      "         1.50014739e-03, -5.78624720e-04, -1.94689701e-03,\n",
      "        -5.44503098e-03,  6.62938412e-03,  1.31066674e-02,\n",
      "        -2.58988794e-02, -5.38352830e-03,  6.84147095e-03,\n",
      "        -1.89448856e-02, -7.28243915e-03, -9.45474301e-03,\n",
      "         5.62012475e-03, -1.84619874e-02, -1.45807322e-02,\n",
      "        -2.26272480e-03, -2.05278210e-03,  6.38891198e-03,\n",
      "         4.87192767e-03, -2.10867450e-03, -2.29325872e-02,\n",
      "         2.29936969e-02,  4.86874674e-03,  1.71124432e-02,\n",
      "         1.90614928e-02,  1.07254079e-02, -3.48407775e-03,\n",
      "        -7.08231935e-03,  2.67577870e-03, -1.69403688e-03,\n",
      "         2.85392371e-03,  2.73393700e-03,  2.04230156e-02,\n",
      "        -9.07282624e-03, -2.81158602e-03, -1.03124948e-02,\n",
      "         1.12812659e-02,  2.87549030e-02, -5.51206199e-03,\n",
      "        -6.17152138e-04, -1.22620175e-02, -9.21184011e-03,\n",
      "         7.31297722e-03,  1.18622314e-02, -1.48640480e-04,\n",
      "         7.80317374e-03, -5.06707700e-03,  1.50827062e-03,\n",
      "        -3.42502678e-03, -2.39600684e-03,  8.36349907e-04,\n",
      "         1.73260737e-03, -5.92194730e-03, -4.50858526e-04,\n",
      "        -8.36911611e-03,  1.17377182e-02, -1.10735567e-02,\n",
      "         1.13449013e-02,  1.94435418e-02,  1.10345175e-02,\n",
      "        -6.74756989e-03,  1.73626654e-02,  2.00586170e-02,\n",
      "        -7.37389270e-03,  9.20607126e-04,  2.38649249e-02,\n",
      "        -2.16455851e-03, -2.08829548e-02,  4.00345307e-03,\n",
      "         8.94668861e-04,  5.60002448e-03, -1.73205975e-04,\n",
      "        -3.03670508e-03, -3.42888176e-03,  6.33758958e-03,\n",
      "         1.00842342e-02, -9.32368264e-03, -2.35230848e-03,\n",
      "        -3.74053069e-03, -4.99522034e-03, -5.94505924e-04,\n",
      "        -3.01218405e-03, -1.19216768e-02, -1.03537636e-02,\n",
      "        -2.20062714e-02,  5.32677677e-03,  1.24651473e-02,\n",
      "        -1.30954920e-03]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/attention_output/kernel:0' shape=(2, 256, 256) dtype=float32, numpy=\n",
      "array([[[-0.06627491, -0.05115125, -0.02575397, ...,  0.07440324,\n",
      "         -0.01220043, -0.02180736],\n",
      "        [ 0.00767311, -0.07045826, -0.01909415, ...,  0.05993831,\n",
      "         -0.00217992, -0.035649  ],\n",
      "        [ 0.05423113,  0.0347053 , -0.04288366, ...,  0.0716204 ,\n",
      "          0.04279641, -0.02831298],\n",
      "        ...,\n",
      "        [ 0.03665005, -0.00954082, -0.00968216, ..., -0.00268019,\n",
      "         -0.033043  ,  0.04132235],\n",
      "        [-0.07826567, -0.01265202, -0.05806536, ..., -0.0081444 ,\n",
      "          0.06474836,  0.0183478 ],\n",
      "        [ 0.03381025,  0.02749352, -0.05880542, ..., -0.07957155,\n",
      "         -0.0596256 , -0.00938581]],\n",
      "\n",
      "       [[-0.06882027, -0.04355503, -0.02115908, ..., -0.0324252 ,\n",
      "          0.04733945,  0.0919828 ],\n",
      "        [ 0.00338934,  0.06124661,  0.00542536, ...,  0.01612057,\n",
      "          0.06067363,  0.03696968],\n",
      "        [ 0.0358087 ,  0.06695747,  0.08041126, ...,  0.00994698,\n",
      "          0.02631339, -0.07735702],\n",
      "        ...,\n",
      "        [-0.0093443 ,  0.01399944,  0.06208455, ..., -0.06611136,\n",
      "         -0.04366817, -0.02771618],\n",
      "        [-0.01768924,  0.09191341,  0.01689749, ...,  0.00746253,\n",
      "         -0.04895218,  0.02189833],\n",
      "        [-0.0335498 , -0.00352027, -0.0222322 , ..., -0.04377457,\n",
      "          0.01371039,  0.00690212]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/attention_output/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-5.37444046e-03,  2.65640654e-02,  1.93307884e-02, -8.34489800e-03,\n",
      "       -3.97707743e-04, -6.80357777e-03, -1.36380559e-02,  1.44482618e-02,\n",
      "        5.64721599e-03, -4.25048126e-03,  4.94005671e-03, -5.18116122e-03,\n",
      "        7.14527909e-03, -8.95882305e-03, -5.29899728e-03, -1.17744645e-02,\n",
      "        1.84023241e-03,  1.28034805e-03,  3.65175754e-02,  1.15873283e-02,\n",
      "       -1.13276206e-03, -8.06390215e-03,  4.00403477e-02,  1.81483827e-03,\n",
      "       -7.08636537e-04, -2.50222385e-02,  7.68533116e-03,  1.22488923e-02,\n",
      "       -7.69346301e-03, -3.65954149e-03,  2.77495738e-02, -7.69405800e-04,\n",
      "        1.53161609e-03, -5.60855959e-03,  1.37114218e-02, -4.31985129e-03,\n",
      "        1.60896755e-03,  1.56080574e-02,  1.10030320e-04, -1.15059186e-02,\n",
      "        1.84768010e-02,  2.23989133e-02,  1.13923405e-03,  2.25049593e-02,\n",
      "       -5.58004598e-04, -3.39317461e-03, -1.16356183e-03, -9.52714495e-03,\n",
      "        2.99354047e-02,  1.47809100e-03, -1.24000374e-03, -2.19799648e-03,\n",
      "       -1.64488330e-02, -2.13890988e-03, -6.92325062e-04,  3.87422438e-03,\n",
      "       -7.69718364e-03, -1.69394683e-04,  2.74389540e-03, -9.96936671e-03,\n",
      "        2.94588017e-03,  4.59300466e-02,  4.30780128e-02,  1.47019909e-03,\n",
      "        4.45939153e-02, -4.78403270e-03,  7.17666326e-03,  1.23371847e-03,\n",
      "        7.76832830e-03, -6.44487562e-03, -7.66811776e-04,  2.78788689e-03,\n",
      "        1.78405305e-03,  1.41276633e-02,  6.82437932e-03, -2.59009842e-03,\n",
      "       -9.12996940e-03, -6.74716779e-04,  3.82816256e-03,  9.63161699e-03,\n",
      "        3.29112890e-03,  1.04505569e-02,  2.26479047e-03,  3.07040792e-02,\n",
      "       -3.04662017e-03, -1.08776893e-02,  2.20461246e-02,  1.69031220e-04,\n",
      "       -1.51974382e-03,  5.25316829e-03,  7.59724760e-03, -9.17626731e-03,\n",
      "       -9.05602053e-03, -2.70345015e-03, -6.78654294e-04, -8.97839852e-03,\n",
      "        9.23081953e-03,  1.03939511e-03, -4.37160302e-03, -2.12003221e-03,\n",
      "       -3.49457515e-03,  2.82200822e-03, -8.49643163e-03,  5.29177347e-03,\n",
      "       -4.93918196e-04, -6.39423868e-03,  3.41888331e-02, -6.43996941e-03,\n",
      "       -1.41802058e-02,  1.13750175e-02, -7.55159883e-03, -1.39749451e-02,\n",
      "        6.38569612e-03,  3.39626102e-03,  1.97885223e-02, -1.15969786e-02,\n",
      "       -6.32922072e-03, -1.71835013e-02, -1.18375747e-02, -2.97913165e-03,\n",
      "        2.03263704e-02, -7.61032151e-03, -1.37476958e-02, -5.94530581e-03,\n",
      "        3.51873052e-04, -5.71704796e-03,  7.48070003e-03, -1.55565208e-02,\n",
      "       -3.05568823e-03,  3.82533036e-02,  4.51599993e-02,  3.18635032e-02,\n",
      "        1.10517885e-03,  2.67495587e-02, -2.32354784e-03, -2.17784252e-02,\n",
      "        1.17014814e-03, -3.90405324e-03, -4.63393109e-04, -1.21484976e-03,\n",
      "        1.35448575e-03, -9.11618758e-04, -1.74719933e-02, -2.15003989e-03,\n",
      "       -3.07125226e-03, -6.24730019e-03, -3.43290507e-03, -1.46705308e-03,\n",
      "       -3.89232999e-03, -6.99240132e-04, -7.32966326e-03, -8.18273053e-03,\n",
      "       -5.53129765e-04, -2.57576513e-03, -4.93251206e-03,  1.17096864e-02,\n",
      "        2.53781322e-02, -9.56548937e-03,  2.29117014e-02, -1.17562832e-02,\n",
      "        5.42341871e-03,  3.51930666e-03, -3.65729188e-03,  5.63861104e-03,\n",
      "        1.84680633e-02,  3.74454889e-03,  8.52746773e-04, -4.17151675e-03,\n",
      "        8.35062965e-05,  4.13419772e-03, -4.74085240e-03, -6.11745333e-03,\n",
      "       -4.89820668e-04,  1.20844245e-02, -9.60004982e-03, -4.03945288e-03,\n",
      "       -2.08992814e-03, -1.08481012e-02, -4.17259522e-03, -2.87299021e-03,\n",
      "        6.15131808e-03, -1.13792559e-02, -1.83506552e-02,  8.58406164e-03,\n",
      "       -6.50768680e-03, -3.84974666e-03, -5.88674610e-03, -9.52019880e-04,\n",
      "        4.94608562e-03, -5.44687733e-03,  1.10133598e-02,  2.85606692e-03,\n",
      "       -2.76557333e-03,  2.81302165e-02, -1.07788257e-02,  2.44673602e-02,\n",
      "       -1.28606334e-02,  7.66094134e-04,  2.75301188e-02,  5.46627957e-03,\n",
      "        5.10464597e-04, -1.94227472e-02,  2.09182370e-02,  4.61552329e-02,\n",
      "        5.30419685e-02,  1.05085187e-02,  8.55938625e-03, -1.36387879e-02,\n",
      "        1.30224589e-03, -1.04744006e-02, -7.98691064e-03, -1.20033557e-02,\n",
      "        6.07679947e-04,  1.59478504e-02,  5.65712806e-03,  2.96733901e-02,\n",
      "        3.15452777e-02, -5.50278137e-03,  2.38817534e-03, -9.88701452e-03,\n",
      "       -4.38148156e-03,  2.20037792e-02,  4.51830477e-02,  4.66549397e-03,\n",
      "        4.67460137e-03, -2.16768915e-03,  1.21946435e-03, -1.09742666e-02,\n",
      "        7.81751145e-03, -9.30400332e-04, -1.10200504e-02, -1.14577077e-02,\n",
      "       -7.51136709e-03,  3.11274477e-03, -2.32392969e-03,  1.54855512e-02,\n",
      "       -8.88297334e-03, -9.61685728e-04, -4.02232585e-03, -1.53780077e-02,\n",
      "        5.98167753e-05, -3.46980314e-03,  4.05996246e-03,  3.25302929e-02,\n",
      "        2.52780579e-02,  1.13204299e-02, -5.09053748e-03,  2.40058340e-02,\n",
      "        2.14673094e-02, -1.29459240e-02, -3.85313178e-03, -4.28174576e-03,\n",
      "        1.32431220e-02, -9.84528195e-03, -7.97236711e-03, -3.25439014e-02],\n",
      "      dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(256, 32) dtype=float32, numpy=\n",
      "array([[-0.09956627,  0.0733521 ,  0.13273369, ..., -0.06100715,\n",
      "         0.10422991, -0.08688468],\n",
      "       [-0.11897494, -0.14856239,  0.1246138 , ..., -0.08775283,\n",
      "         0.06782766, -0.1459661 ],\n",
      "       [-0.06368046, -0.12536784, -0.03517342, ..., -0.08993744,\n",
      "        -0.10722653, -0.08244801],\n",
      "       ...,\n",
      "       [ 0.12027816, -0.08077545,  0.03720304, ..., -0.11177506,\n",
      "         0.01565615,  0.0457162 ],\n",
      "       [-0.12258943, -0.04253123,  0.14011662, ...,  0.01597271,\n",
      "         0.1361475 , -0.00095134],\n",
      "       [ 0.01311474,  0.08864599,  0.13634834, ...,  0.04942603,\n",
      "        -0.12393627,  0.09550407]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([-3.38940113e-03, -1.43181393e-02,  5.71827550e-05,  3.20175313e-03,\n",
      "        2.54780035e-02, -1.59778830e-03, -3.17913713e-03,  6.97310781e-03,\n",
      "        1.75361726e-02,  7.31024006e-03, -4.37924126e-03,  6.03977591e-03,\n",
      "        3.33219464e-03, -6.43814681e-03, -6.01992570e-03,  8.66823923e-03,\n",
      "        1.13922153e-02,  2.58217612e-03,  1.48589117e-02, -2.82445387e-03,\n",
      "        1.21883042e-02, -1.10406047e-02,  2.46256143e-02,  1.40034379e-02,\n",
      "        6.60330383e-03, -1.47076910e-02, -1.34902121e-02,  2.49169134e-02,\n",
      "        2.56714951e-02, -1.34222675e-02, -3.78139713e-03, -5.77438716e-03],\n",
      "      dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(32, 256) dtype=float32, numpy=\n",
      "array([[ 0.04876836,  0.12734497, -0.12855865, ...,  0.0520364 ,\n",
      "        -0.12425145, -0.013046  ],\n",
      "       [ 0.05005004,  0.08355139,  0.15243725, ..., -0.12722145,\n",
      "        -0.05046501, -0.0651369 ],\n",
      "       [-0.00140422, -0.07161334,  0.09759182, ...,  0.05202462,\n",
      "        -0.11844948,  0.05586337],\n",
      "       ...,\n",
      "       [ 0.10737494,  0.12737197, -0.03406253, ...,  0.04057204,\n",
      "        -0.05545905,  0.1350928 ],\n",
      "       [ 0.05373452,  0.12889087,  0.02865996, ...,  0.04824902,\n",
      "        -0.09962318, -0.08121847],\n",
      "       [-0.1154058 ,  0.04792824, -0.01980044, ...,  0.06651144,\n",
      "        -0.07371715,  0.13161184]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-5.86535409e-03,  3.90136503e-02,  1.81487910e-02, -5.57560008e-03,\n",
      "        1.66632445e-03, -1.51386531e-02, -5.23915887e-03,  4.64877347e-03,\n",
      "        4.39973734e-03, -9.19319410e-03,  4.19102423e-03, -7.16074696e-03,\n",
      "       -1.57898979e-03,  6.80655940e-03, -3.54006700e-03,  7.77666632e-04,\n",
      "       -4.68284683e-03, -8.82197637e-03,  3.98459360e-02,  4.07742783e-02,\n",
      "        4.59695468e-03, -2.12106854e-03,  9.05773640e-02,  4.93883202e-03,\n",
      "       -7.40556139e-03, -5.98568618e-02, -2.14341353e-03,  1.53453546e-02,\n",
      "       -1.77094399e-03, -1.91153884e-02,  8.32524523e-02,  1.57859013e-03,\n",
      "       -4.10237722e-03, -1.14450837e-02,  1.31004322e-02, -6.84251264e-03,\n",
      "        2.95037264e-03,  1.49819236e-02, -8.77308659e-03, -2.01781448e-02,\n",
      "        3.73592833e-03,  1.85645223e-02, -6.31892914e-03,  4.10103053e-02,\n",
      "       -9.89848166e-04, -1.19855311e-02, -1.19112497e-02, -1.13471597e-02,\n",
      "        3.99413109e-02, -3.00814980e-03,  6.71537686e-03, -4.75046784e-03,\n",
      "        2.17579864e-03, -3.47750168e-03,  1.71328394e-03,  8.14430322e-03,\n",
      "        4.73962165e-03,  1.36503987e-02, -3.03697598e-04, -1.40881687e-02,\n",
      "        3.20045487e-03,  1.18846215e-01,  8.75070393e-02, -7.89589714e-03,\n",
      "        6.85069859e-02, -2.77043902e-03,  6.68535591e-04,  5.54204686e-04,\n",
      "        9.13662929e-03, -9.27045010e-03,  8.57090764e-03, -2.38992018e-03,\n",
      "       -2.13086000e-03,  2.67697610e-02, -4.34686057e-03, -8.65839305e-04,\n",
      "        9.83309895e-02,  4.04743943e-03,  2.05301810e-02, -1.35686598e-03,\n",
      "       -1.07993583e-04,  2.26394627e-02,  7.44346436e-03,  1.01635188e-01,\n",
      "       -8.99922743e-04, -9.92921367e-03,  1.27394544e-02, -4.92448499e-03,\n",
      "        3.79246171e-03,  3.29183415e-02,  4.56195138e-02, -1.12717142e-02,\n",
      "       -7.93580525e-03, -1.82938424e-03, -2.57916376e-03, -7.24540465e-03,\n",
      "        1.33476723e-02,  4.87340754e-03, -9.67985578e-03, -2.26552715e-03,\n",
      "       -2.51606456e-03, -2.22313072e-04, -1.84705714e-03,  1.97918457e-03,\n",
      "       -3.67611088e-03, -1.61923934e-02,  4.56767753e-02, -1.57663096e-02,\n",
      "       -1.73449516e-02,  4.96066473e-02, -5.47468383e-03, -1.02983201e-02,\n",
      "        6.01832336e-03,  5.44547429e-03,  3.08112931e-02,  1.39235414e-03,\n",
      "       -1.14020342e-02, -4.43383902e-02, -1.34109128e-02,  2.65705050e-04,\n",
      "        1.42637296e-02, -5.81810344e-03, -1.66453305e-03, -9.77285579e-03,\n",
      "       -1.75469636e-03, -7.02892290e-03,  1.44776783e-03, -1.88283306e-02,\n",
      "       -1.74622722e-02,  9.30762663e-02,  7.93474168e-02,  5.28179556e-02,\n",
      "       -1.25982612e-02,  3.79703864e-02,  1.19024795e-03, -1.40233459e-02,\n",
      "        2.68321438e-03, -6.11793436e-03, -3.01024155e-03, -1.37481932e-02,\n",
      "        1.43915205e-03, -1.33325122e-02, -2.85634659e-02, -6.71405485e-03,\n",
      "       -3.70564731e-03, -3.34914937e-03, -3.51023651e-03, -1.04807541e-02,\n",
      "       -1.18517708e-02, -6.28015725e-03, -1.76499278e-04, -8.16351175e-03,\n",
      "       -2.98399269e-03, -5.11351181e-03, -1.14472145e-02,  1.17125921e-03,\n",
      "        5.04026040e-02, -7.54085230e-03,  6.79088756e-02, -1.88991800e-02,\n",
      "       -4.14572802e-04,  1.05564194e-02, -3.52046522e-03,  6.06999733e-03,\n",
      "        6.64860904e-02, -3.97851516e-04,  2.67217774e-03, -1.35013764e-03,\n",
      "        5.38568804e-03,  7.04575330e-03, -4.11272421e-03, -8.06736480e-03,\n",
      "       -7.77319120e-03,  2.65577156e-02, -5.82275447e-03, -4.15354175e-03,\n",
      "       -1.26738222e-02,  8.19793262e-04, -1.10712070e-02, -1.05653629e-02,\n",
      "        1.02973534e-02, -9.47982073e-03, -8.64892546e-03,  1.54398680e-02,\n",
      "        7.63341878e-03, -1.10366633e-02,  8.88008799e-06, -2.79206363e-03,\n",
      "        4.73575061e-03, -5.76943206e-03,  6.53444696e-03, -3.49577959e-03,\n",
      "       -4.21424350e-03,  4.34806459e-02, -6.32222891e-02,  5.04102260e-02,\n",
      "       -1.49040073e-02, -1.35596038e-03,  7.34590143e-02,  3.22887525e-02,\n",
      "       -6.01257151e-03, -1.23873958e-02,  8.30778033e-02,  8.33081901e-02,\n",
      "        8.94823074e-02, -2.04456924e-03, -7.39558454e-05, -1.03641329e-02,\n",
      "        5.03464276e-03, -6.63557509e-03,  2.43749227e-02, -2.59528738e-02,\n",
      "        4.22867341e-03,  5.74718490e-02,  5.34979021e-03,  1.09582312e-01,\n",
      "        1.09659024e-01, -1.09975049e-02,  3.62878758e-03, -8.41378048e-03,\n",
      "       -5.60903177e-03,  4.98879775e-02,  1.05848901e-01,  5.75940311e-03,\n",
      "        5.48379146e-04,  2.02334882e-03,  6.30228734e-03, -6.87959120e-02,\n",
      "        8.15469958e-03, -1.01087475e-02,  1.36027709e-02, -1.91373588e-03,\n",
      "       -1.59728378e-02, -3.03550577e-03,  4.98348707e-03,  3.53448354e-02,\n",
      "       -2.75439955e-03,  1.37675814e-02,  3.13286693e-03, -9.07140318e-03,\n",
      "        4.88599017e-03, -5.52321260e-04, -3.92579334e-03,  9.04048234e-02,\n",
      "        1.00499555e-01,  3.86567190e-02,  6.35846300e-06,  2.54592635e-02,\n",
      "        4.98218760e-02, -1.27679044e-02, -3.92705342e-03, -3.66226910e-03,\n",
      "        4.69486415e-02,  2.02886946e-03,  4.40150034e-04, -5.91300838e-02],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0.9904153 , 1.0218135 , 1.0094174 , 0.9909501 , 1.001886  ,\n",
      "       0.9855099 , 1.0049094 , 0.9911848 , 0.9978327 , 0.9911524 ,\n",
      "       0.9978999 , 0.99982965, 1.0153455 , 1.0225514 , 0.9881477 ,\n",
      "       0.9874598 , 0.985311  , 0.9873942 , 1.0239377 , 1.0155969 ,\n",
      "       0.99514675, 1.0078868 , 1.0549133 , 1.0032778 , 0.98967606,\n",
      "       1.0289962 , 0.9962458 , 0.9895182 , 0.9963564 , 1.0186417 ,\n",
      "       1.0354418 , 0.99625856, 0.9943373 , 0.9949135 , 1.0073445 ,\n",
      "       1.0026133 , 0.99881494, 1.0058864 , 0.9949917 , 0.9875745 ,\n",
      "       1.0111401 , 1.0002573 , 0.9913992 , 1.0145313 , 0.98437005,\n",
      "       0.98954946, 0.9890392 , 0.9914423 , 1.0352943 , 0.9994361 ,\n",
      "       0.9992824 , 1.0054504 , 1.0107937 , 0.9942595 , 0.99849254,\n",
      "       1.0032976 , 1.0008094 , 1.009343  , 1.003237  , 0.99402106,\n",
      "       0.9970036 , 1.0681313 , 1.0681057 , 0.99187493, 1.0520408 ,\n",
      "       0.9936215 , 0.9885986 , 1.0006217 , 1.004923  , 0.9947753 ,\n",
      "       0.9972865 , 1.0019243 , 0.9940453 , 1.0009115 , 0.98544824,\n",
      "       1.0021815 , 1.0108687 , 1.0006555 , 1.0085005 , 0.9991723 ,\n",
      "       0.99647945, 1.0077751 , 1.0051221 , 1.0481015 , 1.0064634 ,\n",
      "       1.0021825 , 1.0157632 , 0.9934838 , 1.000297  , 1.0072095 ,\n",
      "       1.0268544 , 0.984441  , 0.99947613, 0.99828964, 0.9950006 ,\n",
      "       0.9862876 , 1.014156  , 0.99484664, 0.9890413 , 1.0002596 ,\n",
      "       0.9982602 , 1.0019658 , 1.0092995 , 0.9932139 , 0.9867364 ,\n",
      "       0.98648876, 1.0376158 , 1.0108224 , 0.980835  , 0.9926372 ,\n",
      "       0.9828058 , 1.0044416 , 1.0198733 , 1.0051574 , 1.0041857 ,\n",
      "       1.0099747 , 0.9894502 , 1.0443361 , 0.9819054 , 1.0070987 ,\n",
      "       1.0191507 , 0.9938366 , 1.0059154 , 0.9890674 , 0.9965163 ,\n",
      "       0.9949942 , 0.9993401 , 0.9823519 , 0.9823868 , 1.0488429 ,\n",
      "       1.0490143 , 1.0362445 , 0.98825896, 1.0252995 , 0.99802   ,\n",
      "       0.9998496 , 0.9910651 , 0.9990681 , 0.99273586, 0.99270713,\n",
      "       1.0008647 , 0.99767613, 0.9914229 , 0.9964876 , 0.99344903,\n",
      "       0.99763   , 0.97668403, 0.992359  , 0.99339885, 0.9885017 ,\n",
      "       1.0038232 , 0.9902508 , 1.0012378 , 0.9995673 , 0.99790126,\n",
      "       1.000699  , 1.0210748 , 0.98471487, 1.0415105 , 0.9895903 ,\n",
      "       1.0032911 , 1.0136857 , 0.9991279 , 0.99362177, 1.0251482 ,\n",
      "       0.9953365 , 1.0033594 , 0.98983353, 1.0049703 , 1.0001812 ,\n",
      "       0.9938129 , 0.9920358 , 0.99005014, 1.0142899 , 0.9966056 ,\n",
      "       0.9977165 , 0.985495  , 1.0083134 , 0.987828  , 0.9976783 ,\n",
      "       1.005742  , 0.9954854 , 0.99669904, 1.0039845 , 1.0041163 ,\n",
      "       0.98525536, 1.0007626 , 0.9964073 , 1.0050666 , 0.9936733 ,\n",
      "       1.0081719 , 1.0013627 , 0.9969424 , 1.0265228 , 1.0190758 ,\n",
      "       1.0287704 , 0.9895642 , 0.99126375, 1.0396981 , 1.0108608 ,\n",
      "       0.9955402 , 1.0080421 , 1.0287325 , 1.0723335 , 1.0941048 ,\n",
      "       1.0012013 , 0.9957115 , 1.0069045 , 1.0041249 , 0.9901093 ,\n",
      "       1.0126876 , 0.9860197 , 1.0088097 , 1.0084159 , 1.0025815 ,\n",
      "       1.0463324 , 1.0336202 , 0.99033004, 1.0154384 , 0.9883139 ,\n",
      "       0.9919236 , 1.0239964 , 1.0754524 , 1.0073735 , 0.9988245 ,\n",
      "       0.9981414 , 0.9975907 , 1.0057044 , 1.0030236 , 0.98552185,\n",
      "       1.0075231 , 1.0143392 , 0.9909271 , 0.9891968 , 0.99198496,\n",
      "       1.014622  , 1.0219467 , 1.005055  , 0.9948769 , 1.0004187 ,\n",
      "       1.0019267 , 1.0015501 , 0.9995098 , 1.030563  , 1.0317985 ,\n",
      "       1.0036312 , 0.9980723 , 1.0190363 , 1.0311728 , 0.9927551 ,\n",
      "       0.9973635 , 1.0015486 , 1.0062296 , 0.997261  , 1.0205908 ,\n",
      "       1.0340208 ], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-0.00799345,  0.03462704,  0.02087909, -0.00985075, -0.00341119,\n",
      "       -0.00944223, -0.0077383 ,  0.01323222,  0.00821669, -0.01020515,\n",
      "        0.00301035, -0.00531253,  0.00934094, -0.00444569, -0.00533762,\n",
      "       -0.00619774, -0.00044139, -0.00572814,  0.04238724,  0.0145616 ,\n",
      "        0.0040736 , -0.00766166,  0.05355875,  0.00521458, -0.00144298,\n",
      "       -0.02970035,  0.00684764,  0.0151899 , -0.00238237, -0.00243475,\n",
      "        0.03737685, -0.00382273,  0.00047441, -0.00347358,  0.01518271,\n",
      "       -0.00663661,  0.00335852,  0.01745228, -0.00127492, -0.0146078 ,\n",
      "        0.02123201,  0.02282134,  0.0007921 ,  0.03024936, -0.00064029,\n",
      "       -0.00556268, -0.00489527, -0.01198808,  0.03923461, -0.0015817 ,\n",
      "        0.00566474, -0.00353329, -0.01612666, -0.00151142,  0.00094449,\n",
      "        0.0037093 , -0.0076409 ,  0.00459988,  0.00373036, -0.01570419,\n",
      "        0.0053991 ,  0.05771166,  0.05371556, -0.0035337 ,  0.05327326,\n",
      "       -0.00712428,  0.00258459,  0.00310509,  0.00649369, -0.01007441,\n",
      "       -0.00045496,  0.0019315 ,  0.00210013,  0.01816706,  0.00259625,\n",
      "       -0.00149205,  0.00165875,  0.0023018 ,  0.00627446,  0.00812115,\n",
      "        0.00039348,  0.01213832,  0.00457948,  0.047003  , -0.00283859,\n",
      "       -0.01266363,  0.02420427,  0.00044282, -0.00021387,  0.00731914,\n",
      "        0.01275133, -0.01300864, -0.00987776, -0.00027995, -0.00057363,\n",
      "       -0.00830138,  0.01203076,  0.00178713, -0.00466359, -0.00068203,\n",
      "       -0.00075003,  0.00446769, -0.01037145,  0.00527351, -0.00238769,\n",
      "       -0.01189549,  0.04279372, -0.00822122, -0.0146838 ,  0.02053305,\n",
      "       -0.00503872, -0.01316642,  0.00594397,  0.00331765,  0.02394507,\n",
      "       -0.01061673, -0.01153868, -0.02102356, -0.01278442, -0.00455436,\n",
      "        0.02446339, -0.0023431 , -0.01264788, -0.00626477,  0.00273658,\n",
      "       -0.01116811,  0.00983778, -0.02058357, -0.00738825,  0.0501517 ,\n",
      "        0.05818306,  0.03963539, -0.00080209,  0.03129559,  0.00144713,\n",
      "       -0.02472671,  0.0015881 , -0.00693849, -0.00150881, -0.00223915,\n",
      "        0.00311462, -0.00644552, -0.02243732, -0.00465826, -0.0025977 ,\n",
      "       -0.0040482 , -0.00424097, -0.00449618, -0.00880562, -0.00143233,\n",
      "       -0.00447985, -0.00764571,  0.00088873, -0.00148461, -0.00762004,\n",
      "        0.01374038,  0.03239903, -0.00615135,  0.02762651, -0.01202165,\n",
      "        0.00551601,  0.00636883, -0.00105581,  0.00608018,  0.02461372,\n",
      "        0.00115572,  0.00174125, -0.00614457, -0.00317547,  0.00388385,\n",
      "       -0.00391945, -0.00484154,  0.0005081 ,  0.01557742, -0.00791775,\n",
      "       -0.00264331, -0.00529206, -0.00877539, -0.00643082, -0.00316663,\n",
      "        0.00933122, -0.01091909, -0.01485689,  0.00886819, -0.00657718,\n",
      "       -0.00466723, -0.00618407, -0.00224395,  0.00217284, -0.00475092,\n",
      "        0.01071625,  0.00208311, -0.00100927,  0.04209391, -0.01150899,\n",
      "        0.03186654, -0.01211091,  0.00177387,  0.03819464,  0.00840498,\n",
      "        0.00193906, -0.02182526,  0.02780755,  0.05955662,  0.06915312,\n",
      "        0.00990529,  0.00539198, -0.01356885,  0.00253246, -0.00896219,\n",
      "       -0.0052849 , -0.01927737,  0.00110653,  0.02510773,  0.00862174,\n",
      "        0.04497347,  0.04353537, -0.00655797,  0.00123992, -0.01325661,\n",
      "       -0.0032417 ,  0.03079099,  0.06041409,  0.0072358 ,  0.00243771,\n",
      "       -0.00066751,  0.00068126, -0.0139267 ,  0.0111863 , -0.00208106,\n",
      "       -0.00714222, -0.00820664, -0.01143571,  0.00183813, -0.00125743,\n",
      "        0.01792285, -0.00536442, -0.0006487 , -0.00078764, -0.01581703,\n",
      "        0.00386797, -0.00413243,  0.00377716,  0.04169385,  0.04501894,\n",
      "        0.01817907, -0.00134801,  0.02845194,  0.02661488, -0.01503856,\n",
      "       -0.00565083, -0.00202738,  0.01678121, -0.00523225, -0.00442096,\n",
      "       -0.03743429], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization_1/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0.98921806, 0.98085374, 0.99571395, 0.9870812 , 0.98683375,\n",
      "       0.9760332 , 0.97443867, 0.9737671 , 0.9865155 , 0.98619765,\n",
      "       0.988989  , 0.9958761 , 0.9892373 , 0.98382396, 0.98988736,\n",
      "       0.9776053 , 0.9866523 , 0.98166496, 0.9835996 , 0.99788344,\n",
      "       0.97984767, 0.9983296 , 0.9898685 , 0.9865293 , 0.9914149 ,\n",
      "       0.96718717, 0.98741233, 0.97150743, 0.9835289 , 0.9795174 ,\n",
      "       0.9873629 , 0.9909364 , 0.9861736 , 0.9862437 , 0.9910628 ,\n",
      "       0.99646395, 0.9843    , 0.9993    , 0.99003434, 0.98849094,\n",
      "       0.99687827, 0.9813348 , 0.9903367 , 0.98894405, 0.9829735 ,\n",
      "       0.9859126 , 0.9881718 , 0.9810663 , 0.98471713, 0.992623  ,\n",
      "       0.97969633, 0.9998048 , 0.9925561 , 0.98895365, 0.9909312 ,\n",
      "       0.9961248 , 0.991246  , 0.9853847 , 1.0025272 , 0.98079157,\n",
      "       0.9962481 , 0.9836286 , 0.9897415 , 0.98340404, 0.9803037 ,\n",
      "       0.9933018 , 0.97562355, 0.9888678 , 0.99694175, 0.9909139 ,\n",
      "       0.9927048 , 0.988168  , 0.9902741 , 0.98021126, 0.9722394 ,\n",
      "       0.99208486, 0.96756595, 0.9879205 , 0.9970165 , 0.9820344 ,\n",
      "       0.9916767 , 0.98346263, 0.99552405, 0.97800815, 0.9941075 ,\n",
      "       0.99254763, 0.9889517 , 0.9919981 , 1.0023775 , 0.9804838 ,\n",
      "       0.9907507 , 0.97595906, 0.9915796 , 0.9883364 , 0.9867096 ,\n",
      "       0.9843077 , 0.99964076, 0.9957167 , 0.98406804, 0.9847614 ,\n",
      "       0.98713166, 0.99151725, 1.0015169 , 0.9879471 , 0.97938114,\n",
      "       0.97429484, 0.9856052 , 0.9707572 , 0.9778831 , 0.9767845 ,\n",
      "       0.98080724, 0.9955912 , 0.9920863 , 0.99564147, 0.9784708 ,\n",
      "       0.9941567 , 0.98538977, 0.987788  , 0.9780676 , 0.99710983,\n",
      "       0.9945937 , 0.9751934 , 0.9895308 , 0.98294604, 0.99039793,\n",
      "       0.9801859 , 0.99066156, 0.97470576, 1.0015098 , 0.9772022 ,\n",
      "       0.9848799 , 0.98643965, 0.98369074, 0.9873669 , 0.99100065,\n",
      "       0.98024434, 0.985193  , 0.9907101 , 0.9927824 , 0.9842814 ,\n",
      "       0.99442005, 0.99487484, 0.9900249 , 0.9954511 , 0.986612  ,\n",
      "       0.98094517, 0.9697323 , 0.98500586, 0.9847711 , 0.97979367,\n",
      "       0.9971922 , 0.9870913 , 0.9900923 , 0.9886614 , 0.99773735,\n",
      "       0.9919641 , 0.9846056 , 0.98270684, 0.9909124 , 0.9948152 ,\n",
      "       0.9918336 , 0.9983857 , 0.9764169 , 0.9955651 , 0.98735   ,\n",
      "       0.98833406, 1.0007439 , 0.98384196, 0.996456  , 0.99247104,\n",
      "       0.98929733, 0.9900861 , 0.98457223, 0.9876869 , 0.9805948 ,\n",
      "       0.98966265, 0.9851698 , 0.9915207 , 0.98298275, 0.9917238 ,\n",
      "       0.9847531 , 0.9785993 , 0.9824941 , 0.98837256, 0.9882318 ,\n",
      "       0.98121303, 0.9951884 , 0.98088205, 0.9978828 , 0.98494947,\n",
      "       0.99741673, 1.0082844 , 0.9920967 , 0.98065954, 0.9929183 ,\n",
      "       0.9865198 , 0.98075396, 0.9868806 , 0.97662145, 0.9948782 ,\n",
      "       0.99064714, 0.9759579 , 0.9765734 , 0.9847689 , 0.97578126,\n",
      "       0.9977086 , 0.97010636, 0.98440474, 0.9981454 , 0.98701113,\n",
      "       0.98911947, 0.9718192 , 0.996575  , 0.9886519 , 0.9947113 ,\n",
      "       0.9706321 , 0.9472058 , 0.9843931 , 0.9977135 , 0.9860551 ,\n",
      "       0.9806901 , 0.9888339 , 0.9600887 , 0.9877393 , 0.98992497,\n",
      "       0.98956096, 0.98655725, 0.9620004 , 0.9918941 , 0.981699  ,\n",
      "       0.9983543 , 0.9951718 , 0.9826492 , 0.98403686, 0.98272574,\n",
      "       1.0094336 , 0.975057  , 1.0018166 , 0.9845699 , 0.9924369 ,\n",
      "       0.99061847, 0.9923773 , 0.9962798 , 0.9914279 , 0.99307835,\n",
      "       0.9811612 , 0.9836417 , 0.9936036 , 0.9888692 , 0.9839119 ,\n",
      "       1.0005159 , 0.9816324 , 0.9844798 , 0.97235274, 0.984369  ,\n",
      "       0.9664861 ], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization_1/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-1.69655569e-02, -1.89164113e-02, -5.57746645e-03, -3.12556815e-03,\n",
      "       -2.03389842e-02, -3.76140513e-02,  1.77269690e-02, -3.30872685e-02,\n",
      "       -4.09985334e-03, -2.16740575e-02, -1.45372283e-02, -9.24069807e-03,\n",
      "        1.25933858e-02,  2.40544528e-02, -1.30252843e-03,  2.08104192e-03,\n",
      "       -1.73521973e-02, -2.95193251e-02, -1.80420242e-02, -5.08482801e-03,\n",
      "        9.83445067e-03, -7.56233558e-03, -1.07393898e-02,  1.18924575e-02,\n",
      "       -1.55905355e-02,  1.18159121e-02, -1.10276500e-02, -3.24137397e-02,\n",
      "        5.40302740e-03,  2.00993661e-02, -1.16840731e-02, -2.43467651e-02,\n",
      "       -2.04079840e-02, -1.27062881e-02, -8.50256719e-03, -8.26991722e-03,\n",
      "        6.49548555e-03, -2.46792682e-03, -1.82362460e-02, -3.02634835e-02,\n",
      "       -4.76847589e-03, -2.30500083e-02, -1.41526675e-02, -1.40168639e-02,\n",
      "       -1.20214093e-02, -2.41795443e-02, -2.69600190e-02, -2.65560187e-02,\n",
      "       -1.75988041e-02, -1.85566973e-02,  1.76640656e-02, -1.01509755e-02,\n",
      "        2.28963676e-03, -4.53980314e-03, -1.08360508e-02, -1.39855444e-02,\n",
      "       -9.66456428e-04,  2.00302564e-02,  2.49404996e-03, -3.24176140e-02,\n",
      "       -1.25994133e-02, -1.48009202e-02, -7.72571331e-03, -2.55418643e-02,\n",
      "       -1.89252645e-02, -1.43545028e-02, -3.78624350e-02,  1.33235464e-02,\n",
      "       -1.89294666e-03, -1.84185971e-02, -1.90609030e-03, -1.41559355e-03,\n",
      "       -1.05192019e-02, -2.13689879e-02, -3.59118991e-02, -3.13278963e-03,\n",
      "       -2.44427565e-02,  6.75425958e-03,  4.85499622e-03, -2.43790299e-02,\n",
      "       -1.19984103e-02, -2.64322627e-02,  7.33920000e-03, -2.10094023e-02,\n",
      "        5.15274936e-04, -1.25050982e-02, -1.32588428e-02, -1.37848193e-02,\n",
      "       -1.35061890e-03, -2.28710640e-02, -9.06452816e-03, -3.25461552e-02,\n",
      "       -6.12054300e-03, -7.02881545e-04, -1.91871338e-02, -4.90257842e-03,\n",
      "        8.41411296e-03, -4.02167765e-03, -1.58044659e-02, -4.09802049e-03,\n",
      "       -8.11735401e-04,  8.63845198e-05, -8.39329045e-03, -7.18457112e-03,\n",
      "       -2.50049420e-02, -3.50036956e-02, -1.68608259e-02,  9.41506308e-03,\n",
      "       -1.72305629e-02, -2.29984652e-02, -3.01841437e-03, -1.30545618e-02,\n",
      "        8.15360714e-03, -3.02092778e-03, -2.31496356e-02,  2.80430517e-03,\n",
      "       -3.17274816e-02,  1.96114089e-02, -2.15622243e-02, -2.25738948e-03,\n",
      "        6.58553420e-03,  2.95838318e-03,  3.87964945e-04, -1.62164047e-02,\n",
      "       -4.93003661e-03, -3.48280333e-02, -3.98962339e-03, -3.37292925e-02,\n",
      "       -2.66584475e-02, -2.42366474e-02, -1.47047201e-02, -1.42069347e-02,\n",
      "       -3.28170359e-02, -1.76703203e-02, -3.92955309e-03, -1.54787423e-02,\n",
      "       -1.53009873e-02, -1.40582453e-02, -1.68428402e-02, -1.51017634e-02,\n",
      "        6.46430859e-03, -2.88559645e-02, -3.59269306e-02, -1.45611735e-02,\n",
      "       -1.34156328e-02,  2.24971166e-03, -3.34651060e-02, -3.26731950e-02,\n",
      "       -2.15444621e-02, -2.82069314e-02,  7.88004044e-03, -1.63367819e-02,\n",
      "       -1.38757494e-03, -6.49481546e-04, -1.69711504e-02, -1.34358127e-02,\n",
      "       -1.69134792e-02, -1.19781271e-02, -6.37260778e-03, -1.88395642e-02,\n",
      "       -1.59012135e-02,  1.17715681e-02, -8.55778489e-05, -1.26778902e-02,\n",
      "       -1.51196066e-02, -1.82073973e-02, -1.78741722e-03, -1.98154319e-02,\n",
      "       -7.33136944e-03, -1.07659755e-04, -5.36335818e-03, -3.76422028e-03,\n",
      "       -1.15804849e-02,  8.80122837e-03,  3.86574684e-04, -2.71952152e-03,\n",
      "       -2.13252865e-02, -3.32427560e-03, -2.19426490e-02, -1.24687748e-02,\n",
      "       -1.77774373e-02, -6.51578140e-03, -9.52924602e-03, -1.91703979e-02,\n",
      "       -4.19356022e-03, -1.26713458e-02,  1.41750940e-03, -2.29909271e-02,\n",
      "       -1.12510351e-02, -7.37922732e-03,  1.24546688e-03, -1.33515960e-02,\n",
      "       -3.16849840e-03, -1.85999535e-02,  3.88346449e-03, -9.17920936e-03,\n",
      "       -1.56957246e-02, -4.31053294e-03, -2.30456665e-02, -8.02383758e-03,\n",
      "       -4.86062653e-03,  9.18667181e-04, -2.42986083e-02, -1.35652171e-02,\n",
      "       -2.22286191e-02, -1.02236252e-02, -3.70083079e-02,  7.91151449e-03,\n",
      "       -7.35198322e-04, -3.17772897e-03,  9.20119230e-03, -4.64181192e-02,\n",
      "       -9.45196301e-03, -7.82994833e-03, -5.94695564e-03, -2.32257992e-02,\n",
      "       -4.82612103e-02, -1.87291261e-02,  4.24349168e-03, -2.20274348e-02,\n",
      "       -6.03350019e-03, -1.26342708e-02, -3.36279273e-02, -1.85719058e-02,\n",
      "       -1.54364165e-02,  7.02761929e-04, -1.48687763e-02,  2.25279666e-02,\n",
      "        7.20103737e-03, -2.72000842e-02,  1.40406871e-02,  4.67178319e-03,\n",
      "       -3.25988345e-02, -2.07942147e-02, -2.10202113e-02,  1.84780639e-02,\n",
      "        1.56919193e-02, -1.45908771e-02,  4.52752830e-03, -8.46360717e-03,\n",
      "        1.15373880e-02, -9.19302460e-03, -1.38460351e-02, -7.64471479e-03,\n",
      "       -6.63505588e-03, -2.23247036e-02,  7.81114399e-03, -7.18884403e-03,\n",
      "       -1.39535451e-02, -1.81741845e-02, -1.18126329e-02,  7.01049622e-03,\n",
      "       -1.55713446e-02,  1.23417405e-02,  1.02782585e-02,  1.36639150e-02],\n",
      "      dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(256, 1) dtype=float32, numpy=\n",
      "array([[-0.10074419],\n",
      "       [-0.01058034],\n",
      "       [-0.04488105],\n",
      "       [-0.13693297],\n",
      "       [ 0.07752278],\n",
      "       [ 0.06870764],\n",
      "       [-0.03763139],\n",
      "       [-0.04578247],\n",
      "       [ 0.06345737],\n",
      "       [-0.11919942],\n",
      "       [ 0.10460275],\n",
      "       [ 0.14653726],\n",
      "       [-0.02951072],\n",
      "       [ 0.04184206],\n",
      "       [-0.13558477],\n",
      "       [ 0.10756903],\n",
      "       [-0.10052765],\n",
      "       [-0.11216532],\n",
      "       [ 0.02023418],\n",
      "       [ 0.01513903],\n",
      "       [-0.11620139],\n",
      "       [ 0.15006855],\n",
      "       [-0.01084159],\n",
      "       [-0.13164955],\n",
      "       [ 0.10102312],\n",
      "       [ 0.00431274],\n",
      "       [-0.07853703],\n",
      "       [ 0.0119028 ],\n",
      "       [ 0.11691019],\n",
      "       [-0.00906952],\n",
      "       [-0.0102849 ],\n",
      "       [-0.05936806],\n",
      "       [ 0.08019375],\n",
      "       [-0.0740558 ],\n",
      "       [ 0.05006518],\n",
      "       [-0.10818585],\n",
      "       [-0.12306381],\n",
      "       [ 0.06421729],\n",
      "       [-0.06551794],\n",
      "       [ 0.08424528],\n",
      "       [-0.08097576],\n",
      "       [ 0.04126705],\n",
      "       [-0.09697039],\n",
      "       [-0.0106492 ],\n",
      "       [-0.0954331 ],\n",
      "       [ 0.11058211],\n",
      "       [ 0.10413843],\n",
      "       [ 0.07824519],\n",
      "       [-0.01814502],\n",
      "       [-0.1331494 ],\n",
      "       [ 0.1264818 ],\n",
      "       [-0.1298898 ],\n",
      "       [ 0.05571537],\n",
      "       [-0.13768272],\n",
      "       [ 0.05022189],\n",
      "       [-0.0478263 ],\n",
      "       [ 0.07773467],\n",
      "       [-0.10536595],\n",
      "       [-0.07452224],\n",
      "       [ 0.12208598],\n",
      "       [ 0.07053415],\n",
      "       [ 0.00626797],\n",
      "       [ 0.00808619],\n",
      "       [-0.09110814],\n",
      "       [ 0.0048289 ],\n",
      "       [-0.14118582],\n",
      "       [-0.04217791],\n",
      "       [ 0.02765056],\n",
      "       [ 0.06888257],\n",
      "       [-0.13253   ],\n",
      "       [ 0.03885093],\n",
      "       [-0.12981692],\n",
      "       [ 0.08060071],\n",
      "       [-0.0183046 ],\n",
      "       [ 0.0740997 ],\n",
      "       [ 0.14315844],\n",
      "       [ 0.00106195],\n",
      "       [ 0.1376059 ],\n",
      "       [ 0.01779849],\n",
      "       [ 0.08128478],\n",
      "       [ 0.07446382],\n",
      "       [-0.02569247],\n",
      "       [ 0.11567263],\n",
      "       [ 0.00695955],\n",
      "       [ 0.08442642],\n",
      "       [ 0.13134049],\n",
      "       [ 0.02523119],\n",
      "       [-0.13502495],\n",
      "       [-0.05278282],\n",
      "       [-0.01829521],\n",
      "       [-0.00970464],\n",
      "       [ 0.06000728],\n",
      "       [-0.10556197],\n",
      "       [-0.11791156],\n",
      "       [ 0.06705616],\n",
      "       [-0.06782246],\n",
      "       [-0.03802562],\n",
      "       [-0.06974119],\n",
      "       [ 0.12440996],\n",
      "       [ 0.1295417 ],\n",
      "       [ 0.11197092],\n",
      "       [ 0.09457619],\n",
      "       [-0.05271872],\n",
      "       [-0.08480508],\n",
      "       [-0.04295214],\n",
      "       [-0.09662694],\n",
      "       [-0.01587793],\n",
      "       [-0.01756635],\n",
      "       [-0.09172557],\n",
      "       [ 0.01224453],\n",
      "       [ 0.04217371],\n",
      "       [-0.01222414],\n",
      "       [-0.0223204 ],\n",
      "       [-0.07515173],\n",
      "       [ 0.02743035],\n",
      "       [ 0.12715471],\n",
      "       [-0.09340447],\n",
      "       [ 0.00426591],\n",
      "       [-0.05552968],\n",
      "       [ 0.12498465],\n",
      "       [-0.04001683],\n",
      "       [ 0.06718705],\n",
      "       [ 0.05734583],\n",
      "       [ 0.09545641],\n",
      "       [ 0.10746223],\n",
      "       [-0.06459093],\n",
      "       [ 0.08814354],\n",
      "       [-0.11450434],\n",
      "       [-0.07306922],\n",
      "       [-0.00847846],\n",
      "       [ 0.00262441],\n",
      "       [ 0.00511662],\n",
      "       [ 0.07800147],\n",
      "       [-0.01251965],\n",
      "       [ 0.1134311 ],\n",
      "       [ 0.09658507],\n",
      "       [-0.04511158],\n",
      "       [-0.09112217],\n",
      "       [ 0.11380041],\n",
      "       [-0.08394989],\n",
      "       [ 0.05700862],\n",
      "       [-0.04698101],\n",
      "       [ 0.13407125],\n",
      "       [-0.09909844],\n",
      "       [ 0.10268531],\n",
      "       [-0.09108178],\n",
      "       [ 0.02184421],\n",
      "       [ 0.09207641],\n",
      "       [ 0.10060735],\n",
      "       [ 0.07762908],\n",
      "       [-0.0791875 ],\n",
      "       [-0.0941481 ],\n",
      "       [-0.09623067],\n",
      "       [-0.08315846],\n",
      "       [-0.09417289],\n",
      "       [-0.07123271],\n",
      "       [-0.00808799],\n",
      "       [-0.05972775],\n",
      "       [-0.00223861],\n",
      "       [ 0.09181694],\n",
      "       [ 0.05213688],\n",
      "       [-0.07698003],\n",
      "       [-0.12574503],\n",
      "       [ 0.02663687],\n",
      "       [ 0.00113618],\n",
      "       [-0.09027856],\n",
      "       [ 0.10906891],\n",
      "       [-0.05631819],\n",
      "       [-0.03439461],\n",
      "       [ 0.07258245],\n",
      "       [-0.09619135],\n",
      "       [ 0.0948706 ],\n",
      "       [ 0.10149006],\n",
      "       [-0.00031353],\n",
      "       [ 0.10638917],\n",
      "       [ 0.10531703],\n",
      "       [ 0.06632449],\n",
      "       [ 0.07164097],\n",
      "       [-0.0744971 ],\n",
      "       [-0.13781826],\n",
      "       [-0.03051728],\n",
      "       [ 0.12276156],\n",
      "       [-0.06595089],\n",
      "       [-0.04356789],\n",
      "       [-0.00901273],\n",
      "       [ 0.10820853],\n",
      "       [-0.11059011],\n",
      "       [-0.05942325],\n",
      "       [-0.06245459],\n",
      "       [ 0.08390795],\n",
      "       [-0.09221423],\n",
      "       [-0.10887861],\n",
      "       [-0.10883094],\n",
      "       [ 0.00879752],\n",
      "       [-0.01644914],\n",
      "       [ 0.01230658],\n",
      "       [ 0.11368773],\n",
      "       [ 0.12211256],\n",
      "       [-0.00902944],\n",
      "       [ 0.01918247],\n",
      "       [ 0.09244868],\n",
      "       [ 0.01672452],\n",
      "       [-0.00188186],\n",
      "       [-0.00613365],\n",
      "       [-0.00125347],\n",
      "       [-0.05062804],\n",
      "       [ 0.04074489],\n",
      "       [-0.05960395],\n",
      "       [-0.11221341],\n",
      "       [-0.0710455 ],\n",
      "       [-0.00488899],\n",
      "       [ 0.09873195],\n",
      "       [-0.03407212],\n",
      "       [-0.01133122],\n",
      "       [ 0.07616309],\n",
      "       [ 0.00150445],\n",
      "       [-0.00885292],\n",
      "       [ 0.12231314],\n",
      "       [-0.08258314],\n",
      "       [-0.06472397],\n",
      "       [ 0.11403105],\n",
      "       [ 0.01679954],\n",
      "       [ 0.00201043],\n",
      "       [ 0.01104551],\n",
      "       [ 0.13010547],\n",
      "       [ 0.11249878],\n",
      "       [-0.05614305],\n",
      "       [ 0.00516226],\n",
      "       [ 0.10389545],\n",
      "       [ 0.08846912],\n",
      "       [ 0.03697421],\n",
      "       [ 0.07291222],\n",
      "       [-0.07981824],\n",
      "       [-0.04502392],\n",
      "       [-0.04375886],\n",
      "       [-0.04006658],\n",
      "       [-0.00956747],\n",
      "       [-0.02964149],\n",
      "       [-0.11069926],\n",
      "       [-0.11015812],\n",
      "       [-0.13253585],\n",
      "       [-0.08576323],\n",
      "       [ 0.06584324],\n",
      "       [ 0.01167415],\n",
      "       [-0.01633348],\n",
      "       [-0.00536261],\n",
      "       [ 0.12327022],\n",
      "       [-0.03306184],\n",
      "       [ 0.00299461],\n",
      "       [-0.10966357],\n",
      "       [ 0.13423054],\n",
      "       [-0.04981562],\n",
      "       [ 0.00525665],\n",
      "       [ 0.11914454],\n",
      "       [ 0.03828417],\n",
      "       [-0.00454372]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.00028618], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/782 [============>.................] - ETA: 1:33 - loss: 1.0997 - accuracy: 0.5491"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m/home/franc/posit_transformer.ipynb Cell 14\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/franc/posit_transformer.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mTest acc: \u001B[39m\u001B[39m{\u001B[39;00mmodel\u001B[39m.\u001B[39mevaluate(int_test_ds)[\u001B[39m1\u001B[39m]\u001B[39m:\u001B[39;00m\u001B[39m.3f\u001B[39m\u001B[39m}\u001B[39;00m\u001B[39m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1509\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   1507\u001B[0m \u001B[39mwith\u001B[39;00m trace\u001B[39m.\u001B[39mTrace(\u001B[39m'\u001B[39m\u001B[39mtest\u001B[39m\u001B[39m'\u001B[39m, step_num\u001B[39m=\u001B[39mstep, _r\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m):\n\u001B[1;32m   1508\u001B[0m   callbacks\u001B[39m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 1509\u001B[0m   tmp_logs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtest_function(iterator)\n\u001B[1;32m   1510\u001B[0m   \u001B[39mif\u001B[39;00m data_handler\u001B[39m.\u001B[39mshould_sync:\n\u001B[1;32m   1511\u001B[0m     context\u001B[39m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    882\u001B[0m compiler \u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mxla\u001B[39m\u001B[39m\"\u001B[39m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_jit_compile \u001B[39melse\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39mnonXla\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    884\u001B[0m \u001B[39mwith\u001B[39;00m OptionalXlaContext(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 885\u001B[0m   result \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_call(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwds)\n\u001B[1;32m    887\u001B[0m new_tracing_count \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    888\u001B[0m without_tracing \u001B[39m=\u001B[39m (tracing_count \u001B[39m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:924\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    921\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_lock\u001B[39m.\u001B[39mrelease()\n\u001B[1;32m    922\u001B[0m \u001B[39m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    923\u001B[0m \u001B[39m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 924\u001B[0m results \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_stateful_fn(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwds)\n\u001B[1;32m    925\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_created_variables \u001B[39mand\u001B[39;00m \u001B[39mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[1;32m    926\u001B[0m   \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\u001B[39m\"\u001B[39m\u001B[39mCreating variables on a non-first call to a function\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    927\u001B[0m                    \u001B[39m\"\u001B[39m\u001B[39m decorated with tf.function.\u001B[39m\u001B[39m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3032\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3029\u001B[0m \u001B[39mwith\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_lock:\n\u001B[1;32m   3030\u001B[0m   (graph_function,\n\u001B[1;32m   3031\u001B[0m    filtered_flat_args) \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3032\u001B[0m \u001B[39mreturn\u001B[39;00m graph_function\u001B[39m.\u001B[39;49m_call_flat(\n\u001B[1;32m   3033\u001B[0m     filtered_flat_args, captured_inputs\u001B[39m=\u001B[39;49mgraph_function\u001B[39m.\u001B[39;49mcaptured_inputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1956\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1952\u001B[0m possible_gradient_type \u001B[39m=\u001B[39m gradients_util\u001B[39m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1953\u001B[0m \u001B[39mif\u001B[39;00m (possible_gradient_type \u001B[39m==\u001B[39m gradients_util\u001B[39m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1954\u001B[0m     \u001B[39mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1955\u001B[0m   \u001B[39m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1956\u001B[0m   \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_build_call_outputs(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_inference_function\u001B[39m.\u001B[39;49mcall(\n\u001B[1;32m   1957\u001B[0m       ctx, args, cancellation_manager\u001B[39m=\u001B[39;49mcancellation_manager))\n\u001B[1;32m   1958\u001B[0m forward_backward \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1959\u001B[0m     args,\n\u001B[1;32m   1960\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1961\u001B[0m     executing_eagerly)\n\u001B[1;32m   1962\u001B[0m forward_function, args_with_tangents \u001B[39m=\u001B[39m forward_backward\u001B[39m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m \u001B[39mwith\u001B[39;00m _InterpolateFunctionError(\u001B[39mself\u001B[39m):\n\u001B[1;32m    590\u001B[0m   \u001B[39mif\u001B[39;00m cancellation_manager \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m--> 591\u001B[0m     outputs \u001B[39m=\u001B[39m execute\u001B[39m.\u001B[39;49mexecute(\n\u001B[1;32m    592\u001B[0m         \u001B[39mstr\u001B[39;49m(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49msignature\u001B[39m.\u001B[39;49mname),\n\u001B[1;32m    593\u001B[0m         num_outputs\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_num_outputs,\n\u001B[1;32m    594\u001B[0m         inputs\u001B[39m=\u001B[39;49margs,\n\u001B[1;32m    595\u001B[0m         attrs\u001B[39m=\u001B[39;49mattrs,\n\u001B[1;32m    596\u001B[0m         ctx\u001B[39m=\u001B[39;49mctx)\n\u001B[1;32m    597\u001B[0m   \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    598\u001B[0m     outputs \u001B[39m=\u001B[39m execute\u001B[39m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    599\u001B[0m         \u001B[39mstr\u001B[39m(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39msignature\u001B[39m.\u001B[39mname),\n\u001B[1;32m    600\u001B[0m         num_outputs\u001B[39m=\u001B[39m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    603\u001B[0m         ctx\u001B[39m=\u001B[39mctx,\n\u001B[1;32m    604\u001B[0m         cancellation_manager\u001B[39m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/miniconda3/envs/seai/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m     58\u001B[0m   ctx\u001B[39m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 59\u001B[0m   tensors \u001B[39m=\u001B[39m pywrap_tfe\u001B[39m.\u001B[39;49mTFE_Py_Execute(ctx\u001B[39m.\u001B[39;49m_handle, device_name, op_name,\n\u001B[1;32m     60\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m \u001B[39mexcept\u001B[39;00m core\u001B[39m.\u001B[39m_NotOkStatusException \u001B[39mas\u001B[39;00m e:\n\u001B[1;32m     62\u001B[0m   \u001B[39mif\u001B[39;00m name \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

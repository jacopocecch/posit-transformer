{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjei6wIcCNOK"
   },
   "source": [
    "# Transformer encoder for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_KWuqkLmCNOO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684315798436,
     "user_tz": -120,
     "elapsed": 2424,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-05-19T07:19:20.943169752Z",
     "start_time": "2023-05-19T07:19:19.194343845Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 09:19:19.530005: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/count\n",
      "2023-05-19 09:19:19.530080: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/count\n",
      "2023-05-19 09:19:19.530098: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/api\n",
      "2023-05-19 09:19:19.530110: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/api\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import os, pathlib, shutil, random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W46ihJfCNOP"
   },
   "source": [
    "### Dataset Imdb for sentences binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MM2b4HG6CNOP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684315703807,
     "user_tz": -120,
     "elapsed": 37909,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "50e6b1d1-6671-4467-d4b0-c48178273732"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
    "                                    untar=True, cache_dir='.',\n",
    "                                    cache_subdir='')\n",
    "\n",
    "shutil.rmtree('aclImdb/train/unsup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "JphODnh7CNOP",
    "executionInfo": {
     "status": "error",
     "timestamp": 1684315798436,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "a8bcc471-4b35-4556-9b13-d78a36609e36"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileExistsError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileExistsError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-eec741c76c5c>\u001B[0m in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mtrain_dir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase_dir\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m\"train\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mcategory\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\"neg\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"pos\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmakedirs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_dir\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mcategory\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0mfiles\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dir\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mcategory\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRandom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1337\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiles\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/os.py\u001B[0m in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    223\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 225\u001B[0;31m         \u001B[0mmkdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    226\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    227\u001B[0m         \u001B[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileExistsError\u001B[0m: [Errno 17] File exists: 'aclImdb/val/neg'"
     ]
    }
   ],
   "source": [
    "# Create a validation set with the 20% of training data\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files) \n",
    "    num_val_samples = int(0.2 * len(files)) \n",
    "    val_files = files[-num_val_samples:] \n",
    "    for fname in val_files: \n",
    "        shutil.move(train_dir / category / fname, val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZeP01N0oCNOQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684317207682,
     "user_tz": -120,
     "elapsed": 8372,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "6f0d139e-6e9d-43e1-a115-78e5297476b4",
    "ExecuteTime": {
     "end_time": "2023-05-19T07:19:28.600626156Z",
     "start_time": "2023-05-19T07:19:20.951174585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 09:19:22.324462: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 09:19:24.334346: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:164] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets that return integers sequences\n",
    "\n",
    "batch_size = 32\n",
    "train_ds = keras.utils.text_dataset_from_directory( \"aclImdb/train\", batch_size=batch_size)\n",
    "val_ds = keras.utils.text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n",
    "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)\n",
    "\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x) \n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = TextVectorization(\n",
    " max_tokens=max_tokens,\n",
    " output_mode=\"int\",\n",
    " output_sequence_length=max_length, \n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Do7sQZFyCNOQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684315815138,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-05-19T07:19:32.164522119Z",
     "start_time": "2023-05-19T07:19:32.106445996Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim \n",
    "        self.dense_dim = dense_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"),layers.Dense(embed_dim),])\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None): \n",
    "        if mask is not None: \n",
    "            mask = mask[:, tf.newaxis, :] \n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "    \n",
    "    def get_config(self): \n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "        \"embed_dim\": self.embed_dim,\n",
    "        \"num_heads\": self.num_heads,\n",
    "        \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim) \n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None): \n",
    "        return tf.math.not_equal(inputs, 0) \n",
    "    \n",
    "    def get_config(self): \n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "        \"output_dim\": self.output_dim,\n",
    "        \"sequence_length\": self.sequence_length,\n",
    "        \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l3sPKIztCNOR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684315815138,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-05-19T07:19:34.141998694Z",
     "start_time": "2023-05-19T07:19:34.099451442Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "sequence_length = 600\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CpbKyZDGCNOR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684315816502,
     "user_tz": -120,
     "elapsed": 1367,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    }
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs) \n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\",\n",
    " loss=\"binary_crossentropy\",\n",
    " metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JwFLAlMCNOR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684315816503,
     "user_tz": -120,
     "elapsed": 11,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "b75c78b5-d57f-46f2-de18-c574cb4018a3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<tf.Variable 'positional_embedding/embedding/embeddings:0' shape=(20000, 256) dtype=float32, numpy=\n",
      "array([[ 0.04429097,  0.02982345, -0.04750621, ...,  0.03149572,\n",
      "        -0.02255521, -0.01286163],\n",
      "       [-0.00765695, -0.01877952,  0.02530385, ...,  0.00484483,\n",
      "        -0.04495964,  0.02896006],\n",
      "       [ 0.02057966, -0.03033677, -0.04477325, ..., -0.03880764,\n",
      "        -0.03412137, -0.03791126],\n",
      "       ...,\n",
      "       [-0.0259515 , -0.03587122,  0.0267035 , ..., -0.04493271,\n",
      "         0.00103974, -0.02846854],\n",
      "       [-0.04507805, -0.01669551,  0.00864657, ..., -0.03672589,\n",
      "        -0.01724706,  0.02994117],\n",
      "       [-0.03943715,  0.04555156,  0.02501934, ..., -0.04719875,\n",
      "         0.04613448, -0.02291266]], dtype=float32)>, <tf.Variable 'positional_embedding/embedding_1/embeddings:0' shape=(600, 256) dtype=float32, numpy=\n",
      "array([[-0.00178373, -0.03841952, -0.04867255, ..., -0.03922776,\n",
      "         0.00872876,  0.02552914],\n",
      "       [ 0.02510444,  0.02715831,  0.0169317 , ..., -0.01206386,\n",
      "         0.04364611,  0.02741561],\n",
      "       [-0.03976976,  0.00715145,  0.04917356, ...,  0.04215923,\n",
      "         0.0190606 ,  0.01453384],\n",
      "       ...,\n",
      "       [-0.02488816, -0.00982888, -0.0335316 , ..., -0.0463172 ,\n",
      "         0.03066485,  0.00588747],\n",
      "       [-0.04338615,  0.00858082,  0.02977583, ..., -0.02035735,\n",
      "        -0.04868848, -0.0094332 ],\n",
      "       [-0.03745872,  0.00147983, -0.04950674, ...,  0.04490801,\n",
      "        -0.01621199,  0.04694198]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/query/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[-0.00066292,  0.00881399, -0.00470723, ..., -0.00204104,\n",
      "          0.0035375 , -0.00592412],\n",
      "        [-0.00574875,  0.00582729, -0.00890143, ...,  0.0087388 ,\n",
      "          0.00325603, -0.00016338]],\n",
      "\n",
      "       [[ 0.00717499,  0.00722605,  0.00147081, ...,  0.00863705,\n",
      "          0.00319221, -0.00131015],\n",
      "        [ 0.00889467,  0.00559784, -0.00459192, ...,  0.0004531 ,\n",
      "         -0.00558912, -0.00606231]],\n",
      "\n",
      "       [[ 0.00428747, -0.00109172,  0.00939424, ...,  0.00727906,\n",
      "          0.00065856,  0.00148637],\n",
      "        [ 0.00810687,  0.00517865, -0.00607663, ...,  0.00885459,\n",
      "         -0.00749492, -0.00909113]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00445389,  0.00031694,  0.00486469, ...,  0.00246277,\n",
      "         -0.00799477,  0.00504062],\n",
      "        [-0.00604037,  0.00287188, -0.00698057, ...,  0.00375249,\n",
      "          0.00442097, -0.00561553]],\n",
      "\n",
      "       [[-0.00377387, -0.00788756,  0.00120136, ..., -0.00737445,\n",
      "          0.00284444, -0.00238489],\n",
      "        [ 0.00423643, -0.00810702,  0.00069077, ...,  0.0011138 ,\n",
      "          0.00264813,  0.00231769]],\n",
      "\n",
      "       [[-0.0090037 , -0.00682832, -0.00148685, ...,  0.00063503,\n",
      "         -0.00192723, -0.0028418 ],\n",
      "        [-0.00508277, -0.00577315, -0.00177481, ..., -0.00415368,\n",
      "         -0.00804505, -0.00128602]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/query/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/key/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[ 7.0017856e-04,  2.4993829e-03, -2.8840899e-03, ...,\n",
      "          8.0505479e-03, -5.7578422e-03, -1.8105325e-03],\n",
      "        [ 5.1917722e-03,  6.4281933e-03,  7.1884356e-03, ...,\n",
      "         -5.4267328e-04, -5.2709840e-03, -6.9648959e-05]],\n",
      "\n",
      "       [[ 4.7052801e-03,  7.7131707e-03,  7.9364870e-03, ...,\n",
      "         -7.9508480e-03, -8.3894655e-03, -2.0416705e-03],\n",
      "        [ 1.7631957e-03,  1.3861293e-03, -5.9405481e-03, ...,\n",
      "         -5.4118321e-03, -1.2784032e-03,  9.3076490e-03]],\n",
      "\n",
      "       [[ 1.6663708e-03,  7.2835498e-03,  6.4729843e-03, ...,\n",
      "          6.9024060e-03,  5.4392125e-03, -2.0815758e-03],\n",
      "        [ 5.9818812e-03, -9.0482589e-03,  4.1624177e-03, ...,\n",
      "         -5.0412617e-03, -9.0435930e-03,  1.6431063e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-1.7579943e-03,  5.1957900e-03,  6.5422170e-03, ...,\n",
      "         -2.0091864e-03,  9.2824753e-03, -4.6707438e-03],\n",
      "        [-5.5118068e-03,  6.6611115e-03, -4.0327339e-03, ...,\n",
      "          3.6220578e-03,  6.8488605e-03, -3.7544891e-03]],\n",
      "\n",
      "       [[ 3.1487206e-03, -1.0492401e-03,  3.4870021e-04, ...,\n",
      "         -2.3785206e-03, -1.4644088e-03, -6.5206159e-03],\n",
      "        [-6.6253650e-03,  4.5340341e-03,  9.4112474e-03, ...,\n",
      "         -4.9895532e-03,  3.2211645e-03, -3.6798697e-04]],\n",
      "\n",
      "       [[ 4.7348849e-03,  8.3028451e-03,  9.9845603e-04, ...,\n",
      "         -8.1538307e-03,  7.3148683e-03, -4.2104069e-04],\n",
      "        [ 4.5137480e-04, -5.7428512e-03, -1.7463826e-03, ...,\n",
      "         -9.1260588e-03, -8.2031330e-03,  8.4268115e-04]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/key/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/value/kernel:0' shape=(256, 2, 256) dtype=float32, numpy=\n",
      "array([[[ 2.5615357e-03,  3.7116725e-03, -2.5519547e-03, ...,\n",
      "         -8.2538798e-03,  9.5918216e-04, -9.4670448e-03],\n",
      "        [ 8.1720389e-03, -6.9050798e-03,  5.9638638e-04, ...,\n",
      "         -1.9798926e-03,  5.8805048e-03, -6.5737180e-03]],\n",
      "\n",
      "       [[-4.2075822e-03,  6.1300267e-03, -8.2631968e-04, ...,\n",
      "          2.9641576e-03,  1.1744630e-03,  7.5558871e-03],\n",
      "        [-7.9031289e-04,  4.0146150e-04,  3.3815829e-03, ...,\n",
      "         -3.3281813e-03, -8.7339599e-03, -8.2933381e-03]],\n",
      "\n",
      "       [[ 3.5947189e-05, -1.0865601e-03,  5.3992495e-03, ...,\n",
      "          4.5207832e-03, -7.9544652e-03,  9.4967932e-03],\n",
      "        [-5.7408698e-03,  4.3606833e-03,  7.0743021e-03, ...,\n",
      "         -5.7431692e-03, -4.5496812e-03, -3.1984271e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.6310941e-03,  5.0345836e-03, -7.9172235e-03, ...,\n",
      "         -3.4693070e-04, -2.1752128e-03,  5.4629333e-04],\n",
      "        [ 5.5183629e-03,  6.2270686e-03, -7.5434125e-03, ...,\n",
      "          4.5258412e-03,  7.9807956e-03, -6.3526789e-03]],\n",
      "\n",
      "       [[-7.0702499e-03, -5.4176133e-03, -1.3802210e-03, ...,\n",
      "          7.4546449e-03,  8.0818702e-03,  3.9903102e-03],\n",
      "        [-6.9989008e-03, -5.1142219e-03, -4.9623414e-03, ...,\n",
      "          6.5001212e-03,  6.2339846e-03,  9.4545595e-03]],\n",
      "\n",
      "       [[ 2.6419060e-03,  2.0148763e-03, -1.9945293e-03, ...,\n",
      "         -1.5653493e-03, -6.9084410e-03, -4.1159270e-03],\n",
      "        [ 8.7240413e-03, -8.9811478e-03, -5.7167346e-03, ...,\n",
      "          4.3284586e-03, -4.6588206e-03,  3.3774264e-03]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/value/bias:0' shape=(2, 256) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/attention_output/kernel:0' shape=(2, 256, 256) dtype=float32, numpy=\n",
      "array([[[-0.0644432 ,  0.07345807,  0.05609555, ...,  0.06030592,\n",
      "          0.01935954,  0.01254207],\n",
      "        [-0.06756635, -0.06232866, -0.03999388, ..., -0.04635835,\n",
      "          0.05565643,  0.01945658],\n",
      "        [-0.00476646,  0.02211958, -0.07302277, ...,  0.07502725,\n",
      "         -0.06217032, -0.03298822],\n",
      "        ...,\n",
      "        [ 0.00827219,  0.04551985,  0.00644489, ..., -0.03417448,\n",
      "          0.0488686 ,  0.0468037 ],\n",
      "        [-0.04394239,  0.01794593, -0.06009561, ...,  0.06435696,\n",
      "          0.0486294 ,  0.00376053],\n",
      "        [-0.05242517, -0.06250115, -0.03985385, ...,  0.06754384,\n",
      "          0.03997598,  0.05579951]],\n",
      "\n",
      "       [[ 0.02181043,  0.01793993,  0.01136844, ..., -0.05361503,\n",
      "         -0.01164467, -0.06957941],\n",
      "        [-0.03427727,  0.02603916,  0.06109279, ..., -0.00603884,\n",
      "         -0.03547672,  0.07609979],\n",
      "        [-0.04960498,  0.00743784, -0.03541257, ..., -0.00883094,\n",
      "          0.01076182,  0.03463297],\n",
      "        ...,\n",
      "        [-0.06728698,  0.05988573,  0.02883583, ...,  0.0259963 ,\n",
      "          0.06443905, -0.02298698],\n",
      "        [-0.02868468, -0.01371258, -0.00310283, ..., -0.07609741,\n",
      "          0.05558144,  0.01426452],\n",
      "        [-0.0492454 ,  0.01949958, -0.04285585, ...,  0.06579252,\n",
      "         -0.05169672,  0.00096291]]], dtype=float32)>, <tf.Variable 'transformer_encoder/multi_head_attention/attention_output/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(256, 32) dtype=float32, numpy=\n",
      "array([[ 0.11905512, -0.03941063,  0.05744208, ...,  0.13773596,\n",
      "        -0.11010107, -0.11972979],\n",
      "       [-0.12101707, -0.10802753,  0.06552382, ..., -0.09569743,\n",
      "        -0.03081804,  0.01300293],\n",
      "       [-0.07889692, -0.13662845, -0.06746356, ..., -0.11019188,\n",
      "         0.05737388, -0.0395065 ],\n",
      "       ...,\n",
      "       [-0.06786643, -0.0117332 , -0.11079751, ...,  0.09658615,\n",
      "         0.06085692,  0.11846688],\n",
      "       [-0.0634138 ,  0.01039402, -0.00756967, ...,  0.01775517,\n",
      "         0.10875288, -0.13849483],\n",
      "       [ 0.11229715,  0.08488967,  0.06110281, ..., -0.11163932,\n",
      "        -0.05009045,  0.05751617]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(32, 256) dtype=float32, numpy=\n",
      "array([[ 0.04399702, -0.06858569,  0.03931695, ..., -0.02299   ,\n",
      "         0.02324644, -0.00992374],\n",
      "       [-0.11056234, -0.05535908,  0.12078038, ...,  0.09394449,\n",
      "        -0.06002679,  0.13795197],\n",
      "       [-0.12154565,  0.06765439, -0.0583095 , ...,  0.1404421 ,\n",
      "         0.13556051, -0.10791751],\n",
      "       ...,\n",
      "       [-0.10312237,  0.03331251, -0.04001309, ...,  0.13086239,\n",
      "         0.07894872,  0.11272773],\n",
      "       [-0.12591374, -0.07618017,  0.01454031, ...,  0.02239046,\n",
      "         0.12017092,  0.06598553],\n",
      "       [ 0.09716618,  0.09567903, -0.06294162, ...,  0.10335042,\n",
      "        -0.10782577,  0.12337196]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization_1/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'transformer_encoder/layer_normalization_1/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(256, 1) dtype=float32, numpy=\n",
      "array([[-0.07573593],\n",
      "       [ 0.12740992],\n",
      "       [ 0.13170223],\n",
      "       [ 0.04281031],\n",
      "       [ 0.04906102],\n",
      "       [ 0.1292816 ],\n",
      "       [ 0.04776931],\n",
      "       [ 0.08688132],\n",
      "       [ 0.13439588],\n",
      "       [ 0.14173971],\n",
      "       [ 0.12342112],\n",
      "       [ 0.14582302],\n",
      "       [ 0.07720195],\n",
      "       [-0.09307654],\n",
      "       [ 0.10945849],\n",
      "       [-0.12290324],\n",
      "       [-0.07205754],\n",
      "       [ 0.02524748],\n",
      "       [-0.04956865],\n",
      "       [-0.00464359],\n",
      "       [ 0.13156037],\n",
      "       [ 0.11951347],\n",
      "       [ 0.14949639],\n",
      "       [-0.00761336],\n",
      "       [-0.12635155],\n",
      "       [ 0.08093765],\n",
      "       [ 0.02308141],\n",
      "       [ 0.04001109],\n",
      "       [-0.0367909 ],\n",
      "       [-0.10290334],\n",
      "       [ 0.14057888],\n",
      "       [-0.02935101],\n",
      "       [ 0.08470927],\n",
      "       [ 0.14274661],\n",
      "       [-0.11986807],\n",
      "       [-0.1413933 ],\n",
      "       [-0.10471135],\n",
      "       [ 0.13036092],\n",
      "       [-0.07882778],\n",
      "       [-0.01165369],\n",
      "       [ 0.14673819],\n",
      "       [-0.10563673],\n",
      "       [-0.05077303],\n",
      "       [-0.06451707],\n",
      "       [ 0.00883406],\n",
      "       [ 0.11105539],\n",
      "       [-0.04359314],\n",
      "       [ 0.11836268],\n",
      "       [-0.04746016],\n",
      "       [ 0.0842412 ],\n",
      "       [ 0.03241251],\n",
      "       [-0.12013816],\n",
      "       [ 0.02597921],\n",
      "       [ 0.10541643],\n",
      "       [ 0.05840112],\n",
      "       [-0.03846122],\n",
      "       [-0.06950298],\n",
      "       [-0.07703172],\n",
      "       [-0.08684326],\n",
      "       [ 0.04042894],\n",
      "       [ 0.11053954],\n",
      "       [ 0.01323518],\n",
      "       [ 0.02623399],\n",
      "       [-0.00098857],\n",
      "       [-0.06676114],\n",
      "       [ 0.00117128],\n",
      "       [-0.01495457],\n",
      "       [-0.02754872],\n",
      "       [ 0.04859227],\n",
      "       [ 0.05569158],\n",
      "       [-0.06696856],\n",
      "       [ 0.09370269],\n",
      "       [-0.10346832],\n",
      "       [ 0.12530036],\n",
      "       [ 0.0434543 ],\n",
      "       [ 0.02312057],\n",
      "       [ 0.12817119],\n",
      "       [ 0.15202527],\n",
      "       [-0.09846325],\n",
      "       [-0.13763352],\n",
      "       [ 0.1169941 ],\n",
      "       [ 0.07923423],\n",
      "       [ 0.05128562],\n",
      "       [ 0.13838764],\n",
      "       [-0.09380334],\n",
      "       [-0.12047003],\n",
      "       [-0.05926751],\n",
      "       [ 0.10699733],\n",
      "       [-0.12258635],\n",
      "       [ 0.06361935],\n",
      "       [-0.11398116],\n",
      "       [ 0.12714998],\n",
      "       [-0.06838264],\n",
      "       [ 0.10758673],\n",
      "       [-0.00990501],\n",
      "       [-0.12889439],\n",
      "       [ 0.09661968],\n",
      "       [ 0.06842256],\n",
      "       [-0.09885581],\n",
      "       [-0.0043492 ],\n",
      "       [-0.06066971],\n",
      "       [ 0.04625949],\n",
      "       [ 0.10735445],\n",
      "       [-0.08090687],\n",
      "       [ 0.0668046 ],\n",
      "       [-0.14683637],\n",
      "       [ 0.01525682],\n",
      "       [ 0.09070919],\n",
      "       [-0.15110914],\n",
      "       [-0.03304103],\n",
      "       [-0.11984786],\n",
      "       [-0.14250891],\n",
      "       [-0.01133963],\n",
      "       [-0.09615514],\n",
      "       [-0.03136303],\n",
      "       [-0.0343833 ],\n",
      "       [ 0.10799016],\n",
      "       [ 0.12447114],\n",
      "       [ 0.14307131],\n",
      "       [-0.0325413 ],\n",
      "       [-0.11797598],\n",
      "       [-0.08800134],\n",
      "       [-0.11805609],\n",
      "       [ 0.04383649],\n",
      "       [ 0.13078742],\n",
      "       [ 0.13637753],\n",
      "       [ 0.05785333],\n",
      "       [ 0.06569821],\n",
      "       [-0.12698397],\n",
      "       [-0.05506271],\n",
      "       [-0.03996541],\n",
      "       [-0.08490188],\n",
      "       [ 0.14494084],\n",
      "       [-0.12111953],\n",
      "       [-0.00603543],\n",
      "       [ 0.09773947],\n",
      "       [ 0.07439202],\n",
      "       [ 0.06089109],\n",
      "       [ 0.05599064],\n",
      "       [ 0.11739899],\n",
      "       [-0.12828474],\n",
      "       [ 0.08241417],\n",
      "       [-0.15145063],\n",
      "       [-0.02423766],\n",
      "       [-0.03479582],\n",
      "       [-0.0284131 ],\n",
      "       [ 0.14367883],\n",
      "       [ 0.06630822],\n",
      "       [ 0.01931132],\n",
      "       [-0.00950502],\n",
      "       [ 0.14991568],\n",
      "       [ 0.03435619],\n",
      "       [ 0.05627912],\n",
      "       [ 0.05895622],\n",
      "       [ 0.13371153],\n",
      "       [ 0.03638759],\n",
      "       [ 0.07152942],\n",
      "       [-0.00520343],\n",
      "       [ 0.08240134],\n",
      "       [ 0.12712224],\n",
      "       [ 0.0630518 ],\n",
      "       [-0.06610177],\n",
      "       [-0.13614689],\n",
      "       [ 0.10597394],\n",
      "       [-0.02661224],\n",
      "       [-0.09436427],\n",
      "       [ 0.13045509],\n",
      "       [-0.07926949],\n",
      "       [-0.14637768],\n",
      "       [-0.05870108],\n",
      "       [-0.07916056],\n",
      "       [ 0.03079441],\n",
      "       [ 0.09488149],\n",
      "       [-0.09622449],\n",
      "       [-0.09930389],\n",
      "       [ 0.14081945],\n",
      "       [ 0.08864872],\n",
      "       [-0.13319004],\n",
      "       [ 0.02404554],\n",
      "       [ 0.06948896],\n",
      "       [ 0.06340449],\n",
      "       [ 0.02970262],\n",
      "       [-0.0570375 ],\n",
      "       [-0.14623146],\n",
      "       [ 0.04159904],\n",
      "       [-0.127437  ],\n",
      "       [-0.02543633],\n",
      "       [-0.03760561],\n",
      "       [-0.09009612],\n",
      "       [ 0.09447061],\n",
      "       [ 0.11748166],\n",
      "       [-0.03361151],\n",
      "       [-0.08189934],\n",
      "       [ 0.05195847],\n",
      "       [ 0.06408487],\n",
      "       [ 0.00705852],\n",
      "       [-0.13059802],\n",
      "       [ 0.01211794],\n",
      "       [ 0.06771915],\n",
      "       [-0.08453536],\n",
      "       [ 0.0170036 ],\n",
      "       [ 0.05684708],\n",
      "       [-0.04549693],\n",
      "       [-0.01345606],\n",
      "       [-0.09020228],\n",
      "       [-0.1348899 ],\n",
      "       [-0.08601639],\n",
      "       [-0.00326537],\n",
      "       [ 0.1367736 ],\n",
      "       [ 0.13403462],\n",
      "       [-0.0031433 ],\n",
      "       [-0.13218139],\n",
      "       [-0.06203387],\n",
      "       [-0.11883684],\n",
      "       [-0.14755628],\n",
      "       [ 0.15102161],\n",
      "       [ 0.10164107],\n",
      "       [-0.14321017],\n",
      "       [-0.12496379],\n",
      "       [ 0.08471008],\n",
      "       [-0.0308442 ],\n",
      "       [ 0.01529026],\n",
      "       [ 0.01201434],\n",
      "       [ 0.12444712],\n",
      "       [-0.06529978],\n",
      "       [-0.07335693],\n",
      "       [-0.07597586],\n",
      "       [-0.10908836],\n",
      "       [-0.03944127],\n",
      "       [ 0.08803354],\n",
      "       [-0.12258351],\n",
      "       [ 0.11386643],\n",
      "       [ 0.03339002],\n",
      "       [ 0.01025088],\n",
      "       [-0.12306885],\n",
      "       [ 0.0235049 ],\n",
      "       [-0.03504463],\n",
      "       [ 0.12424959],\n",
      "       [ 0.01777332],\n",
      "       [ 0.10247083],\n",
      "       [ 0.08110486],\n",
      "       [-0.14590444],\n",
      "       [-0.13791162],\n",
      "       [-0.04331219],\n",
      "       [ 0.07318874],\n",
      "       [ 0.07038613],\n",
      "       [ 0.00015256],\n",
      "       [-0.09031794],\n",
      "       [-0.07951266],\n",
      "       [ 0.06672791],\n",
      "       [ 0.10091521],\n",
      "       [-0.02899273],\n",
      "       [-0.1005384 ],\n",
      "       [-0.02304174],\n",
      "       [ 0.10551731],\n",
      "       [ 0.04549478]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeqYzKiDCNOS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684316176243,
     "user_tz": -120,
     "elapsed": 358179,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "693101cc-825f-44f9-f792-e4f7acdd56f9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 126s 193ms/step - loss: 0.4693 - binary_accuracy: 0.7786 - val_loss: 0.2699 - val_binary_accuracy: 0.8912\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 76s 121ms/step - loss: 0.1677 - binary_accuracy: 0.9374 - val_loss: 0.3137 - val_binary_accuracy: 0.8848\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 64s 102ms/step - loss: 0.0895 - binary_accuracy: 0.9675 - val_loss: 0.4814 - val_binary_accuracy: 0.8730\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 57s 91ms/step - loss: 0.0554 - binary_accuracy: 0.9811 - val_loss: 0.5087 - val_binary_accuracy: 0.8686\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f24e70decb0>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"encoder_model/full_transformer_encoder.h5\", save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "] \n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, \n",
    "callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xRpqgmtACNOS",
    "ExecuteTime": {
     "end_time": "2023-05-19T07:19:42.306975124Z",
     "start_time": "2023-05-19T07:19:41.771640557Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"encoder_model/full_transformer_encoder.h5\",\n",
    "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
    "                    \"PositionalEmbedding\": PositionalEmbedding})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_TtOVHgCNOS"
   },
   "source": [
    "Evaluate the model accuracy with Float32 default weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGWHmFsjCNOT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684316198265,
     "user_tz": -120,
     "elapsed": 22027,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "e0dde5e5-b14a-4dbe-919f-d8c29916bd9a",
    "ExecuteTime": {
     "end_time": "2023-05-19T07:20:01.762407114Z",
     "start_time": "2023-05-19T07:19:45.092780194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36/782 [>.............................] - ETA: 4:52 - loss: 0.9583 - binary_accuracy: 0.5816"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mevaluate(int_test_ds)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1514\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   1512\u001B[0m         logs \u001B[38;5;241m=\u001B[39m tmp_logs  \u001B[38;5;66;03m# No error, now safe to assign to logs.\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m         end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m data_handler\u001B[38;5;241m.\u001B[39mstep_increment\n\u001B[0;32m-> 1514\u001B[0m         \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_test_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1515\u001B[0m logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[1;32m   1516\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_test_end(logs\u001B[38;5;241m=\u001B[39mlogs)\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:478\u001B[0m, in \u001B[0;36mCallbackList.on_test_batch_end\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls the `on_test_batch_end` methods of its callbacks.\u001B[39;00m\n\u001B[1;32m    472\u001B[0m \n\u001B[1;32m    473\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001B[39;00m\n\u001B[1;32m    475\u001B[0m \u001B[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001B[39;00m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_call_test_batch_hooks:\n\u001B[0;32m--> 478\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTEST\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mend\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:316\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook\u001B[0;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[1;32m    314\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_batch_begin_hook(mode, batch, logs)\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hook \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 316\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_end_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    318\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnrecognized hook: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(hook))\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:336\u001B[0m, in \u001B[0;36mCallbackList._call_batch_end_hook\u001B[0;34m(self, mode, batch, logs)\u001B[0m\n\u001B[1;32m    333\u001B[0m   batch_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_start_time\n\u001B[1;32m    334\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times\u001B[38;5;241m.\u001B[39mappend(batch_time)\n\u001B[0;32m--> 336\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_batches_for_timing_check:\n\u001B[1;32m    339\u001B[0m   end_hook_name \u001B[38;5;241m=\u001B[39m hook_name\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:374\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook_helper\u001B[0;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[1;32m    373\u001B[0m   hook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(callback, hook_name)\n\u001B[0;32m--> 374\u001B[0m   \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timing:\n\u001B[1;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m hook_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hook_times:\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:1056\u001B[0m, in \u001B[0;36mProgbarLogger.on_test_batch_end\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m   1054\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_test_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1055\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_called_in_fit:\n\u001B[0;32m-> 1056\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py:1125\u001B[0m, in \u001B[0;36mProgbarLogger._batch_update_progbar\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m   1122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1123\u001B[0m   \u001B[38;5;66;03m# Only block async when verbose = 1.\u001B[39;00m\n\u001B[1;32m   1124\u001B[0m   logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[0;32m-> 1125\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprogbar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:909\u001B[0m, in \u001B[0;36mProgbar.update\u001B[0;34m(self, current, values, finalize)\u001B[0m\n\u001B[1;32m    907\u001B[0m prev_total_width \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_total_width\n\u001B[1;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dynamic_display:\n\u001B[0;32m--> 909\u001B[0m   \u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\b\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mprev_total_width\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    910\u001B[0m   sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    911\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/ipykernel/iostream.py:584\u001B[0m, in \u001B[0;36mOutStream.write\u001B[0;34m(self, string)\u001B[0m\n\u001B[1;32m    582\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\u001B[38;5;241m.\u001B[39mschedule(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flush)\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 584\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_schedule_flush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(string)\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/ipykernel/iostream.py:481\u001B[0m, in \u001B[0;36mOutStream._schedule_flush\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_schedule_in_thread\u001B[39m():\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_io_loop\u001B[38;5;241m.\u001B[39mcall_later(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflush_interval, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flush)\n\u001B[0;32m--> 481\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpub_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_schedule_in_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/ipykernel/iostream.py:213\u001B[0m, in \u001B[0;36mIOPubThread.schedule\u001B[0;34m(self, f)\u001B[0m\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_events\u001B[38;5;241m.\u001B[39mappend(f)\n\u001B[1;32m    212\u001B[0m     \u001B[38;5;66;03m# wake event thread (message content is ignored)\u001B[39;00m\n\u001B[0;32m--> 213\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event_pipe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    215\u001B[0m     f()\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/zmq/sugar/socket.py:688\u001B[0m, in \u001B[0;36mSocket.send\u001B[0;34m(self, data, flags, copy, track, routing_id, group)\u001B[0m\n\u001B[1;32m    681\u001B[0m         data \u001B[38;5;241m=\u001B[39m zmq\u001B[38;5;241m.\u001B[39mFrame(\n\u001B[1;32m    682\u001B[0m             data,\n\u001B[1;32m    683\u001B[0m             track\u001B[38;5;241m=\u001B[39mtrack,\n\u001B[1;32m    684\u001B[0m             copy\u001B[38;5;241m=\u001B[39mcopy \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    685\u001B[0m             copy_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy_threshold,\n\u001B[1;32m    686\u001B[0m         )\n\u001B[1;32m    687\u001B[0m     data\u001B[38;5;241m.\u001B[39mgroup \u001B[38;5;241m=\u001B[39m group\n\u001B[0;32m--> 688\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrack\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32mzmq/backend/cython/socket.pyx:742\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket.Socket.send\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mzmq/backend/cython/socket.pyx:789\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket.Socket.send\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mzmq/backend/cython/socket.pyx:250\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket._send_copy\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/zmq/backend/cython/checkrc.pxd:13\u001B[0m, in \u001B[0;36mzmq.backend.cython.checkrc._check_rc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTZUuwX3CNOT"
   },
   "source": [
    "Evaluate the model accuracy converting the weights to Float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IgdomyWMCNOT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684316198265,
     "user_tz": -120,
     "elapsed": 14,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "2d9f5dce-8c38-43c5-a9ca-3b4cfb75268f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[dtype('float32')]\n"
     ]
    }
   ],
   "source": [
    "K.set_floatx('float16')\n",
    "\n",
    "# Get the original weights\n",
    "ws = model.get_weights()\n",
    "print(np.unique([w.dtype for w in model.get_weights()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfEDcDTrCNOT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684317104328,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "e8f5a352-4215-4940-9dfd-65927521d79d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[dtype('float16')]\n"
     ]
    }
   ],
   "source": [
    "# Convert the weights to Posit <16,0> and load a new model\n",
    "wsp = [w.astype(K.floatx()) for w in ws]\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"float16\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs) \n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_float16 = keras.Model(inputs, outputs)\n",
    "model_float16.compile(optimizer=\"adam\",\n",
    " loss=\"binary_crossentropy\",\n",
    " metrics=[\"accuracy\"])\n",
    "model_float16.set_weights(wsp)\n",
    "\n",
    "print(np.unique([w.dtype for w in model_float16.get_weights()]))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "int_test_ds = int_test_ds.map(lambda x, y: (tf.cast(x, tf.float16), tf.cast(y, tf.float16)))"
   ],
   "metadata": {
    "id": "I5yAvWmlGKZ1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684317108720,
     "user_tz": -120,
     "elapsed": 1,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(list(int_test_ds)[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpILO6YuHBhg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684317211215,
     "user_tz": -120,
     "elapsed": 1300,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "6042f88a-4c6f-438f-d0e8-1faa196407ae"
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(<tf.Tensor: shape=(32, 600), dtype=int64, numpy=\n",
      "array([[   1,    1,  443, ...,    0,    0,    0],\n",
      "       [4252,    2,  353, ...,    0,    0,    0],\n",
      "       [  11, 1867,    7, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  10, 1550,   11, ...,    0,    0,    0],\n",
      "       [  21,    2,  214, ...,    0,    0,    0],\n",
      "       [  74,  142,   34, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1], dtype=int32)>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWxuyCDqCNOT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684317135557,
     "user_tz": -120,
     "elapsed": 20805,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "9473cb6f-d790-481a-8d23-40fc0ff12aa4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3540 - accuracy: 0.8667\n",
      "Test acc: 0.867\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model_float16.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oHmcCDmCNOT"
   },
   "source": [
    "Evaluate the model accuracy converting the weights to Posit<16,0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "qtiMeW18CNOT",
    "executionInfo": {
     "status": "error",
     "timestamp": 1684316520185,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "Francesco Hudema",
      "userId": "13573668235636244390"
     }
    },
    "outputId": "49892f56-0ca6-4e5f-c456-dd7807042eac"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-d3d057940ae1>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_floatx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'posit160'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# Get the original weights\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mws\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mw\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend_config.py\u001B[0m in \u001B[0;36mset_floatx\u001B[0;34m(value)\u001B[0m\n\u001B[1;32m    108\u001B[0m     \u001B[0maccepted_dtypes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"float16\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"float32\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"float64\"\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0maccepted_dtypes\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 110\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    111\u001B[0m             \u001B[0;34mf\"Unknown `floatx` value: {value}. \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m             \u001B[0;34mf\"Expected one of {accepted_dtypes}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown `floatx` value: posit160. Expected one of {'float32', 'float16', 'float64'}"
     ]
    }
   ],
   "source": [
    "K.set_floatx('posit160')\n",
    "\n",
    "# Get the original weights\n",
    "ws = model.get_weights()\n",
    "print(np.unique([w.dtype for w in model.get_weights()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpG3jxXkCNOU",
    "outputId": "c9e769b8-7b97-4f2a-cdab-7ee14700fb03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype(posit160)]\n"
     ]
    }
   ],
   "source": [
    "# Convert the weights to Posit <16,0> and load a new model\n",
    "wsp = [w.astype(K.floatx()) for w in ws]\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs) \n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_posit = keras.Model(inputs, outputs)\n",
    "model_posit.compile(optimizer=\"adam\",\n",
    " loss=\"binary_crossentropy\",\n",
    " metrics=[\"accuracy\"])\n",
    "model_posit.set_weights(wsp)\n",
    "\n",
    "print(np.unique([w.dtype for w in model_posit.get_weights()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKjNgOr4CNOU"
   },
   "outputs": [],
   "source": [
    "print(f\"Test acc: {model_posit.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
